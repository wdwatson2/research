{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from rff.layers import GaussianEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    9793\n",
      "0    8965\n",
      "Name: class1, dtype: int64\n",
      "duration              False\n",
      "total_fiat            False\n",
      "total_biat            False\n",
      "min_fiat              False\n",
      "min_biat              False\n",
      "max_fiat              False\n",
      "max_biat              False\n",
      "mean_fiat             False\n",
      "mean_biat             False\n",
      "flowPktsPerSecond     False\n",
      "flowBytesPerSecond    False\n",
      "min_flowiat           False\n",
      "max_flowiat           False\n",
      "mean_flowiat          False\n",
      "std_flowiat           False\n",
      "min_active            False\n",
      "mean_active           False\n",
      "max_active            False\n",
      "std_active            False\n",
      "min_idle              False\n",
      "mean_idle             False\n",
      "max_idle              False\n",
      "std_idle              False\n",
      "class1                False\n",
      "dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>total_fiat</th>\n",
       "      <th>total_biat</th>\n",
       "      <th>min_fiat</th>\n",
       "      <th>min_biat</th>\n",
       "      <th>max_fiat</th>\n",
       "      <th>max_biat</th>\n",
       "      <th>mean_fiat</th>\n",
       "      <th>mean_biat</th>\n",
       "      <th>flowPktsPerSecond</th>\n",
       "      <th>...</th>\n",
       "      <th>std_flowiat</th>\n",
       "      <th>min_active</th>\n",
       "      <th>mean_active</th>\n",
       "      <th>max_active</th>\n",
       "      <th>std_active</th>\n",
       "      <th>min_idle</th>\n",
       "      <th>mean_idle</th>\n",
       "      <th>max_idle</th>\n",
       "      <th>std_idle</th>\n",
       "      <th>class1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9368711.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1564818.0</td>\n",
       "      <td>1549373.0</td>\n",
       "      <td>190205.285714</td>\n",
       "      <td>203290.456522</td>\n",
       "      <td>389822.391917</td>\n",
       "      <td>370323.719754</td>\n",
       "      <td>10.353612</td>\n",
       "      <td>...</td>\n",
       "      <td>267600.198443</td>\n",
       "      <td>1871488.0</td>\n",
       "      <td>1.983656e+06</td>\n",
       "      <td>2195089.0</td>\n",
       "      <td>1.832197e+05</td>\n",
       "      <td>1234883.0</td>\n",
       "      <td>1420565.0</td>\n",
       "      <td>1523088.0</td>\n",
       "      <td>161096.539275</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7340238.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1567554.0</td>\n",
       "      <td>1527893.0</td>\n",
       "      <td>165686.977273</td>\n",
       "      <td>186914.846154</td>\n",
       "      <td>317267.548742</td>\n",
       "      <td>304370.651301</td>\n",
       "      <td>11.580006</td>\n",
       "      <td>...</td>\n",
       "      <td>221462.862028</td>\n",
       "      <td>1491627.0</td>\n",
       "      <td>3.572433e+06</td>\n",
       "      <td>5653239.0</td>\n",
       "      <td>2.942704e+06</td>\n",
       "      <td>1131498.0</td>\n",
       "      <td>1324636.0</td>\n",
       "      <td>1517774.0</td>\n",
       "      <td>273138.379008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4644225.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1270547.0</td>\n",
       "      <td>1079974.0</td>\n",
       "      <td>165865.178571</td>\n",
       "      <td>195302.130435</td>\n",
       "      <td>329473.126261</td>\n",
       "      <td>300492.588227</td>\n",
       "      <td>11.412022</td>\n",
       "      <td>...</td>\n",
       "      <td>217475.425246</td>\n",
       "      <td>1758922.0</td>\n",
       "      <td>1.758922e+06</td>\n",
       "      <td>1758922.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1079974.0</td>\n",
       "      <td>1079974.0</td>\n",
       "      <td>1079974.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4978735.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2492050.0</td>\n",
       "      <td>2457286.0</td>\n",
       "      <td>239543.250000</td>\n",
       "      <td>276596.388889</td>\n",
       "      <td>612435.304238</td>\n",
       "      <td>628339.573544</td>\n",
       "      <td>8.034169</td>\n",
       "      <td>...</td>\n",
       "      <td>436959.716436</td>\n",
       "      <td>1710925.0</td>\n",
       "      <td>2.382905e+06</td>\n",
       "      <td>3054885.0</td>\n",
       "      <td>9.503232e+05</td>\n",
       "      <td>1346073.0</td>\n",
       "      <td>1894031.5</td>\n",
       "      <td>2441990.0</td>\n",
       "      <td>774930.342317</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11838189.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3094089.0</td>\n",
       "      <td>3093543.0</td>\n",
       "      <td>243766.500000</td>\n",
       "      <td>295954.725000</td>\n",
       "      <td>599721.781709</td>\n",
       "      <td>625632.703972</td>\n",
       "      <td>7.602514</td>\n",
       "      <td>...</td>\n",
       "      <td>436129.639296</td>\n",
       "      <td>1747431.0</td>\n",
       "      <td>2.400446e+06</td>\n",
       "      <td>3240696.0</td>\n",
       "      <td>6.232744e+05</td>\n",
       "      <td>1394455.0</td>\n",
       "      <td>1983227.0</td>\n",
       "      <td>3042717.0</td>\n",
       "      <td>725987.829075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     duration  total_fiat  total_biat   min_fiat   min_biat       max_fiat  \\\n",
       "0   9368711.0        16.0         4.0  1564818.0  1549373.0  190205.285714   \n",
       "1   7340238.0        18.0         4.0  1567554.0  1527893.0  165686.977273   \n",
       "2   4644225.0        29.0        15.0  1270547.0  1079974.0  165865.178571   \n",
       "3   4978735.0        19.0         8.0  2492050.0  2457286.0  239543.250000   \n",
       "4  11838189.0        19.0        10.0  3094089.0  3093543.0  243766.500000   \n",
       "\n",
       "        max_biat      mean_fiat      mean_biat  flowPktsPerSecond  ...  \\\n",
       "0  203290.456522  389822.391917  370323.719754          10.353612  ...   \n",
       "1  186914.846154  317267.548742  304370.651301          11.580006  ...   \n",
       "2  195302.130435  329473.126261  300492.588227          11.412022  ...   \n",
       "3  276596.388889  612435.304238  628339.573544           8.034169  ...   \n",
       "4  295954.725000  599721.781709  625632.703972           7.602514  ...   \n",
       "\n",
       "     std_flowiat  min_active   mean_active  max_active    std_active  \\\n",
       "0  267600.198443   1871488.0  1.983656e+06   2195089.0  1.832197e+05   \n",
       "1  221462.862028   1491627.0  3.572433e+06   5653239.0  2.942704e+06   \n",
       "2  217475.425246   1758922.0  1.758922e+06   1758922.0  0.000000e+00   \n",
       "3  436959.716436   1710925.0  2.382905e+06   3054885.0  9.503232e+05   \n",
       "4  436129.639296   1747431.0  2.400446e+06   3240696.0  6.232744e+05   \n",
       "\n",
       "    min_idle  mean_idle   max_idle       std_idle  class1  \n",
       "0  1234883.0  1420565.0  1523088.0  161096.539275       0  \n",
       "1  1131498.0  1324636.0  1517774.0  273138.379008       0  \n",
       "2  1079974.0  1079974.0  1079974.0       0.000000       0  \n",
       "3  1346073.0  1894031.5  2441990.0  774930.342317       0  \n",
       "4  1394455.0  1983227.0  3042717.0  725987.829075       0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = pd.read_csv(r\"C:\\Users\\smbm2\\projects\\research\\csv_datasets\\Scenario A1\\TimeBasedFeatures-Dataset-15s-VPN.csv\") # personal\n",
    "df = pd.read_csv(r\"C:\\python\\research\\csv_datasets\\Scenario A1\\TimeBasedFeatures-Dataset-15s-VPN.csv\") # for IR\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['class1'] = le.fit_transform(df['class1'])\n",
    "\n",
    "print(df['class1'].value_counts())\n",
    "print(df.isna().any())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vpnDataset(Dataset):\n",
    "    def __init__(self, df, target = 'class1'):\n",
    "        self.n = df.shape[0]\n",
    "        \n",
    "        self.y = df[target].astype(np.float32).values\n",
    "\n",
    "        self.x = df.drop(columns=[target]).astype(np.float32).values\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13130\n",
      "13130 5628\n"
     ]
    }
   ],
   "source": [
    "vpn_dataset = vpnDataset(df)\n",
    "train_size = int(0.7*len(vpn_dataset))\n",
    "print(train_size)\n",
    "test_size = len(vpn_dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(vpn_dataset, [train_size, test_size])\n",
    "print(len(train_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 256\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_sz, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_sz, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing is Done. Model time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(SelfAttention, self).__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "        assert(self.head_dim * heads == embed_size), \"Embed size needs to be div by heads\"\n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys =nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.fc_out = nn.Linear(heads*self.head_dim, embed_size)\n",
    "\n",
    "    def forward(self, values, keys, query):\n",
    "        N = query.shape[0]\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n",
    "\n",
    "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
    "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
    "        queries = query.reshape(N, key_len, self.heads, self.head_dim)\n",
    "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "\n",
    "        # if mask is not None:\n",
    "        #     energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
    "\n",
    "        attention = torch.softmax(energy / (self.embed_size ** (1/2)), dim=3)\n",
    "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(N, query_len, self.heads*self.head_dim)\n",
    "        out = self.fc_out(out)\n",
    "        return out\n",
    "    \n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, dropout, forward_expansion):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "\n",
    "        self.attention = SelfAttention(embed_size, heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(nn.Linear(embed_size, forward_expansion*embed_size),\n",
    "                                          nn.ReLU(),\n",
    "                                          nn.Linear(forward_expansion*embed_size, embed_size)\n",
    "                                          )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,value,key,query):\n",
    "        attention = self.attention(value, key, query)\n",
    "        x = self.dropout(self.norm1(attention + query))\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm2(forward + x))\n",
    "        return out\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 sigma,\n",
    "                 embed_size,\n",
    "                 input_size,\n",
    "                 n_features,\n",
    "                 num_layers,\n",
    "                 heads,\n",
    "                 forward_expansion,\n",
    "                 dropout\n",
    "    ):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.embed_size = embed_size\n",
    "        self.embeddings = GaussianEncoding(sigma = sigma, input_size=input_size, encoded_size=embed_size//2) \n",
    "        \n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerBlock(\n",
    "                    embed_size,\n",
    "                    heads,\n",
    "                    dropout=dropout,\n",
    "                    forward_expansion=forward_expansion\n",
    "                )\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"shape of x going in \", x.shape)\n",
    "        N, n_features = x.shape\n",
    "        x = x.unsqueeze(2)\n",
    "        # print(\"shape of x going in \", x.shape)\n",
    "    \n",
    "        x = self.embeddings(x)\n",
    "            \n",
    "        # print(x_i.shape)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, x, x)\n",
    "        \n",
    "        # x= torch.reshape(x, (-1, n_features*x.shape[2]))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Encoder(sigma = 4, embed_size=20, input_size=1, n_features=23, num_layers=1, heads=1, forward_expansion=4, dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[ 0.0000e+00, -4.9193e+00,  1.4977e-01,  ..., -0.0000e+00,\n",
      "           1.1308e-01, -0.0000e+00],\n",
      "         [ 1.6164e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           1.3403e+00,  8.7776e-02],\n",
      "         ...,\n",
      "         [-2.2901e-01, -2.6453e-01,  0.0000e+00,  ..., -0.0000e+00,\n",
      "          -2.4917e+00,  3.9011e-01],\n",
      "         [-0.0000e+00,  0.0000e+00, -2.7723e-02,  ...,  0.0000e+00,\n",
      "          -0.0000e+00,  2.2446e+00],\n",
      "         [-0.0000e+00,  1.3799e-01,  0.0000e+00,  ..., -0.0000e+00,\n",
      "          -8.5961e-01,  2.4876e-01]],\n",
      "\n",
      "        [[-0.0000e+00, -0.0000e+00,  2.5517e+00,  ..., -0.0000e+00,\n",
      "          -1.7768e+00,  4.2568e+00],\n",
      "         [-5.2854e-03, -0.0000e+00,  2.8503e+00,  ...,  2.4009e-01,\n",
      "          -0.0000e+00, -1.9952e+00],\n",
      "         [-2.2255e+00,  0.0000e+00, -8.1048e-02,  ..., -3.6647e-01,\n",
      "           0.0000e+00, -2.1727e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00,  0.0000e+00, -8.0004e-01,  ..., -2.6230e+00,\n",
      "          -4.2408e-01, -0.0000e+00],\n",
      "         [-1.9519e+00, -0.0000e+00, -0.0000e+00,  ..., -1.9183e-01,\n",
      "          -1.1579e+00,  1.1812e-01],\n",
      "         [ 0.0000e+00,  4.8072e-01, -7.0567e-01,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -1.4948e+00]],\n",
      "\n",
      "        [[-6.7108e-01,  4.0681e-01, -8.8838e-01,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -6.4866e+00],\n",
      "         [-0.0000e+00, -0.0000e+00,  5.0619e+00,  ..., -5.2836e-01,\n",
      "          -5.2195e-01,  4.0957e-01],\n",
      "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           4.1051e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00, -0.0000e+00, -2.5238e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           1.4467e+00,  0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "           4.1632e-01,  1.3114e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-5.8895e-01, -0.0000e+00, -6.1585e-01,  ...,  5.3764e+00,\n",
      "          -8.5685e-01,  0.0000e+00],\n",
      "         [ 2.3447e+00,  1.1937e+00, -0.0000e+00,  ...,  2.6820e+00,\n",
      "          -4.6011e+00,  0.0000e+00],\n",
      "         [-6.0180e+00,  0.0000e+00,  7.6510e-01,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -2.0084e+00],\n",
      "         ...,\n",
      "         [-8.4846e-01, -4.8257e-01, -6.5832e-01,  ..., -2.8319e-01,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00,  2.0103e+00, -0.0000e+00,  ...,  1.6112e-01,\n",
      "           1.2671e+00,  0.0000e+00],\n",
      "         [-1.5711e+00, -2.5182e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -1.6363e+00, -2.3636e+00]],\n",
      "\n",
      "        [[-0.0000e+00, -1.2918e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          -1.5213e+00, -5.2228e-01],\n",
      "         [ 5.3797e+00, -0.0000e+00, -0.0000e+00,  ..., -5.4935e-01,\n",
      "          -2.3147e+00, -2.5268e-02],\n",
      "         [-9.0526e-01, -0.0000e+00, -3.1749e+00,  ..., -4.1664e-01,\n",
      "          -0.0000e+00, -1.0108e-01],\n",
      "         ...,\n",
      "         [-8.3622e-01, -2.1791e-01, -4.9149e-01,  ..., -2.1748e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [-5.4540e+00,  0.0000e+00, -1.9373e+00,  ..., -8.0831e-01,\n",
      "          -7.5160e-02,  0.0000e+00],\n",
      "         [ 5.7554e+00,  1.1314e+00,  0.0000e+00,  ..., -3.0093e+00,\n",
      "          -0.0000e+00, -1.6308e+00]],\n",
      "\n",
      "        [[ 0.0000e+00, -0.0000e+00, -1.2087e+00,  ..., -7.8160e-02,\n",
      "          -0.0000e+00, -2.5683e+00],\n",
      "         [-2.2433e+00, -2.2256e+00, -1.6795e-01,  ..., -1.7661e-01,\n",
      "          -9.6808e-01,  3.4746e-01],\n",
      "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  4.9498e-02,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [ 2.2601e-01,  3.7328e-02,  0.0000e+00,  ..., -3.5453e-02,\n",
      "           7.9899e-01, -4.4689e-02],\n",
      "         [-3.1624e-01, -0.0000e+00, -2.2462e+00,  ..., -4.0548e-01,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [-3.7889e+00,  0.0000e+00, -3.8692e-01,  ...,  5.6378e-03,\n",
      "           5.4114e+00,  0.0000e+00]]], grad_fn=<MulBackward0>)\n",
      "tensor([[ 0.0000, -4.9193,  0.1498,  ..., -0.0000, -0.8596,  0.2488],\n",
      "        [-0.0000, -0.0000,  2.5517,  ..., -0.0000, -0.0000, -1.4948],\n",
      "        [-0.6711,  0.4068, -0.8884,  ..., -0.0000,  0.4163,  0.1311],\n",
      "        ...,\n",
      "        [-0.5889, -0.0000, -0.6159,  ..., -0.0000, -1.6363, -2.3636],\n",
      "        [-0.0000, -1.2918,  0.0000,  ..., -3.0093, -0.0000, -1.6308],\n",
      "        [ 0.0000, -0.0000, -1.2087,  ...,  0.0056,  5.4114,  0.0000]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.0000,  0.7715,  0.0703,  ...,  0.0000,  0.0000,  0.0577],\n",
      "         [-0.0000,  0.8331, -0.2484,  ..., -4.6850,  0.3878,  0.0264],\n",
      "         [ 4.1762, -0.0000, -1.0217,  ...,  0.0000, -1.6808, -0.0000],\n",
      "         ...,\n",
      "         [-0.3458, -0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.1694],\n",
      "         [-0.0000, -0.0000, -0.6707,  ...,  2.0873, -0.6882,  3.5982],\n",
      "         [ 3.5147, -0.0000, -0.3557,  ..., -0.3036, -0.6458, -0.0000]],\n",
      "\n",
      "        [[ 0.0000, -0.3227,  2.5349,  ..., -1.1962, -0.5385, -0.4091],\n",
      "         [ 0.7830, -0.0000,  0.0000,  ...,  0.0000,  4.7716,  0.0000],\n",
      "         [ 2.7608, -0.7050, -0.0000,  ...,  2.1877, -0.5841, -0.1224],\n",
      "         ...,\n",
      "         [-1.1506, -2.2142,  5.4270,  ..., -1.6604, -0.0000, -0.0000],\n",
      "         [-0.0000, -0.0000, -0.9903,  ..., -0.5386, -0.0000, -1.0011],\n",
      "         [-2.7704,  0.0000,  0.1539,  ..., -1.2726,  0.1120,  0.0000]],\n",
      "\n",
      "        [[-1.0968, -0.2923, -0.0000,  ...,  0.0000, -0.3761,  0.1341],\n",
      "         [-0.0000,  3.2973, -0.0000,  ...,  0.2252, -0.2621, -0.2059],\n",
      "         [-0.0000,  2.4327, -1.9932,  ...,  0.0000,  0.0000,  4.4961],\n",
      "         ...,\n",
      "         [-0.5835, -3.1582,  3.8868,  ..., -0.5068, -0.0187,  0.0000],\n",
      "         [-0.0000,  0.0000, -1.9148,  ..., -0.5340, -0.1678,  0.0000],\n",
      "         [-0.2608, -0.0000, -0.3298,  ..., -0.2115, -0.4169, -1.5586]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.9686,  0.3070,  0.0000,  ...,  5.4057, -2.1887, -0.3207],\n",
      "         [-0.0000, -0.0135, -2.2014,  ..., -0.0000,  0.0000,  0.0000],\n",
      "         [-0.0000,  0.0000, -0.5878,  ..., -0.0000,  2.1787, -0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.4123,  0.0000,  ..., -0.8045,  0.0000, -0.3982],\n",
      "         [-0.1644,  1.6767, -0.0000,  ...,  0.0000, -0.2635,  0.0000],\n",
      "         [-0.0000, -0.2562, -1.2092,  ..., -0.2276, -0.1913,  0.0000]],\n",
      "\n",
      "        [[-0.9537,  0.0000,  0.0000,  ...,  0.0000,  0.4961, -0.0000],\n",
      "         [ 0.4285, -0.0000,  0.0000,  ..., -0.0000,  0.0000,  0.2719],\n",
      "         [-0.0000, -0.0259, -0.0000,  ..., -0.0000,  2.4353, -0.0938],\n",
      "         ...,\n",
      "         [-0.3945,  3.8430, -0.3342,  ..., -0.0000,  0.0000, -0.0000],\n",
      "         [-2.0166,  4.8526, -0.0000,  ..., -0.3713, -0.0000,  0.0000],\n",
      "         [-0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.2149, -0.0000]],\n",
      "\n",
      "        [[-0.5108, -0.3748,  0.0000,  ...,  0.0000, -7.1233,  0.0080],\n",
      "         [-0.0000,  5.7446,  0.0000,  ..., -2.0002, -0.2409, -0.4318],\n",
      "         [-0.3018, -2.7228,  0.2182,  ..., -0.0921,  0.7734,  0.2364],\n",
      "         ...,\n",
      "         [-0.7182,  0.3712, -0.6503,  ...,  0.0000, -2.1374,  0.0000],\n",
      "         [-0.9087, -1.8745, -0.0000,  ...,  0.0000, -0.6969, -0.0000],\n",
      "         [-0.1233, -3.6809,  3.7767,  ..., -0.8899,  0.0000, -1.2467]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-0.0000,  0.7715,  0.0703,  ..., -0.3036, -0.6458, -0.0000],\n",
      "        [ 0.0000, -0.3227,  2.5349,  ..., -1.2726,  0.1120,  0.0000],\n",
      "        [-1.0968, -0.2923, -0.0000,  ..., -0.2115, -0.4169, -1.5586],\n",
      "        ...,\n",
      "        [-0.9686,  0.3070,  0.0000,  ..., -0.2276, -0.1913,  0.0000],\n",
      "        [-0.9537,  0.0000,  0.0000,  ...,  0.0000,  0.2149, -0.0000],\n",
      "        [-0.5108, -0.3748,  0.0000,  ..., -0.8899,  0.0000, -1.2467]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.0000,  0.0000,  0.3900,  ...,  0.5609, -3.8536, -0.2064],\n",
      "         [ 0.0000,  0.7769,  0.0000,  ..., -0.2514,  1.5968, -5.1078],\n",
      "         [-0.0000,  0.0611, -0.0000,  ..., -0.4929,  0.8751,  2.3262],\n",
      "         ...,\n",
      "         [ 3.8737,  0.0000, -0.0000,  ..., -0.0000,  0.0000, -0.5592],\n",
      "         [ 1.7558, -1.5799, -0.0000,  ...,  0.0000, -0.4618,  0.0000],\n",
      "         [ 3.3070, -2.5818, -0.2830,  ..., -0.0000,  1.0244,  4.9626]],\n",
      "\n",
      "        [[-1.2218,  1.0341, -5.9032,  ...,  0.2968,  0.5537,  0.0000],\n",
      "         [-0.1479,  0.3752, -0.0000,  ...,  0.7651,  0.1240, -0.0000],\n",
      "         [-2.1001,  1.6309, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         ...,\n",
      "         [ 2.4921, -1.5128, -0.0000,  ...,  0.8007, -1.5125, -0.5653],\n",
      "         [-0.0000, -0.0000, -0.9603,  ..., -0.0000, -1.2728, -0.0000],\n",
      "         [-0.0000, -0.0000,  5.4198,  ...,  0.4752,  0.0000, -0.0000]],\n",
      "\n",
      "        [[-2.4587, -2.1350,  0.5435,  ...,  0.0000, -0.0000, -0.7688],\n",
      "         [-0.0000, -0.0000,  0.0000,  ..., -0.9013,  0.0000, -0.0000],\n",
      "         [-0.0000, -0.5170, -1.7025,  ..., -0.8092, -0.5551,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000, -0.1377, -4.2434,  ...,  1.5209,  0.0000,  1.6358],\n",
      "         [ 0.0000,  0.0000,  0.7469,  ..., -0.0000,  0.4853,  0.0381],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000, -4.3005, -4.1921]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000, -0.6220, -0.9425,  ..., -0.0000, -1.2053, -0.0000],\n",
      "         [-0.0000,  4.2682, -0.3992,  ...,  0.2613,  0.2498,  1.2062],\n",
      "         [-0.1995,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000, -4.1055, -0.3433,  ...,  0.0000,  0.0000, -0.0000],\n",
      "         [-0.0000,  3.4850, -0.1427,  ...,  0.7203,  0.5407,  0.0000],\n",
      "         [ 0.0000, -0.0461, -1.0019,  ..., -0.4551,  0.0000,  0.1513]],\n",
      "\n",
      "        [[ 0.1376, -0.6159,  0.0000,  ...,  0.0000, -0.1495,  0.0000],\n",
      "         [-0.0000,  1.3584,  1.8135,  ...,  2.2039, -0.0000, -0.0000],\n",
      "         [-0.0000,  0.0000, -5.2106,  ...,  0.0082, -0.0479,  0.3151],\n",
      "         ...,\n",
      "         [ 2.3649, -1.3035, -0.5344,  ..., -1.6477, -0.0000, -0.0000],\n",
      "         [-0.0000, -0.1886, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [-0.0000, -0.1070, -0.1846,  ..., -0.4369, -0.4076, -0.0000]],\n",
      "\n",
      "        [[-0.6599,  0.0000,  0.0000,  ..., -0.1581,  1.0106,  0.0000],\n",
      "         [-0.0000,  0.0000, -3.6851,  ...,  0.0000, -0.0000,  0.5426],\n",
      "         [ 0.0000,  0.2019, -0.0000,  ...,  2.4823, -0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 5.7761, -0.0000, -0.0000,  ..., -0.4087, -0.2042, -0.0000],\n",
      "         [-0.0000, -0.3507, -0.0000,  ..., -0.0000,  0.0000, -0.3326],\n",
      "         [-0.8625,  3.6026, -1.0117,  ..., -0.0000, -0.0000, -0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-0.0000,  0.0000,  0.3900,  ..., -0.0000,  1.0244,  4.9626],\n",
      "        [-1.2218,  1.0341, -5.9032,  ...,  0.4752,  0.0000, -0.0000],\n",
      "        [-2.4587, -2.1350,  0.5435,  ..., -0.0000, -4.3005, -4.1921],\n",
      "        ...,\n",
      "        [-0.0000, -0.6220, -0.9425,  ..., -0.4551,  0.0000,  0.1513],\n",
      "        [ 0.1376, -0.6159,  0.0000,  ..., -0.4369, -0.4076, -0.0000],\n",
      "        [-0.6599,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.7973,  0.0000,  6.4757,  ..., -0.0000,  0.0000, -5.2437],\n",
      "         [-0.0000,  0.0000,  3.0574,  ...,  0.0000,  0.0000,  0.1140],\n",
      "         [-2.3506,  0.0000,  2.9138,  ...,  0.1893, -0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000, -0.0158, -0.0000,  ..., -0.0000,  0.0000, -0.6360],\n",
      "         [-4.5742,  0.0000,  1.6524,  ...,  0.0000,  0.0000,  0.2810],\n",
      "         [ 0.3348, -0.0000, -0.0000,  ...,  0.3066, -0.2940, -0.0000]],\n",
      "\n",
      "        [[ 0.2571,  0.0000,  0.8818,  ...,  0.2133, -0.0000, -0.7131],\n",
      "         [-3.3546, -0.0000, -0.9762,  ...,  3.4308, -0.3723,  0.0000],\n",
      "         [-0.6332, -0.2002, -0.0000,  ..., -2.1062, -0.9399, -0.0431],\n",
      "         ...,\n",
      "         [-0.0000, -0.5614, -5.4438,  ...,  0.0000, -0.0000,  0.0000],\n",
      "         [-6.8145,  0.0873,  0.4164,  ...,  0.0000,  0.0000,  0.3545],\n",
      "         [-0.0000,  1.3318, -0.0000,  ..., -1.7897,  0.0000, -3.4069]],\n",
      "\n",
      "        [[ 0.0529,  0.0000, -0.0000,  ..., -0.0000, -0.0997, -0.3118],\n",
      "         [-4.1508,  0.3851, -0.0000,  ..., -0.2990, -0.0000,  0.6049],\n",
      "         [ 0.0000,  0.0000, -0.8573,  ...,  0.1847,  0.0000, -0.3294],\n",
      "         ...,\n",
      "         [ 0.0000, -1.8274, -0.0531,  ...,  0.4408, -0.0000, -0.0000],\n",
      "         [-0.5437, -0.1276, -0.0000,  ...,  0.0000, -0.0000, -0.2659],\n",
      "         [ 0.0000,  0.0000, -0.1117,  ..., -0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000, -0.0000, -1.0410,  ..., -2.2521, -0.0000, -0.0000],\n",
      "         [-0.0000,  0.0000,  0.0323,  ..., -5.5686, -0.0000,  0.0000],\n",
      "         [-1.6565, -0.0000, -0.5268,  ..., -0.0000, -0.0000, -1.1906],\n",
      "         ...,\n",
      "         [ 2.4318, -0.3967, -0.0000,  ..., -0.6749, -2.6695,  0.0000],\n",
      "         [ 0.0000,  0.4277, -1.4232,  ..., -0.0000, -0.0000,  0.0000],\n",
      "         [-0.0000, -0.0000, -1.5055,  ..., -0.0000, -0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.3315, -0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.3805],\n",
      "         [-0.0000,  0.6719, -3.1351,  ...,  1.3365, -0.1736, -0.3093],\n",
      "         [-0.0000,  4.6528, -0.7493,  ..., -1.6352, -0.0000,  1.9088],\n",
      "         ...,\n",
      "         [-0.2159, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.1952],\n",
      "         [-0.0226, -0.0000, -1.2061,  ..., -0.0000,  0.0000, -0.0000],\n",
      "         [ 0.0000,  4.4210, -0.7536,  ..., -0.0000,  0.5203, -0.0000]],\n",
      "\n",
      "        [[-0.7876, -0.0000, -0.2070,  ..., -0.0000,  0.0000, -3.0948],\n",
      "         [ 0.0000, -2.6601,  0.0000,  ..., -0.5982,  1.6728, -0.0978],\n",
      "         [-0.0000, -1.1882, -0.0000,  ..., -0.0000,  0.0348, -2.4057],\n",
      "         ...,\n",
      "         [-0.3946, -0.0000, -0.0814,  ...,  0.0000,  0.0000, -0.0000],\n",
      "         [-0.3989,  0.0000, -0.2644,  ..., -0.1143,  0.4122, -3.1391],\n",
      "         [ 3.1116, -0.0000,  0.3323,  ...,  0.0000,  0.0000, -0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-0.7973,  0.0000,  6.4757,  ...,  0.3066, -0.2940, -0.0000],\n",
      "        [ 0.2571,  0.0000,  0.8818,  ..., -1.7897,  0.0000, -3.4069],\n",
      "        [ 0.0529,  0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        ...,\n",
      "        [-0.0000, -0.0000, -1.0410,  ..., -0.0000, -0.0000,  0.0000],\n",
      "        [-0.3315, -0.0000, -0.0000,  ..., -0.0000,  0.5203, -0.0000],\n",
      "        [-0.7876, -0.0000, -0.2070,  ...,  0.0000,  0.0000, -0.0000]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.9160, -0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "         [-0.0648,  0.0000, -0.0000,  ...,  0.3328, -0.0000, -0.0000],\n",
      "         [-0.0000, -0.0000, -0.0000,  ...,  4.9414, -0.4725,  0.0000],\n",
      "         ...,\n",
      "         [-1.4483,  0.0000, -0.0000,  ...,  0.4270, -0.0000,  0.2949],\n",
      "         [-0.3342,  0.0000, -0.0000,  ...,  0.2572, -0.0000,  0.0000],\n",
      "         [-0.3294, -3.2487,  0.2131,  ..., -0.0000,  0.0000,  0.5676]],\n",
      "\n",
      "        [[-1.1284,  0.0000, -0.6248,  ..., -0.0000,  0.0000, -0.6614],\n",
      "         [ 0.0063, -0.0000, -0.0000,  ..., -0.0000, -0.0480,  2.4334],\n",
      "         [-0.0000,  0.0000,  0.1331,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         ...,\n",
      "         [-0.3143,  0.0000, -0.0000,  ...,  0.4606,  0.0000, -0.1255],\n",
      "         [-4.7955,  0.0000,  0.0000,  ...,  0.3382,  0.0000,  0.0000],\n",
      "         [-0.0000,  0.3372,  0.0313,  ...,  0.2250, -0.0000, -0.0000]],\n",
      "\n",
      "        [[-3.6812,  2.9750, -0.0449,  ..., -0.0000,  0.0000, -0.0000],\n",
      "         [-2.9563, -0.5536,  0.0000,  ..., -0.0000, -0.2383,  1.0977],\n",
      "         [-0.0000, -0.0000, -0.0000,  ..., -0.1090, -0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000,  1.1402, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "         [-0.0000,  0.0000, -0.0000,  ..., -0.0000,  0.0662, -0.0000],\n",
      "         [-0.9686,  0.0000, -0.4889,  ..., -0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000, -0.0000, -0.0000,  ..., -0.4967,  0.1637,  0.0000],\n",
      "         [ 0.0000, -0.6306, -0.5312,  ...,  0.0000, -0.0000,  0.0000],\n",
      "         [-0.3310, -0.0000, -0.7092,  ..., -0.6288,  5.5629,  0.1421],\n",
      "         ...,\n",
      "         [-0.0000,  0.1596, -0.0000,  ...,  0.2043,  0.0000, -0.1064],\n",
      "         [-0.0000,  0.2976, -0.0000,  ..., -0.2402,  0.0000, -3.6156],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -1.3908]],\n",
      "\n",
      "        [[-0.0000, -0.0000,  2.3961,  ..., -0.5424,  0.0000, -0.0000],\n",
      "         [ 3.2301,  0.0000, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "         [-0.0000, -0.0000,  0.0000,  ..., -0.0000,  5.2765,  0.5647],\n",
      "         ...,\n",
      "         [-0.0000,  0.0000, -0.2320,  ...,  0.0000, -0.6114,  0.0000],\n",
      "         [-5.1057, -0.0000,  0.0000,  ...,  3.1486, -0.2565, -3.0834],\n",
      "         [-2.1398, -0.0000,  4.6478,  ..., -0.0000,  0.0000, -3.1477]],\n",
      "\n",
      "        [[-0.0000, -0.0000, -0.9668,  ..., -0.0000,  0.6804, -0.0000],\n",
      "         [-0.0000,  0.0000,  2.1693,  ..., -0.2271,  0.0000, -0.0000],\n",
      "         [ 1.2801, -0.0000,  0.1462,  ...,  0.0000,  0.0000,  1.2473],\n",
      "         ...,\n",
      "         [-0.9985,  0.0000, -0.0000,  ..., -0.3642,  0.4483, -0.3074],\n",
      "         [ 0.0000, -3.5401, -0.0713,  ...,  0.1735, -0.0000, -0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.7371]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-0.9160, -0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.5676],\n",
      "        [-1.1284,  0.0000, -0.6248,  ...,  0.2250, -0.0000, -0.0000],\n",
      "        [-3.6812,  2.9750, -0.0449,  ..., -0.0000,  0.0000, -0.0000],\n",
      "        ...,\n",
      "        [-0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.0000, -1.3908],\n",
      "        [-0.0000, -0.0000,  2.3961,  ..., -0.0000,  0.0000, -3.1477],\n",
      "        [-0.0000, -0.0000, -0.9668,  ..., -0.0000, -0.0000, -0.7371]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.1634,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -7.1635],\n",
      "         [-0.0000,  0.0000,  0.0000,  ..., -0.2175,  0.0000, -0.5139],\n",
      "         [ 0.0000,  1.4508, -1.7272,  ...,  0.0000,  0.3269,  2.0822],\n",
      "         ...,\n",
      "         [ 4.8792,  4.3744, -0.6844,  ..., -1.5878, -0.2298, -1.1776],\n",
      "         [-0.7859,  0.0000, -3.1464,  ..., -0.0000, -0.0000,  0.0000],\n",
      "         [-0.0000, -0.0000,  5.3879,  ..., -0.6631,  0.0000, -0.0000]],\n",
      "\n",
      "        [[-0.4618,  1.3181, -5.1060,  ...,  1.4936, -0.0000,  0.2561],\n",
      "         [ 3.7032,  0.0000,  4.2445,  ..., -0.3096,  0.4298, -0.0657],\n",
      "         [-0.0000,  0.2693, -3.9099,  ..., -3.1497,  0.9746, -0.0000],\n",
      "         ...,\n",
      "         [-0.0000, -0.0000,  1.9593,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [ 0.3182,  1.9734, -2.3388,  ..., -0.0671, -0.0000,  0.0904],\n",
      "         [-0.6728,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "        [[ 0.4527,  1.4248, -0.0000,  ..., -0.0000, -0.4483, -0.0000],\n",
      "         [-0.0000, -0.0000,  4.4010,  ...,  5.9663, -1.4940,  0.0000],\n",
      "         [-0.0000, -0.4017, -0.0000,  ..., -2.5536, -0.0381, -0.1629],\n",
      "         ...,\n",
      "         [ 2.2355, -0.0000, -1.0613,  ..., -0.1954, -0.0000, -2.8595],\n",
      "         [-0.0000, -0.3082, -0.0000,  ..., -0.0000, -1.2045,  0.5340],\n",
      "         [ 0.1783, -0.0000,  0.6769,  ...,  0.4974,  0.0833, -1.4752]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 2.6018, -0.6851, -0.6673,  ...,  0.0000, -0.0000, -0.0000],\n",
      "         [-0.5801,  1.9359,  0.0000,  ..., -0.0000, -2.9347, -1.9217],\n",
      "         [-0.3205,  0.3137,  1.6415,  ...,  0.0000, -3.9557, -0.0000],\n",
      "         ...,\n",
      "         [-0.1213, -0.0000, -1.2263,  ..., -0.4353,  0.4975, -0.0000],\n",
      "         [-0.0000,  0.0000, -0.0000,  ..., -0.0000,  1.8867,  0.1140],\n",
      "         [-0.0000,  1.1532,  0.0000,  ..., -0.2278, -0.0000, -0.0000]],\n",
      "\n",
      "        [[-0.5084,  0.0000, -4.5816,  ..., -0.2235,  0.7672,  0.0000],\n",
      "         [-1.6973,  0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
      "         [-0.0000,  0.7599,  0.0000,  ..., -1.8933,  0.8805,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000,  0.6984, -0.0000,  ...,  3.8438, -0.5883,  0.0000],\n",
      "         [-0.0000, -0.0000, -0.5220,  ...,  0.0000, -0.0000, -0.7394],\n",
      "         [-0.8203,  0.0000, -0.0502,  ..., -0.0000,  0.0000, -0.0088]],\n",
      "\n",
      "        [[ 0.1639,  3.4115, -0.0000,  ..., -0.7750,  0.7336,  1.9410],\n",
      "         [-0.0000, -0.1019, -0.9227,  ...,  5.0949,  0.0000, -0.0000],\n",
      "         [-0.4380, -0.1819,  0.0000,  ..., -0.0000, -0.0000, -2.3612],\n",
      "         ...,\n",
      "         [-0.9126, -0.0000,  0.0000,  ..., -2.6584,  0.0923, -1.4461],\n",
      "         [-4.5546,  0.3690, -0.5889,  ..., -0.0000, -0.0000,  0.0000],\n",
      "         [-0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-0.1634,  0.0000,  0.0000,  ..., -0.6631,  0.0000, -0.0000],\n",
      "        [-0.4618,  1.3181, -5.1060,  ..., -0.0000,  0.0000, -0.0000],\n",
      "        [ 0.4527,  1.4248, -0.0000,  ...,  0.4974,  0.0833, -1.4752],\n",
      "        ...,\n",
      "        [ 2.6018, -0.6851, -0.6673,  ..., -0.2278, -0.0000, -0.0000],\n",
      "        [-0.5084,  0.0000, -4.5816,  ..., -0.0000,  0.0000, -0.0088],\n",
      "        [ 0.1639,  3.4115, -0.0000,  ..., -0.0000, -0.0000, -0.0000]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-2.8571e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -0.0000e+00,  4.3067e+00],\n",
      "         [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "          -4.8836e-01,  4.6679e+00],\n",
      "         [-0.0000e+00,  5.1427e-01, -0.0000e+00,  ...,  2.1676e-01,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -1.3271e-01,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00, -9.2623e-01, -0.0000e+00,  ..., -3.0859e-01,\n",
      "           0.0000e+00, -7.2511e-01],\n",
      "         [-0.0000e+00,  5.4430e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           4.4402e-01, -0.0000e+00]],\n",
      "\n",
      "        [[-0.0000e+00,  0.0000e+00, -1.1692e+00,  ..., -1.4606e+00,\n",
      "          -5.4295e-01,  0.0000e+00],\n",
      "         [-0.0000e+00, -0.0000e+00, -1.0062e+00,  ...,  4.9238e+00,\n",
      "          -5.9419e-01,  3.4975e-01],\n",
      "         [-0.0000e+00,  4.2391e-01,  0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  9.5272e-01],\n",
      "         ...,\n",
      "         [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  8.6747e-01,\n",
      "           1.3418e-01,  0.0000e+00],\n",
      "         [-3.7740e-01,  0.0000e+00, -5.4169e-01,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  6.2091e-02],\n",
      "         [-0.0000e+00, -2.9472e+00,  0.0000e+00,  ..., -1.9271e-01,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-2.1033e+00,  0.0000e+00, -2.2949e+00,  ...,  0.0000e+00,\n",
      "          -2.5805e+00,  0.0000e+00],\n",
      "         [-4.2193e-01,  1.7217e-02,  0.0000e+00,  ..., -4.7434e+00,\n",
      "          -8.5774e-01,  4.0003e+00],\n",
      "         [-0.0000e+00, -0.0000e+00, -3.7567e-01,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  1.3403e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00, -1.7523e+00, -0.0000e+00,  ..., -1.6071e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [-0.0000e+00,  5.1448e-03, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           5.2186e-01,  0.0000e+00],\n",
      "         [-1.1579e+00, -4.7807e-01,  7.2056e+00,  ..., -5.9486e-01,\n",
      "           1.8005e-01, -2.3759e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000e+00, -0.0000e+00, -3.0524e-01,  ..., -1.9088e+00,\n",
      "           4.2221e+00,  4.4148e-02],\n",
      "         [-0.0000e+00,  1.4914e-02,  0.0000e+00,  ..., -1.7614e-01,\n",
      "          -0.0000e+00, -4.4816e+00],\n",
      "         [-4.3246e+00, -4.6129e-01, -8.7626e-01,  ...,  0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00,  2.1904e-02,  2.0456e+00,  ..., -0.0000e+00,\n",
      "           6.1833e-01, -0.0000e+00],\n",
      "         [ 3.9979e+00, -2.5376e+00,  1.0856e+00,  ..., -1.7127e+00,\n",
      "           9.4721e-01, -0.0000e+00],\n",
      "         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -1.0563e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 5.4506e-02, -0.0000e+00, -0.0000e+00,  ...,  3.5948e-01,\n",
      "           1.8020e-01,  4.5682e-01],\n",
      "         [-6.9841e-01,  1.1241e-01, -0.0000e+00,  ..., -5.6413e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-1.4667e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -9.1576e-01, -0.0000e+00],\n",
      "         ...,\n",
      "         [ 4.7097e+00,  1.3190e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -1.2782e+00,  7.8562e-01],\n",
      "         [ 0.0000e+00, -0.0000e+00, -1.0098e+00,  ...,  5.4191e+00,\n",
      "          -3.6872e-01,  6.7270e-01],\n",
      "         [-0.0000e+00, -2.0509e+00, -0.0000e+00,  ..., -9.3136e-02,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00, -1.7587e+00],\n",
      "         [-7.3615e-01,  0.0000e+00,  6.8067e-01,  ..., -4.3956e-01,\n",
      "           3.7617e-01, -0.0000e+00],\n",
      "         [-0.0000e+00, -8.7997e-01, -2.1391e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -2.5093e+00,  1.1757e-02,  ..., -1.9264e-01,\n",
      "           2.8395e-01, -8.2207e-01],\n",
      "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -9.3720e-02,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00, -2.3329e+00,  7.4595e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00]]], grad_fn=<MulBackward0>)\n",
      "tensor([[-2.8571,  0.0000, -0.0000,  ..., -0.0000,  0.4440, -0.0000],\n",
      "        [-0.0000,  0.0000, -1.1692,  ..., -0.1927,  0.0000,  0.0000],\n",
      "        [-2.1033,  0.0000, -2.2949,  ..., -0.5949,  0.1800, -0.2376],\n",
      "        ...,\n",
      "        [-0.0000, -0.0000, -0.3052,  ..., -1.0563,  0.0000,  0.0000],\n",
      "        [ 0.0545, -0.0000, -0.0000,  ..., -0.0931,  0.0000,  0.0000],\n",
      "        [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.0000,  0.5550, -0.5039,  ..., -0.0000,  0.8372, -0.2772],\n",
      "         [-0.6044,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -2.8304],\n",
      "         [-0.4165,  0.0000,  0.0000,  ..., -0.0000,  0.5522, -0.0000],\n",
      "         ...,\n",
      "         [-0.0000, -0.0000,  3.3431,  ...,  0.0000, -0.0000, -0.0000],\n",
      "         [-0.0000, -0.0000, -0.0000,  ..., -0.2712, -0.0000, -0.0000],\n",
      "         [-1.9027,  0.0000, -0.0000,  ..., -0.0219, -1.0092, -0.2557]],\n",
      "\n",
      "        [[-0.0000,  0.7303, -0.0000,  ...,  0.0000,  0.0000, -5.0900],\n",
      "         [-0.5275, -0.6115, -4.0750,  ..., -0.4757, -0.3230,  0.0000],\n",
      "         [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.6862,  0.0000],\n",
      "         ...,\n",
      "         [-0.7508,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "         [-0.8731,  0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
      "         [-0.0000,  1.3435, -0.3335,  ..., -0.0000,  0.7116, -0.0000]],\n",
      "\n",
      "        [[-0.0000, -1.3846, -0.0000,  ...,  0.0000, -0.5249,  0.0000],\n",
      "         [-0.1080, -0.0497,  0.0000,  ..., -2.8125,  0.2681, -0.0000],\n",
      "         [-0.0237, -1.3556,  0.7591,  ..., -0.0000,  0.7970,  0.6794],\n",
      "         ...,\n",
      "         [-1.6265,  0.7941, -0.6642,  ..., -0.0000, -0.0000,  0.0000],\n",
      "         [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "         [ 0.0000, -0.0000, -0.2164,  ..., -0.0000,  0.2413, -0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000, -0.0000, -1.1029,  ...,  0.0566,  0.0000,  0.0000],\n",
      "         [-0.0000,  0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [-0.0000, -0.0000,  0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-1.2928,  0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.5139],\n",
      "         [-0.0000,  0.0000,  0.0535,  ...,  0.8502,  0.0000, -0.0000],\n",
      "         [-0.0000,  2.2169, -0.0000,  ..., -0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "        [[-0.0000,  0.0000, -0.0000,  ...,  0.0000,  2.0743, -0.0000],\n",
      "         [-4.1421,  3.1695,  0.1690,  ...,  0.2613, -0.0000,  0.0000],\n",
      "         [-0.0000, -0.0000, -0.3062,  ..., -0.0000,  0.2108, -0.7621],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000,  0.7354],\n",
      "         [ 0.0000, -0.0000,  2.4130,  ...,  0.0000, -0.0000,  3.9004],\n",
      "         [ 2.4013, -0.7213, -1.4088,  ..., -0.1206, -0.0000, -0.0000]],\n",
      "\n",
      "        [[-1.8130, -0.0000, -0.0000,  ..., -0.3782, -0.5172,  4.3349],\n",
      "         [-0.1272,  0.6140,  0.0000,  ..., -0.0000,  1.7204, -0.0000],\n",
      "         [-0.0000, -0.0000,  0.2135,  ..., -0.0000,  0.0000, -0.0666],\n",
      "         ...,\n",
      "         [-0.0000, -0.0000, -0.0000,  ..., -0.6979, -0.1448, -0.0000],\n",
      "         [-0.0000, -0.6362, -0.0000,  ..., -0.2051, -0.9333,  0.0000],\n",
      "         [ 0.0000, -0.0000,  0.0000,  ..., -0.0000, -1.3478, -1.9594]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-0.0000,  0.5550, -0.5039,  ..., -0.0219, -1.0092, -0.2557],\n",
      "        [-0.0000,  0.7303, -0.0000,  ..., -0.0000,  0.7116, -0.0000],\n",
      "        [-0.0000, -1.3846, -0.0000,  ..., -0.0000,  0.2413, -0.0000],\n",
      "        ...,\n",
      "        [-0.0000, -0.0000, -1.1029,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [-0.0000,  0.0000, -0.0000,  ..., -0.1206, -0.0000, -0.0000],\n",
      "        [-1.8130, -0.0000, -0.0000,  ..., -0.0000, -1.3478, -1.9594]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[ 3.4626, -0.0000, -0.2402,  ...,  0.0000, -0.0000, -0.0000],\n",
      "         [-0.3797,  1.0344, -0.0000,  ..., -5.8622,  0.2595,  0.7575],\n",
      "         [-1.0162,  0.4887, -0.0000,  ...,  0.0000,  0.6170, -0.5978],\n",
      "         ...,\n",
      "         [ 0.9243,  0.3865, -0.4577,  ...,  0.5091, -0.0000, -0.6832],\n",
      "         [-0.0000, -0.2750, -0.0000,  ..., -0.4264, -0.0000, -0.0000],\n",
      "         [ 0.0000, -2.6929,  2.8172,  ..., -0.5221, -0.0000, -0.0000]],\n",
      "\n",
      "        [[-3.7824, -0.0000, -0.0000,  ..., -0.1147,  3.7605,  0.0000],\n",
      "         [-0.6685, -1.4621, -0.0000,  ...,  0.0000,  0.7632,  0.1549],\n",
      "         [-1.0041,  2.5153, -0.8382,  ..., -0.0000, -1.1084,  1.7370],\n",
      "         ...,\n",
      "         [-0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0000,  0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.1098],\n",
      "         [-0.0000, -2.8591, -0.7289,  ...,  0.0000,  0.5352,  0.5080]],\n",
      "\n",
      "        [[-0.6795, -0.0000, -0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "         [-0.0000,  0.5252, -0.0000,  ..., -0.0000,  0.2074, -0.0000],\n",
      "         [-0.1020,  1.1153,  0.0000,  ...,  0.0000,  0.9110,  0.1631],\n",
      "         ...,\n",
      "         [ 4.2551, -0.0000,  0.0000,  ..., -0.1663, -1.7594, -0.0511],\n",
      "         [-4.2650, -0.0000, -0.0000,  ...,  0.0000, -0.3055,  3.8775],\n",
      "         [-3.3253,  0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.6502]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000,  0.1747, -0.0000,  ...,  0.0000,  3.7466,  0.0000],\n",
      "         [-0.8703, -0.3170, -0.3683,  ...,  0.0000, -4.8906, -0.0000],\n",
      "         [ 0.0000,  0.0000, -6.2332,  ..., -0.0000,  0.0000,  0.6484],\n",
      "         ...,\n",
      "         [-0.0000, -0.1668,  0.0000,  ...,  0.1539,  1.0950,  0.0000],\n",
      "         [-0.0000,  0.0000,  1.3881,  ...,  0.0000, -0.0000,  2.8414],\n",
      "         [-0.0000, -0.5363, -1.6544,  ..., -0.0106,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0000,  4.9580,  0.0229,  ..., -0.0415,  0.0000,  0.0997],\n",
      "         [-0.0000,  0.0000, -0.7200,  ...,  0.0000,  0.0000, -0.0000],\n",
      "         [-0.0000, -2.0752, -0.6003,  ..., -0.0000, -0.6328,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000, -0.0000, -0.6170,  ..., -3.5027,  0.0541, -0.0000],\n",
      "         [-0.1145, -0.1198,  0.6133,  ..., -0.6853,  0.0000,  0.2222],\n",
      "         [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.7041,  0.0132]],\n",
      "\n",
      "        [[-0.0000, -0.0000,  0.0000,  ..., -6.5493, -0.2266, -0.0000],\n",
      "         [ 0.3428,  0.0000, -1.2279,  ...,  0.0000, -0.0000, -0.0000],\n",
      "         [-0.0000,  0.0000, -0.7351,  ..., -0.2767, -0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.1714,  0.4062, -0.1403,  ...,  0.8070,  0.3946, -0.0000],\n",
      "         [-0.8689,  0.2627,  0.0000,  ...,  0.0000,  0.0000,  3.2045],\n",
      "         [-0.0000,  0.0000, -0.6169,  ..., -0.0000,  0.0000,  0.5481]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[ 3.4626, -0.0000, -0.2402,  ..., -0.5221, -0.0000, -0.0000],\n",
      "        [-3.7824, -0.0000, -0.0000,  ...,  0.0000,  0.5352,  0.5080],\n",
      "        [-0.6795, -0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.6502],\n",
      "        ...,\n",
      "        [-0.0000,  0.1747, -0.0000,  ..., -0.0106,  0.0000,  0.0000],\n",
      "        [-0.0000,  4.9580,  0.0229,  ..., -0.0000, -0.7041,  0.0132],\n",
      "        [-0.0000, -0.0000,  0.0000,  ..., -0.0000,  0.0000,  0.5481]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-1.7033, -0.1152, -4.0243,  ...,  0.0806, -1.5733,  0.0000],\n",
      "         [-0.0000, -0.0326, -0.0000,  ...,  0.3441,  0.0000, -0.0000],\n",
      "         [-0.0000,  5.1600, -3.1503,  ...,  0.1316,  0.0000,  0.5981],\n",
      "         ...,\n",
      "         [-0.0000,  4.4338, -1.7897,  ...,  0.0000, -2.2758, -3.2175],\n",
      "         [-0.0000,  0.7321, -0.0000,  ...,  0.0000,  0.5999, -0.2382],\n",
      "         [-0.0000,  0.0000, -0.0000,  ...,  0.6480,  0.0000, -0.2272]],\n",
      "\n",
      "        [[ 0.0000,  0.0000, -0.0000,  ...,  0.5746,  0.0000,  0.4086],\n",
      "         [-0.0000,  0.0000, -0.0000,  ..., -0.7939, -0.5891,  1.8861],\n",
      "         [ 0.0000, -0.3843, -0.0000,  ...,  0.0703,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.7657,  0.0000, -0.0000,  ...,  0.0000, -0.0000, -0.2378],\n",
      "         [-0.0000, -0.1503, -0.3504,  ..., -0.0000, -0.3978, -0.2252],\n",
      "         [ 1.8167, -0.0000, -0.0000,  ..., -0.0000,  0.1581, -0.0000]],\n",
      "\n",
      "        [[ 0.0000, -0.0000, -0.0000,  ..., -4.7737,  1.4056,  0.0777],\n",
      "         [-0.0000,  0.2502, -0.1310,  ...,  0.3513,  0.3727, -0.0000],\n",
      "         [ 0.8613, -0.0000, -0.0000,  ...,  0.6146, -2.5530, -0.1504],\n",
      "         ...,\n",
      "         [-0.6418, -0.0000,  5.1840,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [-1.2646,  0.3413, -0.0000,  ...,  0.2212,  0.3590,  0.0000],\n",
      "         [-0.8740, -0.0000, -0.0000,  ..., -0.9866, -0.0000, -1.4091]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000, -0.0000, -0.0000,  ..., -0.1838, -0.0000,  2.8811],\n",
      "         [-0.4106,  0.0000,  2.3232,  ...,  0.0000, -0.2998,  0.0000],\n",
      "         [-2.4875, -0.0000, -0.0000,  ...,  2.4586,  0.0000, -1.1754],\n",
      "         ...,\n",
      "         [-0.7699,  0.5244, -0.0000,  ...,  0.1536,  0.6279,  0.0000],\n",
      "         [ 0.0000, -0.2319, -0.5215,  ...,  1.4485, -0.0000, -0.0000],\n",
      "         [-1.0282, -1.7338, -0.0000,  ..., -1.7409,  0.1509,  0.5355]],\n",
      "\n",
      "        [[-0.0000, -0.0000, -0.0000,  ..., -0.0952, -0.0000,  0.0890],\n",
      "         [-0.0000,  0.0000, -0.0000,  ..., -4.5489, -0.0000, -1.1910],\n",
      "         [ 0.0000, -0.0000, -0.6535,  ...,  0.0000, -0.0559, -0.0210],\n",
      "         ...,\n",
      "         [-0.0000,  0.0000, -0.1504,  ..., -0.0000,  0.7718,  0.0000],\n",
      "         [-0.0000, -2.2286, -0.0000,  ..., -0.2956,  0.0000, -0.0000],\n",
      "         [-2.6457,  0.1243,  0.0000,  ..., -0.2379, -0.0000, -3.1192]],\n",
      "\n",
      "        [[ 2.9785, -0.1881, -0.0000,  ...,  3.7023, -0.0000, -0.4863],\n",
      "         [-0.5061,  0.0000, -2.2928,  ...,  0.7553,  0.5090,  0.0000],\n",
      "         [-0.0000, -0.0000, -0.0000,  ...,  0.0000,  0.1715,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000, -0.0000,  4.1311,  ..., -0.2915, -0.2251, -0.5098],\n",
      "         [-3.6463,  1.3572, -0.6486,  ..., -0.0000,  0.0000, -0.0000],\n",
      "         [-0.0000, -0.0000,  0.1682,  ..., -1.0650,  0.0000,  1.0760]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-1.7033, -0.1152, -4.0243,  ...,  0.6480,  0.0000, -0.2272],\n",
      "        [ 0.0000,  0.0000, -0.0000,  ..., -0.0000,  0.1581, -0.0000],\n",
      "        [ 0.0000, -0.0000, -0.0000,  ..., -0.9866, -0.0000, -1.4091],\n",
      "        ...,\n",
      "        [-0.0000, -0.0000, -0.0000,  ..., -1.7409,  0.1509,  0.5355],\n",
      "        [-0.0000, -0.0000, -0.0000,  ..., -0.2379, -0.0000, -3.1192],\n",
      "        [ 2.9785, -0.1881, -0.0000,  ..., -1.0650,  0.0000,  1.0760]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-6.1418e-01,  2.3052e-01,  3.8099e-01,  ..., -0.0000e+00,\n",
      "          -1.5954e-01,  3.9599e-01],\n",
      "         [ 7.9587e-01,  0.0000e+00,  1.5244e-02,  ...,  3.5150e-01,\n",
      "           1.6468e+00,  0.0000e+00],\n",
      "         [-7.4195e-01,  3.8320e+00, -1.1864e-02,  ...,  0.0000e+00,\n",
      "          -3.8886e-01,  3.7596e+00],\n",
      "         ...,\n",
      "         [-7.7871e-01,  7.1486e-01, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00, -3.6885e-01],\n",
      "         [ 1.3231e+00,  0.0000e+00,  2.2095e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -7.3964e-01],\n",
      "         [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -3.9656e-01,\n",
      "           0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "        [[-4.8383e+00, -0.0000e+00, -9.8684e-01,  ...,  0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [-0.0000e+00,  4.4032e+00, -2.6780e-01,  ...,  0.0000e+00,\n",
      "          -8.7049e-01,  0.0000e+00],\n",
      "         [-4.6544e-01,  2.5289e-02, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -2.3962e-01,  4.9449e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00,  1.0132e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [-1.1708e+00,  3.8694e+00, -2.5103e+00,  ...,  1.5228e+00,\n",
      "           7.6103e-01, -0.0000e+00],\n",
      "         [-2.0201e+00,  0.0000e+00,  1.2361e-01,  ...,  8.7650e-02,\n",
      "          -1.0677e+00, -1.1742e+00]],\n",
      "\n",
      "        [[-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           5.4716e+00,  0.0000e+00],\n",
      "         [-5.1506e-01, -2.1546e-01, -2.3780e+00,  ..., -3.7145e-02,\n",
      "          -0.0000e+00,  2.8975e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00,  0.0000e+00, -8.6889e-01,  ..., -1.8198e+00,\n",
      "          -3.7072e-01, -0.0000e+00],\n",
      "         [-0.0000e+00,  9.5832e-02,  0.0000e+00,  ...,  2.3303e-01,\n",
      "           4.6443e-01,  9.3987e-02],\n",
      "         [ 3.9420e+00,  2.0027e+00, -1.3770e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -2.5286e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.8168e-01, -1.2967e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           2.6387e-01, -0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -9.7131e-02,\n",
      "           7.3979e-01,  9.1992e-03],\n",
      "         [-6.0644e-01, -3.8290e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 3.7605e+00, -1.1187e-01, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -3.3219e-01, -0.0000e+00],\n",
      "         [-6.4437e-01, -2.1793e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -4.3937e-01, -1.8890e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -6.8351e-02,  ..., -0.0000e+00,\n",
      "           1.8254e+00,  1.0814e+00]],\n",
      "\n",
      "        [[-3.9742e-01, -2.3138e+00, -3.1780e-01,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00,  3.5712e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -6.9314e-02,\n",
      "           4.6837e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [-4.6827e-01,  1.6644e-01, -2.4775e-01,  ...,  0.0000e+00,\n",
      "          -5.2761e-01, -5.8441e-01],\n",
      "         [-6.5193e-01, -4.0540e-01, -5.2701e-02,  ..., -0.0000e+00,\n",
      "           1.0008e-01, -1.4240e-01],\n",
      "         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           2.7853e-01, -1.4386e+00]],\n",
      "\n",
      "        [[-3.8139e+00,  0.0000e+00, -1.7462e+00,  ...,  1.6640e+00,\n",
      "           5.4931e-01, -1.4633e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -4.7398e+00,  ..., -4.3673e-01,\n",
      "           0.0000e+00,  2.9149e-01],\n",
      "         [-7.9047e-01,  6.0246e-01, -0.0000e+00,  ..., -4.8942e-01,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [-2.1230e-01,  1.7956e+00, -0.0000e+00,  ..., -1.4214e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [-1.0496e+00,  2.0760e+00, -0.0000e+00,  ...,  1.6437e+00,\n",
      "           1.1487e+00,  3.7669e+00],\n",
      "         [ 4.9889e+00, -2.3753e-01, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -1.0634e-03, -0.0000e+00]]], grad_fn=<MulBackward0>)\n",
      "tensor([[-6.1418e-01,  2.3052e-01,  3.8099e-01,  ..., -3.9656e-01,\n",
      "          0.0000e+00, -0.0000e+00],\n",
      "        [-4.8383e+00, -0.0000e+00, -9.8684e-01,  ...,  8.7650e-02,\n",
      "         -1.0677e+00, -1.1742e+00],\n",
      "        [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "         -0.0000e+00, -2.5286e-01],\n",
      "        ...,\n",
      "        [-3.8168e-01, -1.2967e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "          1.8254e+00,  1.0814e+00],\n",
      "        [-3.9742e-01, -2.3138e+00, -3.1780e-01,  ..., -0.0000e+00,\n",
      "          2.7853e-01, -1.4386e+00],\n",
      "        [-3.8139e+00,  0.0000e+00, -1.7462e+00,  ...,  0.0000e+00,\n",
      "         -1.0634e-03, -0.0000e+00]], grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.0000, -0.0000, -0.3990,  ...,  0.0000, -6.1070,  0.1373],\n",
      "         [-0.0000,  0.3577, -0.0000,  ..., -0.0000,  0.4894, -0.1655],\n",
      "         [-1.4538,  2.5551, -2.3632,  ...,  0.1553,  0.0605, -0.0181],\n",
      "         ...,\n",
      "         [-0.0000, -3.9104, -0.2660,  ..., -0.2154, -0.0000, -0.0000],\n",
      "         [-2.5493, -0.0000, -0.9847,  ..., -0.9430,  0.7204,  0.0000],\n",
      "         [-0.0000, -0.0000,  4.4131,  ..., -0.0000, -1.6175, -0.0000]],\n",
      "\n",
      "        [[-0.0000, -0.0000, -0.0000,  ...,  3.3107,  3.1260,  0.0000],\n",
      "         [-0.0000,  0.0000,  0.5167,  ...,  0.0000, -0.2938, -0.0000],\n",
      "         [-0.0000,  0.0000,  0.0415,  ...,  0.2311,  3.3910, -4.5509],\n",
      "         ...,\n",
      "         [ 0.0508,  0.3175, -0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "         [-5.2463, -0.0000,  0.0000,  ..., -0.3826,  0.0000, -0.0000],\n",
      "         [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0849,  0.0000]],\n",
      "\n",
      "        [[-0.0000, -0.4412, -0.0000,  ...,  0.0116, -0.0000, -0.0000],\n",
      "         [-3.4573,  0.0000, -0.0000,  ...,  0.0550, -0.5557,  0.0000],\n",
      "         [-1.3383, -1.4261,  0.0000,  ...,  0.2614, -4.3324,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000,  0.0000,  0.0000,  ..., -5.4234,  0.0000,  0.0000],\n",
      "         [-0.0000,  0.1749, -0.0000,  ..., -0.0884,  0.3000,  3.0955],\n",
      "         [-2.4444, -0.0000,  3.4477,  ...,  0.0110, -0.8363, -0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0000, -1.4057, -0.0000,  ..., -0.4921,  0.2334,  0.0000],\n",
      "         [-0.0000,  0.0000, -0.7542,  ..., -0.6255, -0.0000, -0.5206],\n",
      "         [-0.3907, -0.1560, -0.0000,  ..., -0.1947, -0.0000, -0.7012],\n",
      "         ...,\n",
      "         [-0.0000, -0.0000, -0.7371,  ..., -0.0000,  0.1197, -0.0000],\n",
      "         [-0.0000, -0.0000, -0.9058,  ...,  0.0000,  0.0000,  3.9799],\n",
      "         [-0.0000, -0.6303, -0.8170,  ..., -0.0000, -0.0339, -0.0000]],\n",
      "\n",
      "        [[-0.0000,  0.0000, -3.1347,  ...,  0.4624, -0.0000,  2.5956],\n",
      "         [-0.7068,  1.0920, -0.0000,  ...,  0.2117,  0.1897,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0000,  ..., -0.0000, -1.4886, -0.0000],\n",
      "         ...,\n",
      "         [-2.2616,  1.6534, -0.5909,  ...,  0.0484, -0.0000, -2.6989],\n",
      "         [-0.0000,  2.0845, -1.1964,  ...,  2.1493,  0.0786, -0.0000],\n",
      "         [-0.1300,  0.0000, -1.4013,  ..., -0.0000, -0.7539, -0.0000]],\n",
      "\n",
      "        [[-2.4114, -0.0000, -0.0000,  ...,  0.0000,  3.7520, -0.0000],\n",
      "         [-0.7282, -3.3400, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "         [-2.9132,  0.2891,  2.1681,  ..., -0.0000, -1.6344,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000, -5.9744,  0.0000,  ...,  0.1063,  0.6933,  0.0000],\n",
      "         [-0.0000, -0.1224,  0.1668,  ...,  0.0000, -0.0000, -0.0000],\n",
      "         [-0.4309, -3.7940,  2.6732,  ..., -0.0000, -0.0000, -0.2133]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-0.0000, -0.0000, -0.3990,  ..., -0.0000, -1.6175, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0849,  0.0000],\n",
      "        [-0.0000, -0.4412, -0.0000,  ...,  0.0110, -0.8363, -0.0000],\n",
      "        ...,\n",
      "        [ 0.0000, -1.4057, -0.0000,  ..., -0.0000, -0.0339, -0.0000],\n",
      "        [-0.0000,  0.0000, -3.1347,  ..., -0.0000, -0.7539, -0.0000],\n",
      "        [-2.4114, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.2133]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.0000e+00,  8.3193e-01,  0.0000e+00,  ...,  6.8820e-01,\n",
      "          -0.0000e+00, -2.5589e+00],\n",
      "         [-1.6763e+00,  3.9175e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [-0.0000e+00,  2.0769e+00, -1.9621e+00,  ..., -8.7634e-02,\n",
      "          -6.5449e-01,  0.0000e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00,  8.5783e-01, -7.1008e-02,  ..., -0.0000e+00,\n",
      "           2.2303e-01, -6.0565e-01],\n",
      "         [-4.0415e-01, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -2.7297e-01,  0.0000e+00],\n",
      "         [-1.7738e+00, -5.1890e-01, -7.6754e-01,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "        [[-6.8462e-01, -0.0000e+00, -4.8551e-01,  ..., -5.5129e+00,\n",
      "           4.4594e+00,  9.4726e-01],\n",
      "         [-8.0142e-01, -2.8399e+00,  6.1385e-01,  ...,  8.9031e-01,\n",
      "           1.2172e+00, -2.9597e+00],\n",
      "         [-0.0000e+00, -0.0000e+00,  2.0378e+00,  ...,  7.7760e-01,\n",
      "          -9.4057e-01, -9.3417e-01],\n",
      "         ...,\n",
      "         [-4.9786e+00, -0.0000e+00,  2.9142e+00,  ...,  0.0000e+00,\n",
      "          -1.1957e-01, -3.0210e-01],\n",
      "         [-5.4611e-01, -0.0000e+00, -1.0527e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [-2.1404e+00, -0.0000e+00,  0.0000e+00,  ..., -6.2701e-01,\n",
      "           0.0000e+00,  3.4835e-01]],\n",
      "\n",
      "        [[-0.0000e+00, -4.2339e+00,  2.8593e-01,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-0.0000e+00,  2.8537e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  7.4852e-01],\n",
      "         [-1.0088e+00,  1.9282e+00, -9.1209e-01,  ...,  0.0000e+00,\n",
      "          -0.0000e+00, -3.2696e-01],\n",
      "         ...,\n",
      "         [-2.5953e-01,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           5.5725e-01,  1.1230e+00],\n",
      "         [-1.2627e+00,  1.6103e+00,  7.8715e-01,  ..., -2.9730e+00,\n",
      "          -4.2949e+00,  0.0000e+00],\n",
      "         [ 2.2408e+00, -0.0000e+00, -0.0000e+00,  ...,  1.6753e+00,\n",
      "          -4.2499e-02, -9.6952e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000e+00,  1.4069e-01, -0.0000e+00,  ..., -4.8385e-01,\n",
      "           0.0000e+00,  1.8132e-01],\n",
      "         [-0.0000e+00,  4.9469e-01,  3.6235e-01,  ..., -4.8709e+00,\n",
      "           9.4449e-01,  1.5271e-03],\n",
      "         [-0.0000e+00,  5.2467e-01, -8.6061e-01,  ..., -4.5634e-01,\n",
      "          -2.6253e+00, -4.5268e-03],\n",
      "         ...,\n",
      "         [-0.0000e+00,  0.0000e+00, -4.9982e+00,  ..., -5.2016e-01,\n",
      "          -2.2225e-01, -0.0000e+00],\n",
      "         [ 4.8711e-01, -7.8039e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           1.9073e-01, -0.0000e+00],\n",
      "         [-0.0000e+00, -7.0769e-02, -4.1810e-01,  ..., -6.9234e-02,\n",
      "           1.1649e+00,  2.1359e+00]],\n",
      "\n",
      "        [[-2.0302e+00,  3.9627e+00,  1.9967e-01,  ..., -3.3009e-01,\n",
      "          -1.0386e+00, -7.4601e-01],\n",
      "         [-0.0000e+00, -0.0000e+00, -8.8975e-01,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  7.1128e-01],\n",
      "         [-1.3349e-01,  0.0000e+00, -0.0000e+00,  ..., -4.7036e-01,\n",
      "          -8.4607e-01,  0.0000e+00],\n",
      "         ...,\n",
      "         [-2.2732e+00, -6.3279e-01,  0.0000e+00,  ..., -0.0000e+00,\n",
      "           2.9161e-01,  0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -7.4520e-01,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 3.5457e+00, -0.0000e+00, -0.0000e+00,  ..., -8.9296e-02,\n",
      "          -5.1795e-01, -0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00, -1.7319e-01, -0.0000e+00,  ...,  2.0549e-01,\n",
      "          -0.0000e+00,  5.0031e-01],\n",
      "         [-0.0000e+00, -0.0000e+00, -7.4032e-01,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00,  7.1452e-01, -0.0000e+00,  ..., -5.5878e+00,\n",
      "           7.4268e-01, -3.4474e+00],\n",
      "         ...,\n",
      "         [-1.7288e-01, -4.3809e-01,  0.0000e+00,  ...,  4.3637e-01,\n",
      "          -8.1967e-01,  6.8298e+00],\n",
      "         [-1.9357e+00,  0.0000e+00,  4.3255e+00,  ..., -0.0000e+00,\n",
      "           1.5087e+00,  8.3027e-01],\n",
      "         [-4.2923e-01, -5.2109e-02, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -3.6815e+00]]], grad_fn=<MulBackward0>)\n",
      "tensor([[-0.0000,  0.8319,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [-0.6846, -0.0000, -0.4855,  ..., -0.6270,  0.0000,  0.3484],\n",
      "        [-0.0000, -4.2339,  0.2859,  ...,  1.6753, -0.0425, -0.9695],\n",
      "        ...,\n",
      "        [-0.0000,  0.1407, -0.0000,  ..., -0.0692,  1.1649,  2.1359],\n",
      "        [-2.0302,  3.9627,  0.1997,  ..., -0.0893, -0.5180, -0.0000],\n",
      "        [ 0.0000, -0.1732, -0.0000,  ..., -0.0000,  0.0000, -3.6815]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[ 0.0000,  1.9570, -0.0000,  ..., -0.0000, -1.9162,  0.0000],\n",
      "         [-4.5375, -2.8968, -0.2579,  ..., -0.0806, -0.1435,  0.0000],\n",
      "         [-1.2665,  0.0000, -0.2537,  ..., -1.6785,  0.0000, -0.0000],\n",
      "         ...,\n",
      "         [-0.0000,  0.0000, -0.0000,  ..., -2.6651, -0.0000, -0.6815],\n",
      "         [ 0.0000, -0.0000, -0.0000,  ...,  0.0000, -0.0000, -0.2921],\n",
      "         [-0.1117,  1.4573, -1.4640,  ..., -0.0000, -0.0000, -3.1729]],\n",
      "\n",
      "        [[ 0.0000, -0.0000, -0.4465,  ...,  1.3015, -0.2039,  1.5360],\n",
      "         [-0.1529,  3.4474, -0.0000,  ...,  0.0000,  0.1707,  1.8478],\n",
      "         [-0.0000,  1.1665, -0.0000,  ..., -0.0000, -0.0000, -0.0869],\n",
      "         ...,\n",
      "         [-2.8194,  4.5224, -0.0000,  ..., -1.0861, -0.9906, -0.0000],\n",
      "         [-0.0000,  2.0391, -1.6666,  ...,  0.1561,  0.3679,  0.0000],\n",
      "         [-0.3537,  0.6168,  0.0000,  ..., -0.0000,  0.0000,  0.3352]],\n",
      "\n",
      "        [[-0.0000,  0.0508, -0.0000,  ..., -0.2984, -0.1073,  0.0000],\n",
      "         [-0.0000,  6.3287, -0.0000,  ..., -0.2984,  0.0000, -0.8626],\n",
      "         [-2.7912,  0.0000, -0.3988,  ..., -0.0000,  0.0000, -0.0000],\n",
      "         ...,\n",
      "         [-0.3970,  0.0499, -0.4247,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [-0.0000,  1.9386,  0.0000,  ..., -0.2272,  0.0000,  0.0000],\n",
      "         [-1.6327, -0.0000, -0.0000,  ..., -1.5854,  0.3880, -0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000, -0.1149, -0.0000,  ..., -0.0000,  1.3928, -0.7404],\n",
      "         [ 0.0000,  0.3296, -0.0000,  ..., -0.1219,  0.0000,  0.0000],\n",
      "         [ 5.1616, -0.7240,  1.7888,  ...,  0.1225,  0.0682,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000,  0.0000, -0.2140,  ..., -0.0000, -0.0000,  0.0000],\n",
      "         [ 0.0000, -0.0000,  0.7706,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0903,  0.0000, -0.7249,  ...,  1.9786, -2.8953,  0.0000]],\n",
      "\n",
      "        [[-0.0000,  0.0000, -0.0000,  ..., -0.3398, -0.0000,  0.0000],\n",
      "         [-0.0000,  0.0000, -0.0000,  ..., -0.0000, -0.0000,  1.5935],\n",
      "         [-4.1769, -0.0000, -0.0000,  ...,  0.0000, -1.2900, -0.0822],\n",
      "         ...,\n",
      "         [-0.0000, -4.4830,  0.0000,  ..., -0.0597, -0.0000,  0.0000],\n",
      "         [-0.0000,  0.0000, -1.2297,  ..., -0.0000,  0.0000,  0.1512],\n",
      "         [ 0.0000, -1.6214, -0.6484,  ..., -0.0994,  0.0000,  3.2971]],\n",
      "\n",
      "        [[-1.2882,  0.0000, -0.1655,  ...,  0.0255, -0.6517, -0.0000],\n",
      "         [-0.0000,  3.8813, -0.3254,  ..., -0.0000, -0.0000, -0.7153],\n",
      "         [-0.2575,  0.3315, -0.0000,  ..., -0.0000, -0.4931, -0.3643],\n",
      "         ...,\n",
      "         [ 0.0000, -0.0000,  0.0683,  ..., -1.1035,  0.0000, -0.0000],\n",
      "         [-0.0000, -0.0000, -0.5909,  ..., -0.3962, -1.4969, -0.0000],\n",
      "         [-0.0000,  0.7532, -0.0000,  ...,  0.4471,  0.0000, -1.9907]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[ 0.0000,  1.9570, -0.0000,  ..., -0.0000, -0.0000, -3.1729],\n",
      "        [ 0.0000, -0.0000, -0.4465,  ..., -0.0000,  0.0000,  0.3352],\n",
      "        [-0.0000,  0.0508, -0.0000,  ..., -1.5854,  0.3880, -0.0000],\n",
      "        ...,\n",
      "        [-0.0000, -0.1149, -0.0000,  ...,  1.9786, -2.8953,  0.0000],\n",
      "        [-0.0000,  0.0000, -0.0000,  ..., -0.0994,  0.0000,  3.2971],\n",
      "        [-1.2882,  0.0000, -0.1655,  ...,  0.4471,  0.0000, -1.9907]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.0000, -0.0000, -0.6668,  ..., -0.0000,  0.0000,  0.1428],\n",
      "         [ 0.0000,  4.6124, -0.0000,  ..., -0.0419, -0.5968,  0.2594],\n",
      "         [-0.0000,  6.4973, -0.0000,  ...,  1.2029, -0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000, -0.7969, -1.0519,  ...,  0.0000, -0.5198, -0.0000],\n",
      "         [ 1.4933, -0.5742, -1.1933,  ...,  3.1328, -0.0000,  0.0000],\n",
      "         [-0.0000, -0.3462, -0.5691,  ...,  0.0000,  5.2800,  0.0000]],\n",
      "\n",
      "        [[-0.0000,  0.2819, -0.4531,  ...,  0.0000, -0.0000,  1.6251],\n",
      "         [-2.0008, -0.2281, -0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "         [-1.2636,  1.8300,  0.0000,  ...,  0.2961, -0.3949, -0.0000],\n",
      "         ...,\n",
      "         [ 0.5713, -0.0000,  0.4024,  ..., -0.0000,  0.0000,  1.6248],\n",
      "         [-0.7342,  0.4758,  0.0633,  ..., -0.0000,  0.2173,  0.0000],\n",
      "         [-0.0000,  2.6102, -0.0000,  ..., -0.0000, -0.0000, -2.3985]],\n",
      "\n",
      "        [[-0.0000, -0.0000,  3.4216,  ..., -1.0240,  3.3550, -0.3931],\n",
      "         [-0.0000, -0.0000, -0.6021,  ..., -0.0000,  1.9982,  0.0000],\n",
      "         [-0.0000, -0.0000, -0.0000,  ...,  1.0452,  0.0424,  0.5199],\n",
      "         ...,\n",
      "         [-0.0000, -0.1327,  0.0000,  ..., -0.0000,  0.0000, -3.1416],\n",
      "         [-0.0000, -0.3422, -0.5878,  ..., -0.2626, -0.0000, -0.8737],\n",
      "         [-0.0000,  0.5742, -0.0000,  ...,  0.0000,  0.0000, -1.6052]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.5511, -0.2609, -0.0000,  ..., -0.0000, -0.4522, -0.0000],\n",
      "         [-0.0000, -1.5503, -0.0000,  ...,  0.4818,  1.8287, -0.7831],\n",
      "         [-0.0000,  0.0000, -0.0000,  ...,  0.0000, -4.0433,  0.0637],\n",
      "         ...,\n",
      "         [-0.0000,  0.0000, -0.5488,  ..., -0.0000, -0.0000, -2.0505],\n",
      "         [-0.0000,  0.0000, -1.1670,  ...,  0.2018,  0.0000,  0.0000],\n",
      "         [ 0.0000, -1.7796, -1.8354,  ..., -0.0941, -0.6592, -0.3040]],\n",
      "\n",
      "        [[-0.4510,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.3625],\n",
      "         [-0.0430,  0.0000, -0.2034,  ...,  0.7832,  0.0000,  0.0000],\n",
      "         [-0.0000,  0.0000,  0.9070,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "         [ 0.8562,  0.0000, -0.0690,  ...,  0.1127,  0.0000,  0.0000],\n",
      "         [-0.0000, -0.0000,  0.0000,  ..., -0.0000, -1.7583, -1.4681]],\n",
      "\n",
      "        [[ 0.0000, -0.0000,  0.0000,  ..., -0.2871, -0.0000, -0.0000],\n",
      "         [-0.0000,  0.2540, -0.0000,  ..., -0.0472,  1.0838,  0.0102],\n",
      "         [-0.0000,  0.0000, -0.4254,  ...,  0.0092,  0.0000, -0.0000],\n",
      "         ...,\n",
      "         [ 3.9697, -0.0000, -0.6649,  ..., -0.0000, -0.0000, -2.3139],\n",
      "         [-0.0000,  0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "         [-0.0000, -0.0000,  4.0090,  ..., -0.6405, -0.1041, -0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-0.0000, -0.0000, -0.6668,  ...,  0.0000,  5.2800,  0.0000],\n",
      "        [-0.0000,  0.2819, -0.4531,  ..., -0.0000, -0.0000, -2.3985],\n",
      "        [-0.0000, -0.0000,  3.4216,  ...,  0.0000,  0.0000, -1.6052],\n",
      "        ...,\n",
      "        [-2.5511, -0.2609, -0.0000,  ..., -0.0941, -0.6592, -0.3040],\n",
      "        [-0.4510,  0.0000,  0.0000,  ..., -0.0000, -1.7583, -1.4681],\n",
      "        [ 0.0000, -0.0000,  0.0000,  ..., -0.6405, -0.1041, -0.0000]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.0000e+00,  3.6599e-01, -0.0000e+00,  ...,  2.8429e+00,\n",
      "          -0.0000e+00,  2.1089e+00],\n",
      "         [ 1.5587e+00, -0.0000e+00, -6.5188e-01,  ...,  3.8136e+00,\n",
      "           1.1252e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00, -0.0000e+00, -1.4242e-01,  ...,  0.0000e+00,\n",
      "           7.6284e-01, -0.0000e+00],\n",
      "         ...,\n",
      "         [-1.2141e+00, -0.0000e+00, -4.6390e-01,  ..., -9.0854e-01,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [-3.6267e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          -1.0446e-01,  0.0000e+00],\n",
      "         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -1.9302e+00,\n",
      "          -0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.4336e+00,  2.1281e+00,  0.0000e+00,  ...,  9.2133e-01,\n",
      "          -1.0740e+00, -6.0607e-01],\n",
      "         [-0.0000e+00,  2.6824e+00, -2.4853e+00,  ...,  8.7856e-01,\n",
      "          -1.1543e+00,  0.0000e+00],\n",
      "         [-3.6558e+00, -0.0000e+00, -7.3056e-01,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  1.0329e+00],\n",
      "         ...,\n",
      "         [-4.7669e-01, -0.0000e+00,  4.0849e-01,  ...,  0.0000e+00,\n",
      "           1.9820e+00, -2.1078e-01],\n",
      "         [-0.0000e+00,  6.2385e-02, -0.0000e+00,  ...,  5.1207e-02,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 2.3831e+00, -1.2394e+00,  3.3987e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -3.0966e-01]],\n",
      "\n",
      "        [[-6.7432e-02,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00, -3.3314e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  2.0889e-01],\n",
      "         [-0.0000e+00, -0.0000e+00, -4.9651e-01,  ..., -1.6059e+00,\n",
      "          -2.2214e-01, -0.0000e+00],\n",
      "         ...,\n",
      "         [-1.8828e+00, -1.8175e+00, -6.5747e-01,  ...,  0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -3.5369e-01,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [-7.1406e+00,  0.0000e+00,  0.0000e+00,  ...,  9.7105e-02,\n",
      "           2.1798e-01,  7.3371e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.3384e-01, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  4.4867e+00],\n",
      "         [-0.0000e+00, -1.3339e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [ 0.0000e+00, -0.0000e+00, -4.4711e+00,  ...,  3.1212e-03,\n",
      "          -0.0000e+00,  1.4509e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -8.4843e-01, -5.9039e-01,  ...,  0.0000e+00,\n",
      "          -0.0000e+00, -6.6298e-01],\n",
      "         [ 3.4508e-01, -0.0000e+00, -2.1462e-01,  ..., -4.8179e-01,\n",
      "           0.0000e+00,  4.9262e-01],\n",
      "         [-0.0000e+00,  1.8449e-01, -0.0000e+00,  ...,  5.3821e-01,\n",
      "          -0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-0.0000e+00, -0.0000e+00, -7.5490e-01,  ...,  0.0000e+00,\n",
      "          -0.0000e+00, -6.8339e-01],\n",
      "         [ 0.0000e+00,  1.3884e+00, -8.6050e-01,  ..., -4.0365e-01,\n",
      "          -0.0000e+00, -3.8638e-01],\n",
      "         [ 4.6526e+00,  0.0000e+00,  3.4752e+00,  ..., -1.4283e+00,\n",
      "          -0.0000e+00, -2.8458e-01],\n",
      "         ...,\n",
      "         [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -5.1066e-01,\n",
      "           0.0000e+00, -1.9240e+00],\n",
      "         [-0.0000e+00,  0.0000e+00,  2.8487e-01,  ...,  0.0000e+00,\n",
      "           8.5765e-01,  0.0000e+00],\n",
      "         [-0.0000e+00, -3.2109e-02, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-0.0000e+00,  0.0000e+00, -8.4900e-01,  ..., -4.3468e-01,\n",
      "          -1.3702e-01, -5.9419e+00],\n",
      "         [-8.1473e-01,  3.0166e-01,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          -1.7636e+00,  2.4635e-01],\n",
      "         [-8.1018e-01, -0.0000e+00,  3.5490e-01,  ..., -0.0000e+00,\n",
      "           1.2814e-01, -0.0000e+00],\n",
      "         ...,\n",
      "         [-3.1331e+00,  0.0000e+00,  1.3799e-01,  ..., -2.7514e-02,\n",
      "          -0.0000e+00,  2.6387e-01],\n",
      "         [-7.8040e-01, -1.3632e-01, -5.6601e-01,  ..., -0.0000e+00,\n",
      "          -1.0842e+00, -0.0000e+00],\n",
      "         [-5.9222e-01, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -2.9332e+00]]], grad_fn=<MulBackward0>)\n",
      "tensor([[-0.0000,  0.3660, -0.0000,  ..., -1.9302, -0.0000,  0.0000],\n",
      "        [-1.4336,  2.1281,  0.0000,  ..., -0.0000, -0.0000, -0.3097],\n",
      "        [-0.0674,  0.0000, -0.0000,  ...,  0.0971,  0.2180,  0.7337],\n",
      "        ...,\n",
      "        [ 0.7338, -0.0000, -0.0000,  ...,  0.5382, -0.0000,  0.0000],\n",
      "        [-0.0000, -0.0000, -0.7549,  ...,  0.0000, -0.0000,  0.0000],\n",
      "        [-0.0000,  0.0000, -0.8490,  ..., -0.0000,  0.0000, -2.9332]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-1.9428e+00, -0.0000e+00,  4.3349e+00,  ..., -0.0000e+00,\n",
      "          -1.0596e+00, -5.6874e-01],\n",
      "         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           1.4597e+00, -1.0073e-01],\n",
      "         [-1.7221e+00,  0.0000e+00,  2.5080e-01,  ...,  1.2109e-01,\n",
      "           1.5594e-01,  3.4656e-01],\n",
      "         ...,\n",
      "         [-9.7170e-01,  0.0000e+00,  4.1792e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00,  4.1628e-01, -1.3866e-01,  ...,  2.1426e-01,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 4.6622e+00,  0.0000e+00, -0.0000e+00,  ..., -2.7399e-01,\n",
      "           1.2094e+00, -0.0000e+00]],\n",
      "\n",
      "        [[-0.0000e+00, -5.0618e-01,  3.8486e+00,  ...,  0.0000e+00,\n",
      "          -0.0000e+00, -7.7281e-01],\n",
      "         [-0.0000e+00, -5.4940e-01, -0.0000e+00,  ...,  4.5827e-02,\n",
      "           0.0000e+00, -4.9077e+00],\n",
      "         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -0.0000e+00,  6.4170e-01],\n",
      "         ...,\n",
      "         [-1.1066e+00, -0.0000e+00, -0.0000e+00,  ..., -1.6926e-01,\n",
      "          -0.0000e+00, -1.0522e-01],\n",
      "         [-0.0000e+00, -3.6349e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [-4.9784e+00,  4.8183e-01, -5.2655e-01,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.4782e+00,  0.0000e+00,  0.0000e+00,  ...,  5.8447e-03,\n",
      "          -2.9965e-01, -6.9796e-01],\n",
      "         [ 1.7485e-01,  8.3476e-02, -0.0000e+00,  ...,  4.2687e+00,\n",
      "           0.0000e+00,  7.3685e-01],\n",
      "         [-6.4723e-02, -2.5183e+00,  2.3858e+00,  ..., -4.6240e+00,\n",
      "          -0.0000e+00,  1.7131e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00, -3.2180e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -7.2185e-01,  4.4847e-01],\n",
      "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  5.8059e-01,\n",
      "           0.0000e+00, -4.2293e-01],\n",
      "         [-0.0000e+00, -0.0000e+00, -1.5145e-01,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-4.1031e+00,  3.7340e+00, -1.0522e-04,  ..., -1.1237e-01,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [-2.5849e-01, -1.2532e-01,  0.0000e+00,  ..., -6.2021e-01,\n",
      "          -0.0000e+00,  1.4306e+00],\n",
      "         [-1.4929e+00, -0.0000e+00, -0.0000e+00,  ..., -6.5846e-01,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  5.0879e-01,\n",
      "          -4.4785e-01,  4.4624e-01],\n",
      "         [-4.8044e-01,  2.9617e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -1.0407e-01, -0.0000e+00],\n",
      "         [ 0.0000e+00, -0.0000e+00,  3.9600e-01,  ..., -8.2537e-01,\n",
      "           0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "        [[-0.0000e+00, -0.0000e+00, -1.9881e+00,  ..., -0.0000e+00,\n",
      "           4.6178e-01,  0.0000e+00],\n",
      "         [ 9.2190e-01,  0.0000e+00, -5.0953e+00,  ...,  4.5388e-01,\n",
      "           6.1161e+00,  0.0000e+00],\n",
      "         [-0.0000e+00,  1.7899e+00, -6.0689e-01,  ...,  8.9160e-02,\n",
      "           1.0404e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [-6.1339e-01,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -7.9029e-01],\n",
      "         [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.1328e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [ 0.0000e+00,  1.4473e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "        [[-5.8728e-01, -4.4648e-01, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00, -6.0021e-02,  3.8232e+00,  ..., -8.5545e-02,\n",
      "          -1.8668e-01,  0.0000e+00],\n",
      "         [-8.3113e-01,  1.4725e-01, -0.0000e+00,  ..., -5.0499e-01,\n",
      "          -3.3079e-02, -4.5005e-02],\n",
      "         ...,\n",
      "         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -4.9407e-01,\n",
      "           5.1563e-01, -0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  3.1737e-01,\n",
      "          -0.0000e+00, -1.0049e-01],\n",
      "         [-9.7327e-01, -6.1026e-01, -2.2589e+00,  ...,  6.4030e-02,\n",
      "          -5.3187e-01,  0.0000e+00]]], grad_fn=<MulBackward0>)\n",
      "tensor([[-1.9428e+00, -0.0000e+00,  4.3349e+00,  ..., -2.7399e-01,\n",
      "          1.2094e+00, -0.0000e+00],\n",
      "        [-0.0000e+00, -5.0618e-01,  3.8486e+00,  ..., -0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 2.4782e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [-4.1031e+00,  3.7340e+00, -1.0522e-04,  ..., -8.2537e-01,\n",
      "          0.0000e+00, -0.0000e+00],\n",
      "        [-0.0000e+00, -0.0000e+00, -1.9881e+00,  ..., -0.0000e+00,\n",
      "          0.0000e+00, -0.0000e+00],\n",
      "        [-5.8728e-01, -4.4648e-01, -0.0000e+00,  ...,  6.4030e-02,\n",
      "         -5.3187e-01,  0.0000e+00]], grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.5612,  1.4307, -2.6093,  ...,  0.0000,  0.8219,  0.0000],\n",
      "         [ 0.0000, -6.0342, -0.0000,  ...,  0.0000,  0.1752, -0.0000],\n",
      "         [-0.0000,  0.0000,  1.7954,  ...,  0.0000,  1.5778, -0.0000],\n",
      "         ...,\n",
      "         [-0.0000,  0.0000,  0.0000,  ..., -0.0265,  0.0000, -0.9816],\n",
      "         [-0.0000,  0.0000, -0.0000,  ...,  0.7349,  0.0000,  2.6061],\n",
      "         [ 1.4495, -0.0000, -0.0000,  ..., -0.4481, -0.0000, -0.0000]],\n",
      "\n",
      "        [[ 0.9954,  0.4413, -0.0000,  ...,  0.0000, -0.0000,  0.0602],\n",
      "         [-0.0000, -0.0000, -0.0000,  ...,  0.0000, -0.8824, -3.7896],\n",
      "         [-0.0000,  0.5742, -0.0000,  ...,  0.8441, -0.0000, -0.0000],\n",
      "         ...,\n",
      "         [ 0.0000, -4.4373, -0.0000,  ...,  0.0191,  0.0000, -0.3893],\n",
      "         [ 0.0000, -0.6023, -0.0000,  ..., -0.4931,  0.0000, -0.3825],\n",
      "         [ 0.1893, -0.0000,  0.0174,  ..., -0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "        [[-0.7089,  0.0000,  0.0000,  ..., -5.7091, -0.0000, -0.0000],\n",
      "         [-1.1495,  0.0000, -1.0899,  ...,  0.0000, -0.0000,  0.0000],\n",
      "         [-1.4298,  0.0000, -0.0000,  ...,  0.0171, -3.0408, -4.1009],\n",
      "         ...,\n",
      "         [-0.0000,  0.0000, -0.3898,  ..., -0.0000,  0.5816, -5.3936],\n",
      "         [-0.0811, -2.1899, -1.2197,  ...,  0.0000,  0.9858, -0.0000],\n",
      "         [-0.0000,  0.1501,  0.0000,  ...,  0.0000,  0.0000,  0.3175]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000, -0.0000, -0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-1.0609,  0.8057,  0.0000,  ..., -0.4070,  5.5232,  0.3770],\n",
      "         [-0.0000,  0.0000,  0.0842,  ...,  0.2959, -0.0000, -0.5481],\n",
      "         ...,\n",
      "         [ 0.0000,  3.4351, -0.0000,  ..., -0.0000, -0.6409, -0.8260],\n",
      "         [-0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 3.3267, -0.0000,  0.0000,  ..., -0.5476,  0.4905, -0.0999]],\n",
      "\n",
      "        [[ 0.0000,  0.7814,  0.0000,  ...,  0.0000,  0.0000, -6.4850],\n",
      "         [ 0.1455,  0.4796, -2.4555,  ...,  0.4768,  1.0490,  0.0000],\n",
      "         [-6.2533,  0.0000,  0.0000,  ...,  0.0000,  0.6529,  0.0000],\n",
      "         ...,\n",
      "         [ 1.3706,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.5243],\n",
      "         [ 7.3642,  0.0000, -0.0000,  ..., -0.0000,  0.0000, -0.4092],\n",
      "         [ 0.0000, -0.0000, -0.0000,  ...,  0.0000, -0.5023,  0.0000]],\n",
      "\n",
      "        [[-5.3067, -0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.2504],\n",
      "         [-0.6685,  4.2165, -0.0000,  ...,  0.3252, -0.1159, -0.0304],\n",
      "         [-0.0000, -0.9816,  0.1058,  ...,  0.5049, -5.5289,  0.7209],\n",
      "         ...,\n",
      "         [-2.1118,  0.0000,  0.2654,  ...,  0.3041,  0.0000, -0.4196],\n",
      "         [-6.6290,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0000,  0.9401,  0.0000,  ..., -0.0000, -1.0378,  0.1371]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-0.5612,  1.4307, -2.6093,  ..., -0.4481, -0.0000, -0.0000],\n",
      "        [ 0.9954,  0.4413, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [-0.7089,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.3175],\n",
      "        ...,\n",
      "        [-0.0000, -0.0000, -0.0000,  ..., -0.5476,  0.4905, -0.0999],\n",
      "        [ 0.0000,  0.7814,  0.0000,  ...,  0.0000, -0.5023,  0.0000],\n",
      "        [-5.3067, -0.0000, -0.0000,  ..., -0.0000, -1.0378,  0.1371]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.0000, -0.0000, -0.0000,  ...,  0.0000, -2.5446, -0.0000],\n",
      "         [-0.0000, -2.6045,  0.1976,  ..., -0.0271, -4.7964, -2.4309],\n",
      "         [-0.0000,  0.9923, -1.4160,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-1.7194, -1.5249, -2.2814,  ..., -0.3337, -0.0000, -0.0000],\n",
      "         [-0.5706,  3.2814, -0.0000,  ..., -0.0716, -0.1194,  0.0000],\n",
      "         [-0.5842, -0.0000, -0.0000,  ..., -0.0000,  0.1864,  0.2772]],\n",
      "\n",
      "        [[-0.0000, -0.3035,  0.0000,  ..., -0.0000, -1.0255,  4.4489],\n",
      "         [-0.0000,  1.9591, -1.2700,  ...,  0.1954,  0.0000, -4.7738],\n",
      "         [-1.1711, -0.0000, -0.9903,  ..., -0.5472, -0.4192, -0.0000],\n",
      "         ...,\n",
      "         [-0.0000,  0.0000, -0.0000,  ..., -1.2239,  0.6458, -2.1962],\n",
      "         [-0.0000,  0.0000, -0.0000,  ..., -0.0000, -1.4422,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "        [[-1.3622,  1.9083,  2.0868,  ..., -0.0000,  0.0000,  0.0000],\n",
      "         [-6.0483,  0.0000, -0.0000,  ...,  0.2707, -1.5771,  0.4924],\n",
      "         [-1.5003, -0.2596, -3.6755,  ..., -0.4662,  0.0000, -0.3547],\n",
      "         ...,\n",
      "         [ 0.1368, -0.2158, -0.0987,  ..., -0.3998, -0.0000, -0.0000],\n",
      "         [-0.0000, -0.1814, -0.0000,  ...,  0.1501,  0.0000,  3.5756],\n",
      "         [ 4.5269, -0.0000,  0.0000,  ..., -0.4004,  0.2262, -0.4579]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000,  0.0144,  0.0908,  ..., -0.0000,  0.6966, -0.3017],\n",
      "         [ 0.0000,  1.1813,  1.1150,  ..., -0.4677,  0.0000, -2.8409],\n",
      "         [-0.0000,  0.2853,  1.9939,  ..., -3.6406,  0.2341, -0.3482],\n",
      "         ...,\n",
      "         [ 0.0637,  0.0000, -0.3087,  ..., -0.2039,  0.0000,  0.9771],\n",
      "         [-6.5154,  0.6921,  2.3729,  ..., -0.0000, -0.2781, -0.0000],\n",
      "         [-0.0000, -0.0000, -1.0232,  ..., -2.2462, -3.1011, -0.4726]],\n",
      "\n",
      "        [[-0.0000,  0.0000, -0.0000,  ...,  5.3332,  0.3247,  0.5504],\n",
      "         [-1.1256,  0.0000, -0.2786,  ...,  0.0000,  3.1211,  2.1017],\n",
      "         [ 0.0000, -0.0000, -0.0000,  ..., -1.6666, -0.0000, -0.0000],\n",
      "         ...,\n",
      "         [-0.5322,  0.0000, -0.0000,  ...,  0.0000, -0.2190,  5.3142],\n",
      "         [ 0.2258, -0.0000, -0.0000,  ...,  0.0000,  1.0171,  0.0000],\n",
      "         [ 0.0000, -3.6751,  0.0000,  ..., -1.2622,  1.0175,  0.0000]],\n",
      "\n",
      "        [[-0.5775,  0.6471,  0.0000,  ...,  0.3530,  0.0000,  0.0418],\n",
      "         [ 0.5362, -0.0000, -1.2055,  ..., -0.1649,  0.6991,  0.3603],\n",
      "         [ 3.1658,  0.0000, -6.7853,  ..., -0.0690,  0.9687, -0.4157],\n",
      "         ...,\n",
      "         [-2.0189,  1.7592,  0.0000,  ..., -1.4320, -2.0725, -0.0000],\n",
      "         [ 0.3065,  0.0000, -0.0000,  ..., -0.0000,  0.0442,  0.9111],\n",
      "         [-0.0000,  0.0000,  5.8473,  ...,  0.2751, -0.0000, -0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.1864,  0.2772],\n",
      "        [-0.0000, -0.3035,  0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "        [-1.3622,  1.9083,  2.0868,  ..., -0.4004,  0.2262, -0.4579],\n",
      "        ...,\n",
      "        [-0.0000,  0.0144,  0.0908,  ..., -2.2462, -3.1011, -0.4726],\n",
      "        [-0.0000,  0.0000, -0.0000,  ..., -1.2622,  1.0175,  0.0000],\n",
      "        [-0.5775,  0.6471,  0.0000,  ...,  0.2751, -0.0000, -0.0000]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.0000, -0.3649, -0.0000,  ...,  2.6318, -0.5488,  1.3277],\n",
      "         [ 0.0000, -3.5382, -4.1073,  ..., -0.0000,  0.0000, -0.0000],\n",
      "         [-0.0000, -0.0000, -1.0246,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.8663, -0.1885, -1.7637,  ...,  0.0000, -0.0000, -0.0000],\n",
      "         [-0.9592,  2.7249, -0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0000,  1.9666, -2.8390,  ..., -0.0000,  0.0000, -5.1372]],\n",
      "\n",
      "        [[-0.0000,  0.0000, -0.4584,  ..., -0.0591, -0.0000,  1.3187],\n",
      "         [ 0.0000, -0.0000, -0.0000,  ...,  3.1977, -3.5547, -0.0000],\n",
      "         [-0.0000, -0.0000, -3.6270,  ...,  0.1671,  0.0000, -3.8418],\n",
      "         ...,\n",
      "         [-0.0000, -0.2777, -0.0000,  ..., -0.1555, -0.2614,  0.6701],\n",
      "         [-4.8326,  0.0000, -1.3922,  ..., -0.1208,  0.0000,  0.0000],\n",
      "         [ 2.7910, -3.8413, -1.1123,  ..., -0.0000, -0.0000, -3.0807]],\n",
      "\n",
      "        [[-0.2532, -1.3551,  0.0000,  ..., -0.0000,  0.5133, -0.0000],\n",
      "         [-0.9153,  0.1282,  0.0000,  ...,  0.0000, -0.1684, -0.6016],\n",
      "         [ 0.0000, -1.4940, -0.0000,  ..., -2.8035, -0.3843, -3.2757],\n",
      "         ...,\n",
      "         [-0.0000, -0.7307, -0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
      "         [-2.0379,  3.2347,  0.0000,  ...,  0.0000,  2.0163,  0.0000],\n",
      "         [-0.1991,  1.2130,  0.0000,  ...,  0.6979,  0.3622,  0.8378]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1818,  0.0000, -0.0000,  ...,  4.7927, -0.0000,  0.0000],\n",
      "         [-0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "         [-0.0000,  5.8812, -0.0000,  ..., -0.0000, -0.5895,  0.0000],\n",
      "         ...,\n",
      "         [-0.2344, -0.0000,  3.8369,  ...,  0.0708, -0.0000, -1.9521],\n",
      "         [-0.4197, -0.0687, -0.0000,  ...,  0.5609,  0.0000,  2.3662],\n",
      "         [-1.6584, -4.2641, -0.0000,  ..., -0.0000, -0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.0000, -0.2912, -0.1250,  ..., -0.0000,  3.1861,  0.0000],\n",
      "         [-1.6926, -0.0000, -0.0000,  ..., -0.0000,  0.4518, -0.0000],\n",
      "         [-0.9468, -0.1645,  0.0000,  ..., -0.0000, -0.0000, -2.6773],\n",
      "         ...,\n",
      "         [-0.0000, -0.0000, -1.6683,  ..., -0.0000, -0.0000, -2.1526],\n",
      "         [-0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000, -0.0784],\n",
      "         [-1.1170,  0.0000,  0.1701,  ..., -0.2674, -0.7491, -0.0000]],\n",
      "\n",
      "        [[ 3.6442,  0.0000, -0.0000,  ..., -0.2163, -0.0000,  0.0000],\n",
      "         [-1.3301,  4.0328, -0.0000,  ..., -0.0000,  0.0000, -1.1298],\n",
      "         [-0.0000,  0.0000, -0.0000,  ...,  1.5992, -0.0000,  0.6835],\n",
      "         ...,\n",
      "         [-0.5171, -0.0000, -0.0000,  ...,  0.0000, -0.0259, -0.0000],\n",
      "         [-0.0000,  0.0000, -0.8098,  ...,  0.0000, -0.0000,  0.0000],\n",
      "         [-0.0000, -0.3352, -0.7703,  ..., -0.0000,  0.1799, -0.3769]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-0.0000, -0.3649, -0.0000,  ..., -0.0000,  0.0000, -5.1372],\n",
      "        [-0.0000,  0.0000, -0.4584,  ..., -0.0000, -0.0000, -3.0807],\n",
      "        [-0.2532, -1.3551,  0.0000,  ...,  0.6979,  0.3622,  0.8378],\n",
      "        ...,\n",
      "        [ 0.1818,  0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "        [-0.0000, -0.2912, -0.1250,  ..., -0.2674, -0.7491, -0.0000],\n",
      "        [ 3.6442,  0.0000, -0.0000,  ..., -0.0000,  0.1799, -0.3769]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  6.0402e-01,\n",
      "          -8.4381e-02,  3.2415e-01],\n",
      "         [-0.0000e+00,  2.5997e-01, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -2.1614e-03,  2.9037e-01],\n",
      "         [-6.5188e-01,  5.4508e-02, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           4.8223e-01,  1.4828e+00],\n",
      "         ...,\n",
      "         [-3.8774e-01, -0.0000e+00, -9.8482e-01,  ..., -0.0000e+00,\n",
      "           1.0467e-01,  1.3244e-02],\n",
      "         [-0.0000e+00,  9.5142e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -3.6460e-01, -4.0117e-01],\n",
      "         [ 0.0000e+00,  1.1115e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00, -1.0796e+00]],\n",
      "\n",
      "        [[-0.0000e+00,  6.1942e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           2.2542e-01, -1.2004e-01],\n",
      "         [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.1699e+00,\n",
      "           0.0000e+00,  3.9485e-01],\n",
      "         [-0.0000e+00, -0.0000e+00,  2.0639e+00,  ..., -1.1059e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [-1.3414e+00,  0.0000e+00, -0.0000e+00,  ..., -1.4960e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-1.7917e+00,  0.0000e+00, -4.5932e-01,  ..., -2.0743e-01,\n",
      "           0.0000e+00,  2.2710e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -1.0053e-02,  ...,  0.0000e+00,\n",
      "           3.9788e-01,  1.0407e+00]],\n",
      "\n",
      "        [[ 3.5999e-02, -6.9558e-01, -6.2014e-01,  ...,  4.6087e-01,\n",
      "          -5.9517e-01, -0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -1.6012e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00, -0.0000e+00,  2.8591e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -1.3317e-01,\n",
      "          -1.2810e+00, -0.0000e+00],\n",
      "         [-9.5787e-02,  1.3935e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -0.0000e+00,  3.6118e+00],\n",
      "         [-4.7630e-01,  8.3724e-01,  0.0000e+00,  ..., -0.0000e+00,\n",
      "          -1.2860e-01,  4.3784e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.3753e+00,  3.3500e-01, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -7.2262e-01,  0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -3.8148e-01,  ...,  0.0000e+00,\n",
      "          -5.1854e-01, -0.0000e+00],\n",
      "         [-2.3587e+00, -5.4911e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00,  0.0000e+00,  5.5215e+00,  ..., -4.1732e-01,\n",
      "          -5.6927e-01, -0.0000e+00],\n",
      "         [-4.6264e+00,  0.0000e+00, -0.0000e+00,  ...,  4.9628e-01,\n",
      "          -1.4327e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  6.3653e-01,\n",
      "           0.0000e+00, -1.0863e+00]],\n",
      "\n",
      "        [[-0.0000e+00,  3.0192e+00, -0.0000e+00,  ..., -2.8595e-02,\n",
      "          -0.0000e+00,  5.4283e-03],\n",
      "         [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  2.0951e-01,\n",
      "           0.0000e+00,  3.4770e-01],\n",
      "         [ 0.0000e+00,  1.8876e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           1.7773e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00, -4.8860e-01, -5.8695e-01,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [-7.7686e-01, -3.2012e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           2.8792e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -2.1397e-01,\n",
      "          -0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "        [[-0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          -3.8718e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00, -7.8264e-01,  0.0000e+00,  ..., -2.5454e-01,\n",
      "          -0.0000e+00, -7.6840e-01],\n",
      "         [ 3.0052e+00, -2.8365e-01, -6.3585e+00,  ..., -5.7347e-01,\n",
      "           0.0000e+00, -7.8767e-02],\n",
      "         ...,\n",
      "         [ 3.7657e+00,  3.6217e+00, -0.0000e+00,  ...,  3.0006e-01,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [-0.0000e+00, -4.5183e-02,  2.3882e-01,  ..., -1.2807e+00,\n",
      "          -0.0000e+00,  3.4540e+00],\n",
      "         [-1.3906e+00,  0.0000e+00,  0.0000e+00,  ...,  1.6026e-01,\n",
      "           7.7064e-01, -3.4723e-01]]], grad_fn=<MulBackward0>)\n",
      "tensor([[-0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.0000, -1.0796],\n",
      "        [-0.0000,  0.6194, -0.0000,  ...,  0.0000,  0.3979,  1.0407],\n",
      "        [ 0.0360, -0.6956, -0.6201,  ..., -0.0000, -0.1286,  0.4378],\n",
      "        ...,\n",
      "        [ 3.3753,  0.3350, -0.0000,  ...,  0.6365,  0.0000, -1.0863],\n",
      "        [-0.0000,  3.0192, -0.0000,  ..., -0.2140, -0.0000, -0.0000],\n",
      "        [-0.0000, -0.0000,  0.0000,  ...,  0.1603,  0.7706, -0.3472]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.0000e+00,  0.0000e+00, -2.7054e-01,  ...,  3.5386e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00,  1.3644e+00,  8.5926e-01,  ..., -6.4275e-01,\n",
      "           0.0000e+00,  1.8592e+00],\n",
      "         [-1.6289e-01,  8.2187e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [-1.7908e+00,  5.7309e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           6.1693e-01, -1.7161e+00],\n",
      "         [-0.0000e+00,  3.9567e-01, -0.0000e+00,  ..., -5.6536e-01,\n",
      "           1.3649e-01,  0.0000e+00],\n",
      "         [-5.6898e-01,  1.0249e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00, -4.8457e-01,  0.0000e+00,  ..., -5.3711e-01,\n",
      "          -0.0000e+00,  5.4572e+00],\n",
      "         [-0.0000e+00, -3.3083e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          -7.1804e-02, -1.7307e+00],\n",
      "         [-4.6133e-01, -0.0000e+00,  0.0000e+00,  ...,  1.3769e-01,\n",
      "           1.3732e+00,  9.7486e-02],\n",
      "         ...,\n",
      "         [-0.0000e+00, -2.8830e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00, -1.4734e-01, -2.8943e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  3.1079e-01],\n",
      "         [ 0.0000e+00,  5.8921e-02, -8.9522e-02,  ..., -5.7647e-01,\n",
      "           4.7261e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-1.5569e+00, -0.0000e+00,  0.0000e+00,  ..., -1.6232e-02,\n",
      "           6.5881e-01, -2.8203e+00],\n",
      "         [-0.0000e+00,  6.0136e-01, -2.6862e-02,  ...,  0.0000e+00,\n",
      "           1.5744e+00, -0.0000e+00],\n",
      "         [-5.9048e-01,  2.1278e+00,  0.0000e+00,  ..., -1.7168e-01,\n",
      "          -1.7575e-01,  3.3871e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -0.0000e+00,  4.3364e+00,  ..., -7.7161e-01,\n",
      "          -1.7043e+00, -1.6860e+00],\n",
      "         [-7.5548e+00,  2.4128e-01, -3.2744e-01,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -3.7650e-02,  ..., -7.6892e-01,\n",
      "          -5.6467e-01, -0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.4132e-02,  0.0000e+00, -0.0000e+00,  ...,  2.4543e-01,\n",
      "           0.0000e+00,  9.2638e-01],\n",
      "         [-8.4281e-01, -0.0000e+00, -6.8866e-01,  ..., -1.2744e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [-2.4946e-01, -3.6403e-01,  0.0000e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  1.3328e+00],\n",
      "         ...,\n",
      "         [-4.9653e-01, -8.1973e-02, -1.8332e+00,  ..., -3.6614e-01,\n",
      "          -0.0000e+00, -1.2255e+00],\n",
      "         [-8.5120e-01, -1.7545e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [ 2.9689e-01,  4.9634e-01, -8.5222e-03,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  5.8528e-01]],\n",
      "\n",
      "        [[-0.0000e+00,  0.0000e+00, -2.4069e-01,  ..., -0.0000e+00,\n",
      "           6.1634e-01, -7.2817e+00],\n",
      "         [-4.4298e+00, -2.5854e+00, -0.0000e+00,  ...,  3.7259e-01,\n",
      "           3.7919e-01,  0.0000e+00],\n",
      "         [-1.9673e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 1.6474e-01, -0.0000e+00, -0.0000e+00,  ..., -1.0802e-02,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00, -2.4290e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [-7.8507e-01,  0.0000e+00,  0.0000e+00,  ..., -2.8373e+00,\n",
      "          -0.0000e+00,  2.8346e-01]],\n",
      "\n",
      "        [[-2.0332e-01, -0.0000e+00,  3.9246e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  7.0603e-02],\n",
      "         [-2.9111e+00,  5.3112e-03, -1.6115e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 1.5045e+00,  4.7716e-01,  0.0000e+00,  ..., -4.2557e-01,\n",
      "           4.6440e+00, -2.8674e+00],\n",
      "         ...,\n",
      "         [-1.5531e+00,  0.0000e+00, -2.4125e+00,  ...,  3.8107e-01,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-3.2665e+00, -0.0000e+00,  1.3713e+00,  ..., -0.0000e+00,\n",
      "           2.8235e-01,  3.5700e-01],\n",
      "         [-4.3916e-01, -0.0000e+00, -0.0000e+00,  ..., -5.7988e-02,\n",
      "           0.0000e+00,  0.0000e+00]]], grad_fn=<MulBackward0>)\n",
      "tensor([[-0.0000,  0.0000, -0.2705,  ..., -0.0000,  0.0000, -0.0000],\n",
      "        [ 0.0000, -0.4846,  0.0000,  ..., -0.5765,  4.7261,  0.0000],\n",
      "        [-1.5569, -0.0000,  0.0000,  ..., -0.7689, -0.5647, -0.0000],\n",
      "        ...,\n",
      "        [-0.0641,  0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.5853],\n",
      "        [-0.0000,  0.0000, -0.2407,  ..., -2.8373, -0.0000,  0.2835],\n",
      "        [-0.2033, -0.0000,  0.3925,  ..., -0.0580,  0.0000,  0.0000]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[ 0.1246,  1.8969, -4.9397,  ..., -0.0211,  0.0000,  0.0000],\n",
      "         [-0.0000,  0.0000, -4.8743,  ..., -2.6389,  0.0000, -0.0000],\n",
      "         [-1.2946,  1.8835, -0.4605,  ...,  0.5212,  0.8877,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000, -0.0000,  0.0000,  ..., -2.2449,  0.7279,  0.6389],\n",
      "         [-0.0000,  0.6394,  0.0000,  ...,  0.0000,  0.0000, -0.1004],\n",
      "         [ 0.0000, -0.1927, -0.0000,  ..., -0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "        [[-0.0000,  0.0969,  0.0121,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.4373,  0.4081, -1.0651,  ...,  0.0000, -0.0000,  3.3492],\n",
      "         [-0.8765,  1.2534, -0.0000,  ..., -0.0000, -0.0000,  0.0623],\n",
      "         ...,\n",
      "         [-0.0000, -1.0275, -0.0000,  ...,  0.5293, -0.0000, -0.2153],\n",
      "         [-0.0000,  2.3270,  0.0000,  ..., -0.7755,  0.9455,  0.0000],\n",
      "         [ 0.0000,  0.9861, -0.0000,  ...,  0.0000,  0.0000,  0.6177]],\n",
      "\n",
      "        [[-1.1435,  0.0000, -0.2667,  ..., -0.0000, -0.0000,  0.4570],\n",
      "         [-0.5445,  0.0000, -0.0000,  ...,  0.5719, -0.0000,  0.0000],\n",
      "         [-0.0000, -0.3038,  0.0812,  ..., -0.8032, -0.1566,  0.0000],\n",
      "         ...,\n",
      "         [-2.7205,  0.0000,  0.0000,  ..., -0.7710, -0.0000, -0.2009],\n",
      "         [-3.8470, -0.0466, -1.4979,  ...,  0.0000, -0.0000,  0.0000],\n",
      "         [-1.7607,  0.0000,  2.0979,  ..., -0.0000,  0.1339,  0.1721]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0000,  0.0000, -2.3704,  ..., -0.0000, -0.0000,  0.4088],\n",
      "         [-0.0000,  0.0000,  0.3301,  ...,  0.0000,  0.7701,  1.8058],\n",
      "         [-2.3699, -0.0000, -0.8971,  ...,  1.0163,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000, -0.0000, -0.0000,  ..., -0.3561, -0.1205,  0.1667],\n",
      "         [-0.0000, -0.0000, -0.0000,  ...,  0.0000,  0.0000,  2.9520],\n",
      "         [-0.0000, -3.4672, -0.0000,  ..., -0.1639, -0.0000, -0.0000]],\n",
      "\n",
      "        [[-6.3551,  3.5398, -1.7875,  ...,  0.0000, -0.0000,  0.0000],\n",
      "         [-0.2847, -0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "         [-0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "         ...,\n",
      "         [-0.0000,  0.0000, -0.2202,  ...,  0.0000,  0.1043, -0.0000],\n",
      "         [-0.3898, -0.0000, -0.8030,  ..., -0.0000,  0.0000,  0.2074],\n",
      "         [ 3.9630,  0.0000, -1.7128,  ...,  0.0000, -0.2828, -1.6323]],\n",
      "\n",
      "        [[ 0.0000, -0.0406, -0.2322,  ..., -4.9844,  0.0000,  0.0000],\n",
      "         [-0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.2026, -3.8114],\n",
      "         [-0.0567, -0.4409, -2.3559,  ..., -0.2886, -0.0000,  0.0993],\n",
      "         ...,\n",
      "         [-4.6095, -0.0000,  0.5233,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [-0.0000, -4.2271,  0.0000,  ..., -0.7266,  0.0000,  0.0000],\n",
      "         [ 2.3279, -0.0000,  0.0000,  ..., -0.1910, -0.0000, -0.5537]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[ 0.1246,  1.8969, -4.9397,  ..., -0.0000,  0.0000, -0.0000],\n",
      "        [-0.0000,  0.0969,  0.0121,  ...,  0.0000,  0.0000,  0.6177],\n",
      "        [-1.1435,  0.0000, -0.2667,  ..., -0.0000,  0.1339,  0.1721],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000, -2.3704,  ..., -0.1639, -0.0000, -0.0000],\n",
      "        [-6.3551,  3.5398, -1.7875,  ...,  0.0000, -0.2828, -1.6323],\n",
      "        [ 0.0000, -0.0406, -0.2322,  ..., -0.1910, -0.0000, -0.5537]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-1.2904, -0.3830, -1.0052,  ..., -0.3268, -0.9582, -0.7455],\n",
      "         [-0.7273,  0.0000, -0.6238,  ...,  1.3333, -3.7840,  2.9702],\n",
      "         [-0.0000, -0.0000, -0.0000,  ...,  0.0686,  0.0000,  0.4515],\n",
      "         ...,\n",
      "         [ 1.0100, -0.0000, -0.0000,  ...,  0.1488, -1.4167, -0.0000],\n",
      "         [-0.8181, -0.0000, -1.1846,  ...,  0.0000, -0.8084, -0.0444],\n",
      "         [-0.0000, -0.0000,  4.5277,  ..., -1.7045, -0.5584, -1.1081]],\n",
      "\n",
      "        [[-0.0000, -0.0000, -0.0000,  ..., -0.2229, -0.0000, -0.1519],\n",
      "         [ 0.5727, -0.0000,  0.0000,  ...,  0.0000, -0.0147,  1.1740],\n",
      "         [-0.0000,  0.0000, -0.0000,  ...,  5.2473, -0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.1042],\n",
      "         [-1.6057,  0.7066, -1.4482,  ...,  0.0000, -0.7801, -0.0000],\n",
      "         [ 5.0523, -0.1419, -0.0000,  ...,  1.3228, -0.0000, -0.4609]],\n",
      "\n",
      "        [[ 0.0000,  0.0000, -2.2109,  ..., -0.0000,  0.0000, -0.0000],\n",
      "         [-1.0152,  0.1082,  0.3938,  ..., -0.0554, -0.0000,  0.0000],\n",
      "         [-0.8908,  0.0000, -0.0000,  ..., -0.0000, -0.1688,  0.0000],\n",
      "         ...,\n",
      "         [-0.0394,  0.0000, -0.0000,  ...,  1.9619, -0.0485,  0.0000],\n",
      "         [-0.0000, -0.0000, -6.3655,  ...,  0.0000,  0.5656,  0.1668],\n",
      "         [-0.0000, -0.1585, -1.1782,  ...,  0.0000, -1.7520,  0.9802]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0000, -0.0000, -5.1169,  ...,  0.0305,  0.0000,  0.1048],\n",
      "         [-5.6132,  2.5963,  0.0244,  ..., -4.9689, -0.0000, -0.0209],\n",
      "         [-0.0000,  0.0000, -0.0000,  ..., -0.0000, -0.7937,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "         [-0.9028,  0.9293, -0.5184,  ...,  0.3991, -0.2713, -0.0000],\n",
      "         [-0.0000, -4.1449, -0.0000,  ...,  0.0516,  0.0000,  0.0000]],\n",
      "\n",
      "        [[-0.3587,  0.0000,  0.4951,  ...,  0.1355,  0.0000,  0.7028],\n",
      "         [ 0.0000, -0.0000, -0.0000,  ...,  0.0000,  0.9963,  0.0000],\n",
      "         [-0.0000,  1.2190, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         ...,\n",
      "         [-0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.1259, -0.0000],\n",
      "         [-1.5981,  3.3928, -0.4197,  ..., -0.1483, -0.0000, -0.4192],\n",
      "         [ 0.0000, -0.0631, -0.0000,  ..., -0.1664, -0.0000, -0.0000]],\n",
      "\n",
      "        [[-1.4135, -0.0000, -1.3597,  ..., -0.0000, -0.0000,  0.0000],\n",
      "         [-0.3188, -0.0000, -3.9716,  ..., -0.0000, -0.4171, -0.3421],\n",
      "         [ 0.0000, -0.0000, -4.9710,  ...,  0.0000, -0.1432, -0.0000],\n",
      "         ...,\n",
      "         [-0.0000,  0.7237, -0.0000,  ..., -0.0000,  0.2829,  0.0815],\n",
      "         [-0.0000,  4.3833, -0.8035,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-1.0070,  0.0000, -1.7536,  ..., -0.0000,  0.0000,  0.3916]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-1.2904, -0.3830, -1.0052,  ..., -1.7045, -0.5584, -1.1081],\n",
      "        [-0.0000, -0.0000, -0.0000,  ...,  1.3228, -0.0000, -0.4609],\n",
      "        [ 0.0000,  0.0000, -2.2109,  ...,  0.0000, -1.7520,  0.9802],\n",
      "        ...,\n",
      "        [ 0.0000, -0.0000, -5.1169,  ...,  0.0516,  0.0000,  0.0000],\n",
      "        [-0.3587,  0.0000,  0.4951,  ..., -0.1664, -0.0000, -0.0000],\n",
      "        [-1.4135, -0.0000, -1.3597,  ..., -0.0000,  0.0000,  0.3916]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[ 0.0000,  0.0000, -0.0000,  ...,  0.6036, -0.0000,  0.0000],\n",
      "         [ 3.8178,  0.1573, -0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
      "         [-0.0000, -1.4333,  0.0000,  ..., -1.1851, -0.0563,  1.4163],\n",
      "         ...,\n",
      "         [-2.5973,  0.1490,  0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "         [-1.9480, -0.5929,  0.0000,  ..., -0.4308, -0.0000, -3.5571],\n",
      "         [ 3.5508, -0.5780, -0.0000,  ...,  0.0245, -0.0000, -0.0000]],\n",
      "\n",
      "        [[ 0.4038,  0.0000, -0.1861,  ...,  1.1690,  0.0378,  0.5472],\n",
      "         [-1.1407, -0.3239, -0.0000,  ..., -0.0000,  0.5158,  0.0000],\n",
      "         [-0.0000,  0.9213,  2.5900,  ...,  0.0000,  0.8382, -0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  1.8423, -0.8688,  ..., -0.8501, -2.2918, -3.0212],\n",
      "         [-0.9160, -0.3928,  0.3772,  ..., -0.4151,  0.0000,  0.0000],\n",
      "         [ 2.0834, -0.0000,  4.0195,  ..., -0.1956, -0.0000, -0.8512]],\n",
      "\n",
      "        [[-0.0000, -0.5746, -0.9038,  ...,  0.0000,  0.0000, -0.0000],\n",
      "         [-0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.1567],\n",
      "         [-0.0000, -0.0000, -0.0000,  ...,  0.0000,  3.1125,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000, -0.0000,  5.7635,  ..., -0.0000, -1.5792, -0.0000],\n",
      "         [-1.1048,  0.0000, -0.4478,  ...,  1.0079, -1.2729, -0.0000],\n",
      "         [ 3.5526,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000, -0.0000,  0.0000,  ..., -0.5302,  0.2577,  0.5192],\n",
      "         [-0.0000,  0.8019, -0.0000,  ...,  0.0000, -0.0000, -0.1889],\n",
      "         [-1.3317,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "         ...,\n",
      "         [ 0.0577,  0.0000,  0.0000,  ...,  0.0000, -1.6803, -0.0000],\n",
      "         [-4.4915,  3.1947, -0.0000,  ...,  0.0546, -0.8399,  0.0000],\n",
      "         [-2.0924, -4.2095,  5.7918,  ..., -0.2169, -0.0000,  0.2357]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ..., -6.3583,  0.8354,  0.6162],\n",
      "         [-0.0000,  0.0305,  0.2214,  ...,  0.5858, -0.0489,  2.6633],\n",
      "         [-0.0000,  0.0000, -2.9913,  ...,  0.1865, -0.0470,  4.8138],\n",
      "         ...,\n",
      "         [-0.0000, -0.5423, -0.0000,  ..., -0.1082, -0.6896, -0.0000],\n",
      "         [-0.0000, -0.7879, -1.1030,  ..., -0.0000, -1.1140,  1.1705],\n",
      "         [-0.9811, -0.6627,  0.0000,  ...,  0.0000, -0.0000, -0.9040]],\n",
      "\n",
      "        [[-0.4396, -0.0000, -0.0000,  ..., -0.0000, -0.4513,  0.9183],\n",
      "         [ 0.6368,  0.0000,  0.4127,  ..., -0.3121,  0.0000, -0.0000],\n",
      "         [-0.0000,  1.0713, -0.0000,  ..., -0.3653, -0.2785, -0.0000],\n",
      "         ...,\n",
      "         [ 2.3969, -0.0000,  2.5403,  ..., -0.0000, -1.1229, -0.7381],\n",
      "         [ 0.1275, -0.0000, -0.1919,  ...,  0.1237, -0.2033,  1.4288],\n",
      "         [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -1.1928, -0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[ 0.0000,  0.0000, -0.0000,  ...,  0.0245, -0.0000, -0.0000],\n",
      "        [ 0.4038,  0.0000, -0.1861,  ..., -0.1956, -0.0000, -0.8512],\n",
      "        [-0.0000, -0.5746, -0.9038,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        ...,\n",
      "        [-0.0000, -0.0000,  0.0000,  ..., -0.2169, -0.0000,  0.2357],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.9040],\n",
      "        [-0.4396, -0.0000, -0.0000,  ..., -0.0000, -1.1928, -0.0000]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.3779, -0.0000, -0.2219,  ..., -0.5182,  0.0000,  2.0805],\n",
      "         [-5.5036,  0.2737, -0.0000,  ..., -0.0000,  0.2828,  0.0000],\n",
      "         [-0.0000, -0.0000, -0.0000,  ...,  0.0943, -0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000, -0.0000,  0.0000,  ..., -5.8744,  0.0000, -0.0000],\n",
      "         [-0.0000, -0.0542, -0.0000,  ..., -0.0000,  0.0734, -0.0000],\n",
      "         [ 3.3694, -0.0000, -0.3509,  ..., -0.2407,  0.1854, -0.0000]],\n",
      "\n",
      "        [[-4.6827,  1.0669,  0.0000,  ...,  0.1986, -3.8131,  0.0000],\n",
      "         [-0.0000,  0.0000, -0.0000,  ..., -0.0000, -0.0000,  6.8583],\n",
      "         [ 0.0000, -3.6333,  0.0000,  ...,  0.0000,  0.2943,  0.0385],\n",
      "         ...,\n",
      "         [-0.2939, -0.5421, -0.1405,  ..., -0.0000, -0.0000,  0.1254],\n",
      "         [ 0.0000, -0.0000, -0.0000,  ...,  0.0646,  0.3238,  2.6021],\n",
      "         [-5.1883,  0.0000,  0.0000,  ..., -0.0000, -0.9043, -0.0000]],\n",
      "\n",
      "        [[-0.4208, -0.0000, -0.0000,  ..., -0.0000,  1.0227, -0.0000],\n",
      "         [-0.2779, -0.0726, -0.2348,  ..., -4.3797,  0.2679,  0.0000],\n",
      "         [ 0.0000, -0.0000, -0.6952,  ...,  0.0000,  0.0000, -0.0000],\n",
      "         ...,\n",
      "         [ 2.5605, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.8501],\n",
      "         [-0.1790, -0.0000, -0.2744,  ..., -0.0000,  0.2080, -0.0000],\n",
      "         [-1.4655,  1.1653, -0.0000,  ..., -0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-4.2310,  0.2276,  0.0000,  ..., -0.5617,  0.0000,  0.0000],\n",
      "         [ 1.6417, -0.0000,  0.0000,  ...,  1.7261, -0.2952,  0.5707],\n",
      "         [-0.0000,  0.0000, -0.0000,  ...,  0.0000, -5.7276,  0.9977],\n",
      "         ...,\n",
      "         [ 3.2900, -3.6669, -0.3378,  ..., -0.3443, -0.0000,  0.0000],\n",
      "         [-0.0000,  0.0000, -0.0000,  ...,  0.1181, -0.0000,  1.4509],\n",
      "         [-0.6519,  0.0000, -0.0000,  ..., -0.3436, -0.0000, -0.3908]],\n",
      "\n",
      "        [[-0.9528,  1.9118,  2.2925,  ..., -2.4113,  0.3924,  0.0000],\n",
      "         [-0.0000,  0.0000, -0.0000,  ...,  0.7424,  2.1245, -3.6185],\n",
      "         [-0.1955, -0.0000, -0.6964,  ...,  5.1258,  0.0000,  1.9785],\n",
      "         ...,\n",
      "         [ 0.0000, -1.5006, -0.0000,  ..., -0.5621, -0.2321, -1.3089],\n",
      "         [-3.3145,  0.0000, -0.0000,  ..., -0.3079, -0.3295, -0.3769],\n",
      "         [-0.0000,  0.4281, -0.5985,  ..., -0.0588,  0.2377,  0.2802]],\n",
      "\n",
      "        [[-0.0000,  0.0000, -0.8540,  ...,  0.3866,  0.0000,  0.8078],\n",
      "         [-0.0000, -0.5346, -0.0000,  ...,  0.0000,  3.5488,  0.0000],\n",
      "         [-0.0000,  0.9686,  0.0000,  ...,  0.5541,  0.0000,  0.0082],\n",
      "         ...,\n",
      "         [-0.0000, -1.8793, -1.3321,  ...,  0.1539,  1.7547, -0.0000],\n",
      "         [-0.0000,  3.0604, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "         [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.2534,  0.3952]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-0.3779, -0.0000, -0.2219,  ..., -0.2407,  0.1854, -0.0000],\n",
      "        [-4.6827,  1.0669,  0.0000,  ..., -0.0000, -0.9043, -0.0000],\n",
      "        [-0.4208, -0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-4.2310,  0.2276,  0.0000,  ..., -0.3436, -0.0000, -0.3908],\n",
      "        [-0.9528,  1.9118,  2.2925,  ..., -0.0588,  0.2377,  0.2802],\n",
      "        [-0.0000,  0.0000, -0.8540,  ..., -0.0000, -0.2534,  0.3952]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.0000,  0.1156, -2.3556,  ..., -0.0000, -0.2841, -0.9346],\n",
      "         [-0.0000,  0.1511, -0.3723,  ..., -0.0000, -4.3882, -0.0000],\n",
      "         [-0.0000,  0.0000,  0.3524,  ..., -3.6494,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000,  0.0000, -0.0000,  ..., -0.2201, -0.0173,  0.0000],\n",
      "         [ 0.3478, -0.0000, -0.6586,  ..., -0.0000, -0.0000,  0.0000],\n",
      "         [ 4.0605,  0.0000, -0.0000,  ...,  0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "        [[-2.0626,  0.0000, -0.9049,  ...,  0.0000, -0.8580, -0.0187],\n",
      "         [ 0.0000, -0.0000,  0.0000,  ..., -4.2776,  0.3904,  0.1691],\n",
      "         [-0.0000,  0.0000,  0.0000,  ...,  0.5130,  0.1787,  0.0000],\n",
      "         ...,\n",
      "         [-0.8211,  0.0000,  0.1770,  ..., -0.3449,  0.0000,  1.0536],\n",
      "         [-0.0000,  0.0000,  0.3055,  ...,  0.6924,  0.6545,  0.8970],\n",
      "         [-0.0000, -0.0000, -0.7802,  ..., -1.1119,  0.0000, -0.1619]],\n",
      "\n",
      "        [[ 0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.8321, -3.2723],\n",
      "         [ 0.0000,  0.0000, -0.0000,  ...,  0.2770,  0.0000,  2.3822],\n",
      "         [-5.5261,  1.2374, -0.0000,  ..., -0.1065, -0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-2.4855,  1.4455, -0.4076,  ..., -0.0316, -0.0000,  0.0359],\n",
      "         [-0.7791, -0.0531, -0.8111,  ...,  0.5925, -0.4869, -1.2045],\n",
      "         [ 3.6409,  2.2389,  0.2143,  ...,  0.0897,  0.7272, -0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000,  1.4958],\n",
      "         [-0.0000, -0.0839,  4.3022,  ..., -0.3487, -0.0000,  2.5276],\n",
      "         [ 0.0391,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "         ...,\n",
      "         [-0.8408, -0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.4324],\n",
      "         [ 0.0000, -4.4388,  1.6167,  ...,  0.0000,  0.0000, -2.7954],\n",
      "         [-2.8089, -0.2554, -0.0000,  ..., -0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "        [[ 0.1270,  1.7965,  0.1381,  ..., -0.7982,  0.0000,  4.6577],\n",
      "         [-0.0000,  1.1988, -1.9516,  ..., -0.0000, -0.7306,  0.0504],\n",
      "         [ 0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.0267],\n",
      "         ...,\n",
      "         [-1.5070,  3.0923, -0.0000,  ..., -0.0171, -0.0000,  0.0000],\n",
      "         [-0.0000, -0.2195, -0.1815,  ..., -2.2263,  0.6091, -0.8135],\n",
      "         [-0.9504,  2.2395, -0.6322,  ..., -0.1877,  0.0000, -0.0000]],\n",
      "\n",
      "        [[-1.2237, -1.4459, -1.4128,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0743,  ..., -0.0000, -0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000, -1.7724,  ..., -0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.3341,  0.0000],\n",
      "         [-0.0000,  0.5764,  5.0289,  ...,  0.0000,  0.0000, -4.6354],\n",
      "         [-0.3452,  5.8678, -0.0000,  ..., -1.6053, -0.1866,  0.3919]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-0.0000,  0.1156, -2.3556,  ...,  0.0000, -0.0000, -0.0000],\n",
      "        [-2.0626,  0.0000, -0.9049,  ..., -1.1119,  0.0000, -0.1619],\n",
      "        [ 0.0000, -0.0000, -0.0000,  ...,  0.0897,  0.7272, -0.0000],\n",
      "        ...,\n",
      "        [-0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [ 0.1270,  1.7965,  0.1381,  ..., -0.1877,  0.0000, -0.0000],\n",
      "        [-1.2237, -1.4459, -1.4128,  ..., -1.6053, -0.1866,  0.3919]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-1.1838e-01,  5.2491e-01,  2.4991e+00,  ...,  0.0000e+00,\n",
      "          -3.6616e+00,  0.0000e+00],\n",
      "         [-0.0000e+00,  1.7696e-01, -4.6653e-01,  ...,  0.0000e+00,\n",
      "          -1.4034e-01, -2.3504e+00],\n",
      "         [-0.0000e+00,  2.0317e+00, -4.4624e-01,  ...,  0.0000e+00,\n",
      "           1.6542e+00, -4.4005e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00, -0.0000e+00,  8.1145e-01,  ...,  6.4819e-01,\n",
      "          -0.0000e+00,  2.2034e+00],\n",
      "         [-0.0000e+00, -0.0000e+00,  3.2518e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  1.3128e-01]],\n",
      "\n",
      "        [[ 0.0000e+00, -2.5882e+00, -5.5627e-01,  ...,  0.0000e+00,\n",
      "          -2.5425e-01, -2.1472e-01],\n",
      "         [-7.7442e-01,  1.6419e-01, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-5.6012e-01,  1.6938e-01, -1.5295e+00,  ..., -1.7416e+00,\n",
      "          -3.7809e-01, -0.0000e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -5.1887e-01,  0.0000e+00],\n",
      "         [-0.0000e+00, -1.6215e-01, -1.1259e+00,  ..., -2.7204e-01,\n",
      "           6.5717e-01,  0.0000e+00],\n",
      "         [-0.0000e+00,  7.8292e-01,  2.4671e-03,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-0.0000e+00,  5.2302e-01,  0.0000e+00,  ..., -0.0000e+00,\n",
      "          -2.9695e-01, -0.0000e+00],\n",
      "         [ 1.4343e+00,  3.2714e-01, -1.4995e-01,  ..., -3.0302e+00,\n",
      "           7.4451e-01,  0.0000e+00],\n",
      "         [ 4.6165e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "           1.0882e-01, -2.6221e+00],\n",
      "         ...,\n",
      "         [-1.1159e+00,  4.0705e-02, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -1.0935e+00,  1.5228e-01],\n",
      "         [-1.8297e+00,  3.2754e-01, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           6.3015e-01,  2.4454e-01],\n",
      "         [-0.0000e+00,  0.0000e+00,  1.2689e-01,  ..., -0.0000e+00,\n",
      "           3.2537e-02, -2.4434e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 3.9300e-01, -1.9655e+00,  0.0000e+00,  ..., -3.0735e-01,\n",
      "           0.0000e+00,  2.4747e+00],\n",
      "         [-3.4042e-01, -0.0000e+00, -0.0000e+00,  ..., -1.4130e-01,\n",
      "          -5.6496e-01, -1.5501e-01],\n",
      "         [-0.0000e+00,  7.3757e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  6.9680e-01],\n",
      "         ...,\n",
      "         [-6.3358e-01, -0.0000e+00, -8.6332e-01,  ...,  2.4607e-01,\n",
      "          -2.4746e+00, -0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -1.2199e+00,  ...,  0.0000e+00,\n",
      "          -2.6828e-01, -0.0000e+00],\n",
      "         [-0.0000e+00, -1.1627e+00,  0.0000e+00,  ...,  1.5102e-02,\n",
      "          -1.3401e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           2.8414e-01,  1.4361e+00],\n",
      "         [-2.9454e-01, -4.0955e-01,  1.0740e+00,  ..., -4.4179e+00,\n",
      "          -2.6556e-02, -2.5688e+00],\n",
      "         [-6.1985e-01, -0.0000e+00,  4.9584e-02,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [-2.4883e-01, -1.9168e+00, -1.7304e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -2.2360e+00],\n",
      "         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  1.2924e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -1.3325e-01,  ..., -0.0000e+00,\n",
      "          -3.4289e-01, -2.8989e+00]],\n",
      "\n",
      "        [[-0.0000e+00,  1.5975e+00, -1.2586e-01,  ..., -7.1060e-01,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -1.2748e+00,  ..., -3.7342e-01,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [ 5.1659e+00, -2.8326e+00,  0.0000e+00,  ..., -4.2851e-01,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00, -1.5339e-01,  1.7669e-01,  ..., -0.0000e+00,\n",
      "          -4.0839e+00, -2.2276e-01],\n",
      "         [-1.8440e+00, -0.0000e+00, -3.5281e-01,  ..., -1.4893e-01,\n",
      "          -2.8062e+00, -0.0000e+00],\n",
      "         [-1.1313e+00,  0.0000e+00, -2.5550e+00,  ..., -7.4969e-01,\n",
      "          -0.0000e+00, -1.2158e-01]]], grad_fn=<MulBackward0>)\n",
      "tensor([[-0.1184,  0.5249,  2.4991,  ..., -0.0000, -0.0000,  0.1313],\n",
      "        [ 0.0000, -2.5882, -0.5563,  ..., -0.0000,  0.0000,  0.0000],\n",
      "        [-0.0000,  0.5230,  0.0000,  ..., -0.0000,  0.0325, -2.4434],\n",
      "        ...,\n",
      "        [ 0.3930, -1.9655,  0.0000,  ...,  0.0151, -1.3401,  0.0000],\n",
      "        [ 0.0000,  0.0000, -0.0000,  ..., -0.0000, -0.3429, -2.8989],\n",
      "        [-0.0000,  1.5975, -0.1259,  ..., -0.7497, -0.0000, -0.1216]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.6266, -0.0000,  0.0753,  ...,  0.0000, -0.0000, -0.8332],\n",
      "         [-4.1388,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.4751],\n",
      "         [-0.0000,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  2.7897],\n",
      "         ...,\n",
      "         [-1.2933, -0.7548,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [-0.0000,  0.4778,  0.1891,  ...,  0.0000,  0.0000,  0.3272],\n",
      "         [ 6.3784, -0.0385,  0.0000,  ...,  0.0000, -4.7262, -0.0000]],\n",
      "\n",
      "        [[-0.0000,  0.7912, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "         [-0.0000, -0.6087, -1.0371,  ...,  4.9761,  0.3224,  0.4385],\n",
      "         [-0.0000,  0.4528, -0.0000,  ..., -0.0000,  4.5440, -0.1675],\n",
      "         ...,\n",
      "         [-0.0000,  3.8961, -0.2290,  ...,  0.2777, -2.9381,  0.0000],\n",
      "         [-0.3764, -0.6941, -1.1629,  ...,  0.0000, -0.4114,  0.0000],\n",
      "         [-0.1211, -2.6475,  0.1944,  ...,  0.0000, -0.0000,  0.4483]],\n",
      "\n",
      "        [[ 0.0000,  0.0658, -0.0000,  ...,  0.0000, -0.0000, -0.1276],\n",
      "         [-0.2500, -2.1933,  4.4275,  ..., -0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000, -0.1990,  0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "         ...,\n",
      "         [-0.9064, -0.3958, -0.0000,  ..., -0.0000,  5.5458,  0.4732],\n",
      "         [ 0.0000,  0.7547, -0.0000,  ..., -0.2607, -0.2970,  0.4763],\n",
      "         [ 0.0000,  0.3341,  0.0000,  ..., -0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000,  0.0000, -0.0000,  ..., -0.3786, -0.0000, -0.0000],\n",
      "         [-0.5982, -0.0000, -0.0000,  ...,  0.0000,  0.5387,  1.6295],\n",
      "         [-0.6473, -0.6719, -0.7591,  ..., -0.1632, -0.0000,  4.7424],\n",
      "         ...,\n",
      "         [-0.6733,  0.9068, -0.0330,  ..., -3.8095, -0.0000,  0.0000],\n",
      "         [-5.8193,  0.0000, -0.5222,  ..., -0.2149, -0.0000,  0.0000],\n",
      "         [-0.3996, -0.2452, -0.0000,  ..., -0.0000, -0.1050, -0.0000]],\n",
      "\n",
      "        [[-0.0000, -0.0000, -0.6584,  ...,  0.0000, -0.0000,  0.0000],\n",
      "         [-0.0956,  0.5943,  0.0000,  ..., -2.4369,  0.0000,  0.3377],\n",
      "         [-0.4021, -0.6065, -0.0000,  ...,  0.0000,  0.0000,  1.3363],\n",
      "         ...,\n",
      "         [-0.0000,  0.2143, -0.0000,  ..., -0.0000,  0.8337,  0.0000],\n",
      "         [-0.0000,  0.9753,  0.0366,  ..., -4.8167,  0.0000,  0.0000],\n",
      "         [-2.3522, -0.0424,  2.4070,  ..., -0.0000, -0.0000, -0.0901]],\n",
      "\n",
      "        [[ 0.1093,  0.0000,  3.1482,  ...,  0.1514,  0.0302, -0.0000],\n",
      "         [-0.3804,  0.0000,  0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "         [-0.0000,  0.0000, -0.0000,  ...,  3.8266,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000, -0.0000,  4.1379,  ..., -0.9340, -0.3250, -0.4728],\n",
      "         [ 0.0000, -0.6510, -0.6098,  ..., -0.0000, -0.0000,  0.0000],\n",
      "         [-1.8144,  1.6385,  0.0000,  ..., -1.2096, -1.5343, -0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-0.6266, -0.0000,  0.0753,  ...,  0.0000, -4.7262, -0.0000],\n",
      "        [-0.0000,  0.7912, -0.0000,  ...,  0.0000, -0.0000,  0.4483],\n",
      "        [ 0.0000,  0.0658, -0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.0000,  0.0000, -0.0000,  ..., -0.0000, -0.1050, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.6584,  ..., -0.0000, -0.0000, -0.0901],\n",
      "        [ 0.1093,  0.0000,  3.1482,  ..., -1.2096, -1.5343, -0.0000]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-7.1349e+00,  0.0000e+00, -5.4759e-02,  ..., -1.6736e+00,\n",
      "          -1.1228e-01,  0.0000e+00],\n",
      "         [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  7.2352e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [-0.0000e+00, -2.3373e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  1.0174e-01],\n",
      "         ...,\n",
      "         [-0.0000e+00,  1.2531e-01, -0.0000e+00,  ..., -6.8700e-01,\n",
      "           3.8972e-01,  2.7261e-01],\n",
      "         [-0.0000e+00, -1.5089e-01, -0.0000e+00,  ...,  8.6435e-01,\n",
      "           1.0742e+00,  8.1232e-01],\n",
      "         [ 3.6387e+00, -4.2983e+00,  4.6191e+00,  ..., -1.8297e-01,\n",
      "          -1.5051e+00, -2.7797e-02]],\n",
      "\n",
      "        [[-6.8386e-01,  0.0000e+00,  0.0000e+00,  ...,  1.8892e+00,\n",
      "          -2.3315e+00,  0.0000e+00],\n",
      "         [ 2.3513e+00,  3.7008e-01, -5.5897e-01,  ..., -6.5078e-01,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [ 4.2901e+00,  0.0000e+00,  8.8929e-02,  ..., -3.4684e-01,\n",
      "           2.6376e+00,  8.6746e-01],\n",
      "         [ 3.4984e-01,  0.0000e+00, -0.0000e+00,  ...,  6.8598e+00,\n",
      "          -1.3332e+00, -4.2432e-01],\n",
      "         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -4.3462e-01,\n",
      "          -0.0000e+00, -2.1534e+00]],\n",
      "\n",
      "        [[ 4.3218e-02, -5.5712e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -1.1367e+00, -0.0000e+00],\n",
      "         [-0.0000e+00, -2.6398e-01, -0.0000e+00,  ..., -8.3400e-01,\n",
      "           8.1174e+00,  3.4871e-01],\n",
      "         [-0.0000e+00, -1.4631e+00, -2.9240e-01,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  4.8593e+00],\n",
      "         ...,\n",
      "         [-2.1069e+00, -2.9600e+00, -0.0000e+00,  ..., -1.8542e-01,\n",
      "          -8.7521e-01, -5.2787e-01],\n",
      "         [-0.0000e+00,  0.0000e+00,  2.5634e-01,  ..., -0.0000e+00,\n",
      "           8.9354e-01, -0.0000e+00],\n",
      "         [ 0.0000e+00, -0.0000e+00,  2.7153e+00,  ..., -3.3374e-02,\n",
      "          -0.0000e+00, -5.7368e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  7.3618e-01,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [ 1.2428e+00, -0.0000e+00, -1.3542e+00,  ...,  4.4211e+00,\n",
      "           1.3015e+00, -0.0000e+00],\n",
      "         [ 0.0000e+00, -0.0000e+00, -1.2214e+00,  ..., -1.2584e+00,\n",
      "           6.5275e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00, -3.3747e-01,  3.8687e+00,  ..., -0.0000e+00,\n",
      "           7.1707e-01,  3.8168e-01],\n",
      "         [-1.6407e+00, -0.0000e+00, -1.5778e+00,  ..., -0.0000e+00,\n",
      "          -7.2729e-01,  6.3889e+00],\n",
      "         [-0.0000e+00,  2.0674e+00,  0.0000e+00,  ..., -4.0396e-01,\n",
      "          -0.0000e+00, -3.9477e-01]],\n",
      "\n",
      "        [[-0.0000e+00,  9.2223e-01,  3.3764e-01,  ...,  3.3734e-01,\n",
      "          -6.1080e-01,  0.0000e+00],\n",
      "         [ 0.0000e+00,  2.1486e-01,  1.3560e-01,  ...,  6.5788e-01,\n",
      "           2.0510e+00,  3.5626e-01],\n",
      "         [-0.0000e+00,  0.0000e+00, -8.3062e-01,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 4.5976e+00,  2.9767e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           7.4610e-01, -3.5755e+00],\n",
      "         [-0.0000e+00,  2.0098e+00, -1.6337e+00,  ..., -1.1018e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-1.2135e+00, -0.0000e+00,  7.9754e-01,  ...,  0.0000e+00,\n",
      "           1.0938e+00, -1.6984e+00]],\n",
      "\n",
      "        [[-0.0000e+00,  0.0000e+00,  1.1352e+00,  ...,  1.0350e+00,\n",
      "           3.8194e-01,  8.0003e-01],\n",
      "         [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "           3.1536e-01,  2.7831e-01],\n",
      "         [ 6.7882e+00,  0.0000e+00,  1.9351e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -9.7579e-01,\n",
      "           7.4753e-02,  3.5434e-01],\n",
      "         [-5.3856e+00,  0.0000e+00,  2.6985e-03,  ...,  1.1548e+00,\n",
      "           7.3514e-01,  0.0000e+00],\n",
      "         [-4.3244e-01,  0.0000e+00,  3.8290e-01,  ..., -0.0000e+00,\n",
      "           5.7400e-01, -0.0000e+00]]], grad_fn=<MulBackward0>)\n",
      "tensor([[-7.1349,  0.0000, -0.0548,  ..., -0.1830, -1.5051, -0.0278],\n",
      "        [-0.6839,  0.0000,  0.0000,  ..., -0.4346, -0.0000, -2.1534],\n",
      "        [ 0.0432, -0.5571, -0.0000,  ..., -0.0334, -0.0000, -0.5737],\n",
      "        ...,\n",
      "        [-0.0000,  0.0000, -0.0000,  ..., -0.4040, -0.0000, -0.3948],\n",
      "        [-0.0000,  0.9222,  0.3376,  ...,  0.0000,  1.0938, -1.6984],\n",
      "        [-0.0000,  0.0000,  1.1352,  ..., -0.0000,  0.5740, -0.0000]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-1.5069e+00, -0.0000e+00, -0.0000e+00,  ..., -3.1041e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-1.1908e+00, -0.0000e+00, -6.1928e-01,  ..., -7.0158e-01,\n",
      "          -8.6815e-02, -2.9883e+00],\n",
      "         [ 5.0235e-01, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -2.5904e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  7.8491e-03,\n",
      "           2.5556e+00,  2.1730e+00],\n",
      "         [-0.0000e+00,  6.1140e-01, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "           4.8799e-01, -0.0000e+00]],\n",
      "\n",
      "        [[-0.0000e+00,  8.2550e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  2.9136e-01],\n",
      "         [-0.0000e+00, -1.4666e+00,  2.9878e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  1.5148e-01],\n",
      "         [-1.4523e+00, -5.8593e-03, -4.7643e-01,  ...,  5.0478e+00,\n",
      "          -0.0000e+00, -6.6637e-02],\n",
      "         ...,\n",
      "         [-7.2762e-01, -2.7662e+00, -8.0397e-01,  ..., -5.2488e-01,\n",
      "          -5.2415e-02, -0.0000e+00],\n",
      "         [-7.6192e+00,  1.8481e+00, -0.0000e+00,  ...,  2.6666e+00,\n",
      "           1.2937e+00,  0.0000e+00],\n",
      "         [ 5.3453e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "           2.2384e-02, -8.1274e-02]],\n",
      "\n",
      "        [[ 8.4549e-02, -0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           4.4037e-01,  6.9401e-01],\n",
      "         [-0.0000e+00,  0.0000e+00, -1.3124e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -3.4107e+00,\n",
      "          -0.0000e+00,  1.3672e+00],\n",
      "         ...,\n",
      "         [-2.4950e+00, -4.3133e-01,  6.2004e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -9.7210e-01],\n",
      "         [-8.3187e-01, -0.0000e+00, -0.0000e+00,  ...,  1.5088e+00,\n",
      "          -3.3004e-01,  1.7205e-02],\n",
      "         [ 0.0000e+00, -1.2257e-01, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -3.0579e+00, -1.2754e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-4.0154e-01,  2.0303e+00, -1.2156e-01,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-2.8140e+00, -0.0000e+00, -0.0000e+00,  ..., -4.0700e-01,\n",
      "           1.1571e-02, -5.0808e+00],\n",
      "         [-6.1507e-01,  2.0480e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -5.7990e-01,  1.4135e+00],\n",
      "         ...,\n",
      "         [-4.5040e-01,  5.6206e-01, -2.7521e+00,  ...,  4.4573e-01,\n",
      "           0.0000e+00, -9.3043e-01],\n",
      "         [-0.0000e+00, -1.2279e+00, -1.1359e-01,  ...,  1.8125e-01,\n",
      "           7.4789e-01, -0.0000e+00],\n",
      "         [ 2.9775e+00,  1.3872e+00, -0.0000e+00,  ..., -7.7578e-01,\n",
      "           9.1971e-03, -1.9704e+00]],\n",
      "\n",
      "        [[ 1.5120e+00, -0.0000e+00, -4.8517e-01,  ...,  0.0000e+00,\n",
      "          -0.0000e+00,  4.6492e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -1.8224e-01,  ...,  6.9879e-01,\n",
      "          -0.0000e+00,  3.3925e+00],\n",
      "         [-6.1376e-01, -0.0000e+00,  0.0000e+00,  ...,  1.6910e-01,\n",
      "           9.0276e-01, -0.0000e+00],\n",
      "         ...,\n",
      "         [-4.9873e-01, -2.3882e+00, -1.3861e+00,  ..., -2.6217e-01,\n",
      "           0.0000e+00, -1.8395e+00],\n",
      "         [ 8.5885e-02,  9.1833e-01, -1.8669e-01,  ..., -8.2247e-02,\n",
      "           0.0000e+00,  2.4858e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -1.9086e+00,\n",
      "           5.6401e-01, -0.0000e+00]],\n",
      "\n",
      "        [[-0.0000e+00,  3.1558e-02,  0.0000e+00,  ..., -9.8456e-03,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [ 4.2344e-01, -0.0000e+00, -0.0000e+00,  ..., -6.8712e-01,\n",
      "           3.9619e+00, -0.0000e+00],\n",
      "         [-4.4081e-01,  5.2057e-01, -3.4106e+00,  ...,  0.0000e+00,\n",
      "           3.9029e-01,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  1.2380e+00,  1.3568e+00,  ..., -4.6393e-01,\n",
      "           0.0000e+00, -8.8541e-01],\n",
      "         [-1.8017e-01,  0.0000e+00, -0.0000e+00,  ...,  5.9272e-01,\n",
      "           9.1002e-01,  3.2228e+00],\n",
      "         [ 2.6853e+00, -0.0000e+00, -1.0771e+00,  ...,  2.1664e-01,\n",
      "          -0.0000e+00, -8.7837e-01]]], grad_fn=<MulBackward0>)\n",
      "tensor([[-1.5069, -0.0000, -0.0000,  ..., -0.0000,  0.4880, -0.0000],\n",
      "        [-0.0000,  0.8255, -0.0000,  ..., -0.0000,  0.0224, -0.0813],\n",
      "        [ 0.0845, -0.0000,  0.0000,  ...,  0.0000, -3.0579, -1.2754],\n",
      "        ...,\n",
      "        [-0.4015,  2.0303, -0.1216,  ..., -0.7758,  0.0092, -1.9704],\n",
      "        [ 1.5120, -0.0000, -0.4852,  ..., -1.9086,  0.5640, -0.0000],\n",
      "        [-0.0000,  0.0316,  0.0000,  ...,  0.2166, -0.0000, -0.8784]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-2.4374e-01,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -0.0000e+00, -4.3268e-01],\n",
      "         [ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ...,  8.1952e-02,\n",
      "           8.2655e-02,  1.3588e+00],\n",
      "         [ 5.2817e+00, -6.8880e-01,  1.1548e+00,  ...,  0.0000e+00,\n",
      "          -4.8761e+00, -1.2067e+00],\n",
      "         ...,\n",
      "         [-8.8361e-03, -5.1595e-01, -4.3720e-01,  ..., -1.9044e-01,\n",
      "           4.6954e-02,  4.7192e-01],\n",
      "         [-8.8000e-02,  9.4814e-02, -1.4814e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  1.9632e+00],\n",
      "         [-8.9555e-01, -0.0000e+00,  0.0000e+00,  ..., -1.6553e+00,\n",
      "           0.0000e+00, -1.9112e+00]],\n",
      "\n",
      "        [[-4.5565e+00,  1.7420e-01, -2.5665e-01,  ..., -0.0000e+00,\n",
      "           2.4136e-01, -1.9383e+00],\n",
      "         [-1.2121e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00,  3.6384e-01, -8.8016e-01,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.4462e-01,\n",
      "           0.0000e+00, -4.0210e+00],\n",
      "         [ 5.6285e-01,  0.0000e+00, -5.8608e+00,  ...,  1.8184e+00,\n",
      "          -0.0000e+00, -1.8364e-02],\n",
      "         [-1.9973e-01, -4.6080e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -1.3204e-01]],\n",
      "\n",
      "        [[ 3.0231e+00, -0.0000e+00,  4.7070e+00,  ..., -0.0000e+00,\n",
      "          -1.4985e+00,  3.5393e+00],\n",
      "         [-0.0000e+00,  9.5204e-02, -0.0000e+00,  ..., -1.3150e+00,\n",
      "           0.0000e+00,  3.4012e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -9.8347e-01,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 4.0567e+00, -2.5412e+00, -8.5295e-02,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -1.6215e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00, -0.0000e+00,  3.8289e-03,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000e+00, -0.0000e+00, -3.4711e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -2.2528e-01,  ...,  2.1120e-01,\n",
      "          -2.2612e-01, -0.0000e+00],\n",
      "         [ 0.0000e+00,  1.7410e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -1.8055e-01],\n",
      "         ...,\n",
      "         [ 1.2172e+00,  0.0000e+00, -3.8508e-01,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [ 2.8385e-01,  6.9582e-01,  0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -4.2157e-01,  ..., -6.5810e-02,\n",
      "          -3.4375e-01,  0.0000e+00]],\n",
      "\n",
      "        [[-0.0000e+00, -9.6139e-01, -1.3294e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [-1.1829e+00,  5.7033e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          -7.9144e-01, -9.6937e-01],\n",
      "         [ 4.5086e-01,  7.0237e-01,  0.0000e+00,  ..., -7.4505e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00,  0.0000e+00, -4.0910e-02,  ..., -5.1475e-01,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00,  4.3202e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           3.0633e-01,  0.0000e+00],\n",
      "         [-1.1490e-01, -0.0000e+00,  3.8451e+00,  ..., -1.4429e+00,\n",
      "           0.0000e+00, -1.3382e+00]],\n",
      "\n",
      "        [[-0.0000e+00, -0.0000e+00,  1.7544e+00,  ...,  9.8380e-01,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-1.2997e+00,  3.7823e+00, -0.0000e+00,  ...,  1.6170e-02,\n",
      "          -0.0000e+00,  3.5372e-01],\n",
      "         [-5.4673e-01,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           1.1701e+00,  1.5452e-01],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -1.6021e-01,\n",
      "          -0.0000e+00, -1.8125e+00],\n",
      "         [-0.0000e+00,  1.7476e-01, -9.4909e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00, -3.2162e+00,  0.0000e+00,  ..., -1.8818e+00,\n",
      "           1.3961e-01, -0.0000e+00]]], grad_fn=<MulBackward0>)\n",
      "tensor([[-0.2437,  0.0000, -0.0000,  ..., -1.6553,  0.0000, -1.9112],\n",
      "        [-4.5565,  0.1742, -0.2567,  ..., -0.0000, -0.0000, -0.1320],\n",
      "        [ 3.0231, -0.0000,  4.7070,  ..., -0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.0000, -0.0000, -3.4711,  ..., -0.0658, -0.3437,  0.0000],\n",
      "        [-0.0000, -0.9614, -1.3294,  ..., -1.4429,  0.0000, -1.3382],\n",
      "        [-0.0000, -0.0000,  1.7544,  ..., -1.8818,  0.1396, -0.0000]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.1252,  0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.3325],\n",
      "         [-0.7297, -0.0000, -1.0211,  ...,  0.0000, -0.5617, -0.0000],\n",
      "         [-0.5622,  0.0000, -0.0000,  ...,  0.0000,  0.9038,  0.0913],\n",
      "         ...,\n",
      "         [-0.0000, -0.8468, -0.6659,  ...,  5.2966, -0.0000,  0.0000],\n",
      "         [-0.0000,  0.4104, -0.0000,  ..., -0.5924,  0.0000,  0.3459],\n",
      "         [-0.9330, -0.0000,  0.0000,  ..., -0.7598, -0.0000, -0.1337]],\n",
      "\n",
      "        [[-0.0000, -1.0385,  0.4185,  ...,  4.3734,  0.3947, -0.0000],\n",
      "         [-0.0000, -1.2598, -0.0000,  ..., -0.6857, -0.0000, -0.3208],\n",
      "         [-0.0000, -0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 3.3433, -0.3095,  2.8982,  ..., -1.7688, -2.8301, -0.0000],\n",
      "         [ 0.0000,  0.0735, -0.0000,  ...,  0.4073,  0.3404,  2.1275],\n",
      "         [-0.0164,  0.0000, -0.4433,  ...,  0.0000,  0.0000, -5.1217]],\n",
      "\n",
      "        [[-0.6602, -0.2147, -0.0000,  ...,  0.1275, -0.0000, -0.0903],\n",
      "         [ 2.2297, -0.0000, -0.0000,  ..., -1.0504,  2.5503, -0.0000],\n",
      "         [-0.0000, -1.7398,  0.0750,  ...,  0.0000,  0.0000, -0.0000],\n",
      "         ...,\n",
      "         [ 3.5583, -1.3466, -0.2615,  ..., -0.0000, -0.0879, -0.0000],\n",
      "         [-0.9701,  0.0000, -3.7396,  ...,  0.2059, -0.4237, -0.0000],\n",
      "         [-6.3740,  0.2660,  0.0000,  ...,  0.4626,  0.5913,  3.2299]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000,  0.3248, -0.0000,  ...,  1.7363, -0.2348, -0.0000],\n",
      "         [-0.0000,  0.2594, -0.0000,  ...,  0.0000, -5.7079,  1.4761],\n",
      "         [-1.0567,  0.0000, -0.0000,  ...,  1.0575,  0.0548,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000, -0.3100,  3.7420,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [-0.3625, -0.0000, -0.0000,  ..., -0.7514, -0.1251, -1.0356],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.0373]],\n",
      "\n",
      "        [[ 0.0000, -3.0479,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0000,  6.5398,  0.0000,  ..., -0.0000, -0.0000, -0.3424],\n",
      "         [-1.5102,  0.0000,  0.4654,  ..., -0.7188, -0.0000, -0.9306],\n",
      "         ...,\n",
      "         [ 6.0446,  0.0000, -0.2669,  ..., -0.2444,  0.0000,  1.5940],\n",
      "         [ 4.6860, -1.3387,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "         [-0.0000, -0.0000, -0.0000,  ..., -1.1801, -0.0000,  0.1615]],\n",
      "\n",
      "        [[-0.9994, -0.0000, -0.0000,  ...,  0.0000, -0.0170,  0.0000],\n",
      "         [-0.0000, -0.8919,  2.1771,  ...,  0.0000,  0.1211,  0.0000],\n",
      "         [-0.2106,  1.3581, -5.0063,  ...,  0.1553,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 2.5400, -0.4347,  5.7872,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [-0.0000, -0.0000, -0.0000,  ...,  0.0000,  0.0000,  3.2714],\n",
      "         [-0.0000,  0.0000,  3.3127,  ..., -0.0000, -0.8719, -0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-0.1252,  0.0000, -0.0000,  ..., -0.7598, -0.0000, -0.1337],\n",
      "        [-0.0000, -1.0385,  0.4185,  ...,  0.0000,  0.0000, -5.1217],\n",
      "        [-0.6602, -0.2147, -0.0000,  ...,  0.4626,  0.5913,  3.2299],\n",
      "        ...,\n",
      "        [-0.0000,  0.3248, -0.0000,  ..., -0.0000,  0.0000, -0.0373],\n",
      "        [ 0.0000, -3.0479,  0.0000,  ..., -1.1801, -0.0000,  0.1615],\n",
      "        [-0.9994, -0.0000, -0.0000,  ..., -0.0000, -0.8719, -0.0000]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-1.3149e+00,  0.0000e+00,  3.8650e-01,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [-0.0000e+00,  5.9573e-01, -0.0000e+00,  ..., -1.1166e-01,\n",
      "           5.8341e+00, -2.2565e-02],\n",
      "         [-7.1864e-01,  3.6493e-01, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -1.6696e+00,  5.3626e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          -3.6366e+00,  2.0483e-01],\n",
      "         [-0.0000e+00,  8.3267e-01,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00, -1.0226e-01],\n",
      "         [-3.1213e-01, -0.0000e+00, -9.7580e-01,  ..., -1.7010e+00,\n",
      "          -4.3536e-01, -3.6785e-01]],\n",
      "\n",
      "        [[-0.0000e+00,  4.7630e+00, -9.1397e-01,  ..., -4.6764e-01,\n",
      "          -5.2123e-01, -1.2053e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -4.7305e-01,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -7.6831e-02],\n",
      "         [ 6.0524e-02,  0.0000e+00, -0.0000e+00,  ..., -6.4923e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  0.0000e+00,  2.8264e-01,  ...,  6.0389e-01,\n",
      "           5.7500e-01,  5.6115e-01],\n",
      "         [-0.0000e+00,  0.0000e+00, -6.3154e-01,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  2.0728e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -6.0612e-01,  ...,  0.0000e+00,\n",
      "           9.2502e-01,  6.4783e-01]],\n",
      "\n",
      "        [[-2.2713e+00,  1.8437e-01, -0.0000e+00,  ..., -1.2636e-01,\n",
      "          -4.1516e-01, -4.8242e-02],\n",
      "         [-4.8087e+00, -1.1060e-02, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           9.0110e-01,  0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -3.2000e-02,\n",
      "           6.6564e-01,  8.3508e-01],\n",
      "         ...,\n",
      "         [ 7.1002e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -9.5508e-01,  0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  5.2654e-03,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00, -1.0380e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -4.4572e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-4.0613e+00,  0.0000e+00,  8.2625e-02,  ...,  0.0000e+00,\n",
      "          -0.0000e+00,  5.0384e-01],\n",
      "         [-1.7035e+00, -0.0000e+00,  2.0451e+00,  ..., -3.6559e+00,\n",
      "          -1.2992e+00, -1.0155e+00],\n",
      "         [-0.0000e+00,  6.4434e-01,  5.2136e+00,  ..., -3.7173e-01,\n",
      "           2.9604e-01, -2.0717e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00, -1.7225e-01,  0.0000e+00,  ...,  1.2356e-01,\n",
      "          -5.2563e-02,  2.3571e-01],\n",
      "         [-1.6871e+00,  0.0000e+00,  0.0000e+00,  ...,  2.3476e-01,\n",
      "           9.8544e-01,  0.0000e+00],\n",
      "         [-0.0000e+00,  3.2306e-01, -1.1564e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00, -3.8898e+00]],\n",
      "\n",
      "        [[ 0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -1.8517e-01,\n",
      "           0.0000e+00, -4.3522e+00],\n",
      "         [-0.0000e+00, -0.0000e+00, -9.7147e-01,  ...,  0.0000e+00,\n",
      "          -1.9003e+00,  0.0000e+00],\n",
      "         [ 1.8941e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           4.7108e-01,  2.1518e-01],\n",
      "         ...,\n",
      "         [-1.9592e-01,  1.2539e+00,  0.0000e+00,  ...,  6.4175e-01,\n",
      "          -0.0000e+00, -1.1227e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -6.5693e-02,  ...,  3.5682e-01,\n",
      "          -3.5746e-01,  1.8453e-01],\n",
      "         [ 0.0000e+00, -7.2452e-01, -0.0000e+00,  ..., -1.6830e+00,\n",
      "           6.6363e-02, -0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  1.4221e-01,  0.0000e+00,  ..., -0.0000e+00,\n",
      "           6.9947e-02,  4.2106e-01],\n",
      "         [-0.0000e+00, -6.4747e-01, -1.7322e+00,  ...,  1.6222e+00,\n",
      "          -9.5895e-01,  5.4516e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -3.7076e-01,  ...,  1.6420e-01,\n",
      "           6.1257e-01,  0.0000e+00],\n",
      "         ...,\n",
      "         [-2.6599e+00, -0.0000e+00, -6.6061e-01,  ..., -1.2122e+00,\n",
      "          -4.3319e-01,  0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -2.5580e-01,\n",
      "           9.4923e-02,  1.6273e-01],\n",
      "         [-2.5140e-02,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00]]], grad_fn=<MulBackward0>)\n",
      "tensor([[-1.3149,  0.0000,  0.3865,  ..., -1.7010, -0.4354, -0.3679],\n",
      "        [-0.0000,  4.7630, -0.9140,  ...,  0.0000,  0.9250,  0.6478],\n",
      "        [-2.2713,  0.1844, -0.0000,  ..., -0.0000,  0.0000, -4.4572],\n",
      "        ...,\n",
      "        [-4.0613,  0.0000,  0.0826,  ...,  0.0000,  0.0000, -3.8898],\n",
      "        [ 0.0000, -0.0000,  0.0000,  ..., -1.6830,  0.0664, -0.0000],\n",
      "        [ 0.0000,  0.1422,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[ 4.1567, -5.9420, -3.5940,  ...,  0.0000,  0.0000, -0.0000],\n",
      "         [-0.5459, -0.0000,  0.2864,  ..., -0.0000,  0.3103, -1.8159],\n",
      "         [-5.6726,  0.5822, -1.0179,  ...,  0.3037,  0.0000, -0.0000],\n",
      "         ...,\n",
      "         [-0.0000,  0.2495,  0.0000,  ..., -0.0000, -0.0000, -0.1174],\n",
      "         [-0.3531,  0.0000, -0.3425,  ...,  0.5320,  0.0000,  0.4854],\n",
      "         [-0.0000, -2.5562, -0.0000,  ..., -0.0000, -1.1621, -0.0903]],\n",
      "\n",
      "        [[-0.0744,  1.6332, -0.0000,  ...,  4.2256,  0.1343,  0.0000],\n",
      "         [-0.0000,  0.0993, -0.1690,  ..., -4.3601,  0.0000, -0.0000],\n",
      "         [-0.0000,  1.1742, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "         ...,\n",
      "         [-0.8188,  0.5352, -2.7978,  ...,  0.0000, -0.0000,  1.8888],\n",
      "         [ 0.0000, -4.0758,  0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "         [-0.7349, -2.3620, -0.0000,  ...,  1.0641, -0.7055, -0.0000]],\n",
      "\n",
      "        [[ 0.4094,  0.0000,  0.2518,  ...,  2.0319, -3.9377,  0.0000],\n",
      "         [-2.4247,  0.0000, -1.8328,  ...,  0.0000,  0.1697,  3.7652],\n",
      "         [-0.5662, -0.3160, -2.0323,  ..., -0.0000,  0.0000, -0.0000],\n",
      "         ...,\n",
      "         [-0.4174,  0.1522, -0.2185,  ...,  1.7376, -0.0000,  0.0000],\n",
      "         [ 0.0000, -0.0000, -0.2345,  ..., -0.4876, -0.0000,  0.4577],\n",
      "         [-1.7199, -0.9012, -0.0000,  ..., -0.2142, -0.2031, -0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0000, -0.0000,  0.0000,  ...,  0.3968, -0.0000,  3.2522],\n",
      "         [-0.0000, -0.0840,  0.0000,  ..., -0.0000,  0.0000, -2.1348],\n",
      "         [-0.0000,  0.0000, -0.2774,  ..., -5.0006,  0.0000, -0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.7654, -0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "         [-0.0000,  0.0000, -0.0000,  ...,  0.2707, -0.0000, -0.0000],\n",
      "         [ 0.0000,  0.8286,  0.1434,  ...,  0.0000, -0.0000,  0.1146]],\n",
      "\n",
      "        [[ 0.4367,  0.0000, -0.0000,  ...,  0.1838,  0.0000,  0.0000],\n",
      "         [ 0.0000, -0.0000, -0.3563,  ..., -0.0000,  0.7767, -1.2665],\n",
      "         [ 0.2930,  2.4647, -0.1659,  ...,  0.7599, -0.1649,  1.2853],\n",
      "         ...,\n",
      "         [-0.3199,  0.4917, -0.2602,  ...,  0.0000, -0.5595, -0.0000],\n",
      "         [-0.6364, -0.5554, -1.3856,  ...,  0.3090,  0.2224,  4.1375],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "        [[-0.5800,  0.2789,  0.1240,  ...,  1.0830, -0.6842,  0.0000],\n",
      "         [-0.0000,  0.0000,  2.5329,  ..., -1.8724, -0.6018, -0.0000],\n",
      "         [-0.0000,  2.5665, -0.0000,  ..., -2.8123, -0.0616, -0.0000],\n",
      "         ...,\n",
      "         [-0.0986,  1.4061, -1.3218,  ..., -0.0000, -2.6893, -0.0000],\n",
      "         [ 0.0000, -0.3555, -0.0000,  ...,  0.0651, -0.3036, -0.0000],\n",
      "         [-0.9484,  0.9879,  0.0000,  ..., -1.9066,  0.1105, -2.4151]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[ 4.1567, -5.9420, -3.5940,  ..., -0.0000, -1.1621, -0.0903],\n",
      "        [-0.0744,  1.6332, -0.0000,  ...,  1.0641, -0.7055, -0.0000],\n",
      "        [ 0.4094,  0.0000,  0.2518,  ..., -0.2142, -0.2031, -0.0000],\n",
      "        ...,\n",
      "        [ 0.0000, -0.0000,  0.0000,  ...,  0.0000, -0.0000,  0.1146],\n",
      "        [ 0.4367,  0.0000, -0.0000,  ...,  0.0000, -0.0000, -0.0000],\n",
      "        [-0.5800,  0.2789,  0.1240,  ..., -1.9066,  0.1105, -2.4151]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.6801, -0.0000, -0.0000,  ...,  0.0000, -0.4389,  8.0500],\n",
      "         [-0.6984, -0.0000, -0.1230,  ..., -0.0000, -0.5010, -2.9160],\n",
      "         [-0.5251, -0.2320, -0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.4729,  0.0122, -0.0000,  ..., -0.0000, -1.5956, -1.9370],\n",
      "         [ 0.0000,  0.2806,  0.5183,  ...,  2.2948,  0.4724,  0.0459],\n",
      "         [ 0.0000, -0.0000,  4.4897,  ..., -0.0000, -0.0000, -2.6475]],\n",
      "\n",
      "        [[ 0.0000, -0.0000, -0.0000,  ...,  0.0000, -0.3376, -0.6958],\n",
      "         [ 0.2112, -0.0000,  0.6040,  ...,  0.0864, -0.0000, -0.0000],\n",
      "         [-0.2451,  0.0000, -0.0459,  ...,  0.5813,  0.2332,  0.0000],\n",
      "         ...,\n",
      "         [ 0.3214,  0.0000, -0.1518,  ...,  0.0901,  0.0000,  0.8981],\n",
      "         [-0.7427,  0.0000,  0.3659,  ...,  0.0000,  0.4898,  0.4072],\n",
      "         [-0.2753,  0.0000,  0.2025,  ...,  0.9145, -0.0000,  0.0000]],\n",
      "\n",
      "        [[-1.0741,  3.9191,  0.9804,  ..., -0.0000,  0.3938, -3.8995],\n",
      "         [-0.0000,  2.6660, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "         [-0.0448, -0.0000, -0.4417,  ..., -0.0651, -0.0000, -0.0000],\n",
      "         ...,\n",
      "         [-0.0268, -0.0000, -0.0000,  ...,  0.7705, -0.0000,  0.1375],\n",
      "         [-5.0549,  0.0263, -0.3811,  ..., -1.0419,  0.0000, -0.1303],\n",
      "         [ 0.0000,  0.1484, -0.5313,  ..., -0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000,  0.1004, -0.0000,  ..., -1.1846,  0.0000, -2.0039],\n",
      "         [-3.0934, -0.2227,  0.0000,  ...,  0.2571, -0.7821,  7.7358],\n",
      "         [ 1.2827,  0.2415, -0.0000,  ...,  0.0629,  0.2305,  0.2966],\n",
      "         ...,\n",
      "         [-0.0000,  0.0000, -1.1569,  ..., -0.0847,  0.5812, -0.5055],\n",
      "         [-0.0000, -3.5361, -1.0713,  ...,  0.2091, -0.1946, -0.3597],\n",
      "         [ 3.9993,  0.0000, -0.0000,  ...,  0.7077, -0.3084, -2.8082]],\n",
      "\n",
      "        [[-0.0000, -4.9847,  0.0000,  ..., -0.0611, -0.8975, -0.0307],\n",
      "         [-0.8515,  0.0000, -0.6021,  ..., -2.2307, -0.0000, -0.0000],\n",
      "         [-5.5062, -0.0447, -1.2270,  ..., -0.3378,  0.0000, -0.0239],\n",
      "         ...,\n",
      "         [-0.5939, -0.0000, -1.5089,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [-0.7670,  0.0000, -0.0000,  ..., -0.5706,  0.0000, -0.7596],\n",
      "         [-0.0000, -0.6147,  4.6207,  ..., -0.4560, -0.0000, -2.9729]],\n",
      "\n",
      "        [[ 0.3435,  0.0000, -0.0000,  ...,  1.1436,  0.0610, -0.4817],\n",
      "         [ 0.0000,  0.0000, -0.4759,  ...,  0.0000, -0.4773, -0.0000],\n",
      "         [ 0.3228, -2.0346, -0.0000,  ..., -0.0000, -0.5604, -0.5547],\n",
      "         ...,\n",
      "         [ 0.1342, -2.4164, -0.4409,  ...,  0.3749,  0.1246, -0.0000],\n",
      "         [-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.7285, -0.0469],\n",
      "         [-0.5456,  0.5104,  0.3300,  ...,  0.0404,  0.0000, -1.8485]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-0.6801, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -2.6475],\n",
      "        [ 0.0000, -0.0000, -0.0000,  ...,  0.9145, -0.0000,  0.0000],\n",
      "        [-1.0741,  3.9191,  0.9804,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        ...,\n",
      "        [-0.0000,  0.1004, -0.0000,  ...,  0.7077, -0.3084, -2.8082],\n",
      "        [-0.0000, -4.9847,  0.0000,  ..., -0.4560, -0.0000, -2.9729],\n",
      "        [ 0.3435,  0.0000, -0.0000,  ...,  0.0404,  0.0000, -1.8485]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00, -2.9643e+00],\n",
      "         [-7.2466e-01, -0.0000e+00, -6.3664e-01,  ..., -3.2922e-01,\n",
      "          -0.0000e+00,  4.1455e+00],\n",
      "         [-1.7690e+00,  0.0000e+00,  1.4806e-02,  ...,  1.6960e-01,\n",
      "          -0.0000e+00,  6.4217e-01],\n",
      "         ...,\n",
      "         [ 6.3574e-02, -0.0000e+00, -2.9865e-01,  ..., -1.2873e+00,\n",
      "           3.2575e-02, -0.0000e+00],\n",
      "         [-3.7689e-01, -4.4220e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -1.1595e+00, -0.0000e+00],\n",
      "         [-0.0000e+00, -1.2232e+00, -9.5947e-01,  ..., -0.0000e+00,\n",
      "          -1.2475e-01,  7.7946e-02]],\n",
      "\n",
      "        [[-2.1030e+00, -0.0000e+00, -1.0622e+00,  ..., -0.0000e+00,\n",
      "           1.0012e+00,  3.5108e-01],\n",
      "         [-1.4011e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -0.0000e+00,  3.3974e-01],\n",
      "         [ 6.4301e-02,  0.0000e+00,  2.0590e+00,  ..., -2.4710e-02,\n",
      "           4.8007e-01, -4.2399e-01],\n",
      "         ...,\n",
      "         [-2.6664e-01, -5.2516e-02,  6.2369e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -3.9574e-01],\n",
      "         [-3.7460e-01,  1.4696e-01, -2.1676e-01,  ...,  2.2034e-01,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -1.4403e+00,\n",
      "          -2.2025e-01, -4.4325e-01]],\n",
      "\n",
      "        [[-1.2289e+00, -0.0000e+00, -3.0152e-01,  ..., -0.0000e+00,\n",
      "           5.5097e-01,  1.7768e-01],\n",
      "         [-1.8114e+00, -2.3422e+00, -0.0000e+00,  ..., -2.6515e+00,\n",
      "           3.4752e+00,  4.7068e-02],\n",
      "         [-0.0000e+00, -0.0000e+00, -2.8321e+00,  ..., -1.9948e-01,\n",
      "           0.0000e+00,  3.4004e-01],\n",
      "         ...,\n",
      "         [-2.5319e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "           2.2895e+00, -1.1873e-01],\n",
      "         [-0.0000e+00, -0.0000e+00,  3.4464e+00,  ..., -0.0000e+00,\n",
      "          -3.3337e-01, -4.9310e-01],\n",
      "         [ 3.3252e+00, -0.0000e+00,  0.0000e+00,  ..., -1.7090e+00,\n",
      "          -0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 7.1275e-01, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  5.3817e-01],\n",
      "         [ 2.9138e-02, -7.0186e-01, -1.2652e+00,  ...,  4.0230e-01,\n",
      "          -4.3311e+00,  0.0000e+00],\n",
      "         [-3.7315e-01,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -6.6845e-01, -5.9019e-01],\n",
      "         ...,\n",
      "         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -9.0784e-01, -4.6455e-01],\n",
      "         [-5.9274e+00, -0.0000e+00, -4.2919e-01,  ...,  1.2596e-01,\n",
      "          -4.7962e-01, -3.1501e-01],\n",
      "         [-7.9782e-02, -0.0000e+00, -0.0000e+00,  ..., -8.6063e-01,\n",
      "           4.9074e-03, -1.6734e+00]],\n",
      "\n",
      "        [[-6.9679e+00, -0.0000e+00, -2.6401e-01,  ...,  3.8461e+00,\n",
      "           9.4595e-02,  1.9514e-01],\n",
      "         [-0.0000e+00, -6.8105e-01, -2.7689e-01,  ...,  2.9614e-01,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-8.0876e-01,  0.0000e+00, -2.8434e-01,  ...,  0.0000e+00,\n",
      "          -0.0000e+00,  1.4571e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -0.0000e+00,  3.8212e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00, -2.9204e+00],\n",
      "         [-7.2481e-01,  0.0000e+00, -2.7154e+00,  ...,  0.0000e+00,\n",
      "          -9.1249e-01,  2.6010e+00],\n",
      "         [ 9.8911e-02,  1.2272e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          -6.9807e-02, -4.0446e+00]],\n",
      "\n",
      "        [[-0.0000e+00, -0.0000e+00, -1.3347e+00,  ..., -0.0000e+00,\n",
      "          -8.0590e-01, -0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -1.7918e-01,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-2.3134e+00,  0.0000e+00, -0.0000e+00,  ...,  4.2384e-01,\n",
      "           1.1796e-01, -0.0000e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -4.4612e-01,\n",
      "          -2.0492e+00,  2.7121e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  2.0937e+00],\n",
      "         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -3.2232e-01,\n",
      "           0.0000e+00, -0.0000e+00]]], grad_fn=<MulBackward0>)\n",
      "tensor([[-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "         -1.2475e-01,  7.7946e-02],\n",
      "        [-2.1030e+00, -0.0000e+00, -1.0622e+00,  ..., -1.4403e+00,\n",
      "         -2.2025e-01, -4.4325e-01],\n",
      "        [-1.2289e+00, -0.0000e+00, -3.0152e-01,  ..., -1.7090e+00,\n",
      "         -0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 7.1275e-01, -0.0000e+00, -0.0000e+00,  ..., -8.6063e-01,\n",
      "          4.9074e-03, -1.6734e+00],\n",
      "        [-6.9679e+00, -0.0000e+00, -2.6401e-01,  ...,  0.0000e+00,\n",
      "         -6.9807e-02, -4.0446e+00],\n",
      "        [-0.0000e+00, -0.0000e+00, -1.3347e+00,  ..., -3.2232e-01,\n",
      "          0.0000e+00, -0.0000e+00]], grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.0000e+00,  1.1554e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00, -6.0945e-01],\n",
      "         [-2.6658e+00, -0.0000e+00,  0.0000e+00,  ...,  1.7280e-01,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -7.8290e-01,  ..., -5.8011e+00,\n",
      "          -1.9428e-01, -0.0000e+00],\n",
      "         ...,\n",
      "         [-6.6330e+00,  0.0000e+00, -4.2518e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  6.0890e-01],\n",
      "         [ 0.0000e+00,  1.2763e+00, -6.9529e-01,  ..., -2.1117e-01,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-3.9794e-01,  0.0000e+00, -6.9254e-02,  ...,  1.7623e-01,\n",
      "           1.4082e-01,  0.0000e+00]],\n",
      "\n",
      "        [[-0.0000e+00,  0.0000e+00, -8.1126e-02,  ..., -0.0000e+00,\n",
      "           7.7940e-01, -3.0761e+00],\n",
      "         [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          -1.7372e-01,  2.3340e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          -3.0269e+00, -5.2745e-01],\n",
      "         ...,\n",
      "         [-0.0000e+00,  3.9793e+00, -1.2771e-01,  ..., -3.5620e-02,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [-2.2372e+00,  3.5077e+00,  4.5115e+00,  ..., -1.6216e-01,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           1.6217e-03,  2.2745e-01]],\n",
      "\n",
      "        [[ 6.6115e-01,  0.0000e+00, -5.8303e-02,  ..., -0.0000e+00,\n",
      "           2.7105e-01,  0.0000e+00],\n",
      "         [-1.0282e+00, -2.6036e+00, -0.0000e+00,  ...,  4.7043e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [-6.5589e-01,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -3.2922e-01,  0.0000e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00, -1.1736e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -1.2263e+00, -0.0000e+00],\n",
      "         [-7.5265e+00,  0.0000e+00, -4.1115e-01,  ...,  0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [-0.0000e+00,  2.1010e-01, -4.2948e-01,  ...,  3.9919e-01,\n",
      "          -8.5106e-01, -0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000e+00,  1.3550e+00,  4.0302e-01,  ...,  8.8489e-02,\n",
      "           0.0000e+00, -3.8426e+00],\n",
      "         [-0.0000e+00, -0.0000e+00, -2.8561e-01,  ..., -2.9997e-02,\n",
      "           3.0799e-01, -0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  3.5258e-01,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [ 3.2677e+00, -7.2480e-01,  2.7737e-02,  ..., -0.0000e+00,\n",
      "          -3.3448e-01, -1.2225e+00],\n",
      "         [-5.8175e-01,  0.0000e+00, -3.2419e-01,  ..., -0.0000e+00,\n",
      "          -8.3883e-01,  0.0000e+00],\n",
      "         [-6.5487e-01,  0.0000e+00, -0.0000e+00,  ..., -8.6590e-01,\n",
      "          -0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "        [[-0.0000e+00,  0.0000e+00, -3.5993e-01,  ..., -0.0000e+00,\n",
      "          -3.0698e-01, -7.0959e-02],\n",
      "         [-5.3301e-01, -0.0000e+00, -7.1482e-01,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  2.5797e-01,\n",
      "          -0.0000e+00, -6.0456e-01],\n",
      "         ...,\n",
      "         [ 2.8257e+00,  9.3079e-01,  0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -5.9858e-01],\n",
      "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -8.7418e-01,  4.5614e+00],\n",
      "         [-8.0561e-01,  7.5856e-02, -0.0000e+00,  ..., -1.2098e+00,\n",
      "          -1.0453e+00, -0.0000e+00]],\n",
      "\n",
      "        [[-0.0000e+00, -3.3931e-01,  5.4239e+00,  ...,  3.6811e+00,\n",
      "          -3.4506e-01, -0.0000e+00],\n",
      "         [ 1.1191e+00, -0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -5.8255e-01, -1.6990e-01],\n",
      "         [-9.6437e-01, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00, -1.6198e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -3.0521e-02],\n",
      "         [-1.0313e+00,  1.6851e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -6.1434e-01,  ...,  2.8405e-01,\n",
      "          -0.0000e+00, -0.0000e+00]]], grad_fn=<MulBackward0>)\n",
      "tensor([[-0.0000e+00,  1.1554e+00,  0.0000e+00,  ...,  1.7623e-01,\n",
      "          1.4082e-01,  0.0000e+00],\n",
      "        [-0.0000e+00,  0.0000e+00, -8.1126e-02,  ..., -0.0000e+00,\n",
      "          1.6217e-03,  2.2745e-01],\n",
      "        [ 6.6115e-01,  0.0000e+00, -5.8303e-02,  ...,  3.9919e-01,\n",
      "         -8.5106e-01, -0.0000e+00],\n",
      "        ...,\n",
      "        [-0.0000e+00,  1.3550e+00,  4.0302e-01,  ..., -8.6590e-01,\n",
      "         -0.0000e+00, -0.0000e+00],\n",
      "        [-0.0000e+00,  0.0000e+00, -3.5993e-01,  ..., -1.2098e+00,\n",
      "         -1.0453e+00, -0.0000e+00],\n",
      "        [-0.0000e+00, -3.3931e-01,  5.4239e+00,  ...,  2.8405e-01,\n",
      "         -0.0000e+00, -0.0000e+00]], grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.0000,  0.1543, -0.0000,  ..., -0.0000, -0.0000,  0.0525],\n",
      "         [-0.0000,  1.5106, -0.0000,  ...,  0.2642,  0.0000,  0.5954],\n",
      "         [-0.0000,  0.0000, -0.0000,  ...,  1.3929, -0.5354, -0.5115],\n",
      "         ...,\n",
      "         [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -1.7188, -0.5342],\n",
      "         [-0.0000,  0.0000,  0.0000,  ...,  0.3317,  0.0930,  2.6075],\n",
      "         [ 5.7267, -0.0000, -0.0493,  ...,  0.0649, -1.6689, -2.1362]],\n",
      "\n",
      "        [[ 0.1858, -2.5066, -0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-6.4355,  1.0922, -2.2928,  ...,  0.5347,  0.0000,  0.0000],\n",
      "         [-0.0000, -0.3389, -0.7052,  ..., -1.0620,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000, -0.0000, -0.0324,  ..., -0.2353,  1.1831,  4.4062],\n",
      "         [-0.2157,  0.3416,  0.0000,  ..., -0.0000,  0.0000, -3.0164],\n",
      "         [-0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "        [[-0.9569,  5.6452, -0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "         [-0.0000, -0.4001, -3.1303,  ..., -0.0798, -0.0000,  5.0140],\n",
      "         [ 1.1258,  0.0862, -0.0000,  ...,  0.0000, -0.3749,  0.0000],\n",
      "         ...,\n",
      "         [ 4.5769,  0.0000, -0.0556,  ...,  0.1021,  0.0000, -0.0000],\n",
      "         [ 0.1206,  0.2198, -0.0000,  ..., -0.0000, -0.8584, -1.1698],\n",
      "         [-0.0405,  1.5925,  0.0000,  ...,  1.1528,  0.0000, -2.9339]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000, -0.0000, -0.1929,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [-0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.3783, -0.0000],\n",
      "         [-0.0000,  1.9924, -0.0000,  ..., -0.1711,  0.0000,  1.6916],\n",
      "         ...,\n",
      "         [-0.0000, -2.3532,  0.0000,  ..., -0.0241, -0.1071, -0.0000],\n",
      "         [-4.4069, -0.1975, -0.3200,  ...,  0.0447,  0.7929, -0.5728],\n",
      "         [-0.3033, -0.0000, -0.0000,  ..., -0.0000, -1.2267, -0.0000]],\n",
      "\n",
      "        [[-0.0000, -0.0000, -4.3895,  ...,  0.0000,  0.0000,  2.9538],\n",
      "         [-8.0159,  0.0000, -0.1307,  ..., -0.0000,  0.2492,  0.0000],\n",
      "         [-0.0000, -0.3222, -1.1044,  ...,  2.7689, -0.0000,  2.7831],\n",
      "         ...,\n",
      "         [-2.4861,  0.0000,  3.4995,  ...,  0.9781, -0.0000, -0.0000],\n",
      "         [-0.0338,  0.0000, -0.3270,  ...,  0.4967, -0.0000,  2.8271],\n",
      "         [-1.1770,  0.0414,  0.0720,  ..., -0.3062,  0.0000, -0.0000]],\n",
      "\n",
      "        [[-1.1224,  0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [-0.0000,  0.8281,  0.2503,  ...,  5.0159,  0.4391,  0.0000],\n",
      "         [-3.8544, -1.5696, -0.0000,  ..., -0.0000, -2.2976,  0.0000],\n",
      "         ...,\n",
      "         [-0.0000,  0.0000, -0.9068,  ..., -0.0000, -0.0000,  0.8171],\n",
      "         [-4.7508, -0.0000, -0.9394,  ..., -0.3307, -0.0000, -0.9822],\n",
      "         [-0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -2.2625]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-0.0000,  0.1543, -0.0000,  ...,  0.0649, -1.6689, -2.1362],\n",
      "        [ 0.1858, -2.5066, -0.0000,  ..., -0.0000,  0.0000, -0.0000],\n",
      "        [-0.9569,  5.6452, -0.0000,  ...,  1.1528,  0.0000, -2.9339],\n",
      "        ...,\n",
      "        [-0.0000, -0.0000, -0.1929,  ..., -0.0000, -1.2267, -0.0000],\n",
      "        [-0.0000, -0.0000, -4.3895,  ..., -0.3062,  0.0000, -0.0000],\n",
      "        [-1.1224,  0.0000, -0.0000,  ..., -0.0000,  0.0000, -2.2625]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.0000, -0.3243, -0.6721,  ...,  0.6166, -0.0000, -0.4819],\n",
      "         [-0.0000, -0.7038, -0.0000,  ...,  0.0000, -0.0000,  1.7604],\n",
      "         [-1.4158,  0.0364, -0.0000,  ..., -0.0000,  0.3308, -0.0000],\n",
      "         ...,\n",
      "         [ 0.0000, -0.0000, -1.6344,  ...,  0.2170, -0.0000,  1.7650],\n",
      "         [ 0.0000,  0.5953,  0.2003,  ..., -0.0000, -0.0000,  0.0000],\n",
      "         [ 0.0000,  1.9309, -1.3086,  ..., -0.0000, -0.0000, -0.7566]],\n",
      "\n",
      "        [[-0.6825, -0.1692, -6.9895,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.2735, -2.9393,  1.4910,  ..., -0.0000,  0.0096, -4.4673],\n",
      "         [ 4.5915,  0.5553, -0.0000,  ...,  0.2818,  0.4306, -0.0000],\n",
      "         ...,\n",
      "         [-1.8579,  0.3074,  0.0000,  ...,  0.6098,  0.0000,  0.0000],\n",
      "         [-0.0000,  0.0264, -0.6118,  ..., -0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000, -0.0000,  0.0088,  ...,  0.0000,  0.2799, -0.0000]],\n",
      "\n",
      "        [[-0.0000, -2.4672,  0.0000,  ...,  0.2659, -0.0000,  1.3358],\n",
      "         [ 0.0000,  0.4493, -0.0000,  ...,  0.0000, -1.2941, -0.4154],\n",
      "         [-0.6929, -0.0000, -0.0000,  ..., -0.0000, -1.9686,  0.5698],\n",
      "         ...,\n",
      "         [-0.2507, -0.0000, -0.2023,  ..., -0.0000, -0.9505, -0.0000],\n",
      "         [ 0.0000,  2.7211, -1.4997,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 3.8508, -0.0000, -0.1822,  ..., -0.4546, -1.0051, -1.4223]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000, -0.4521, -0.3311,  ..., -0.9406, -0.0000, -0.0000],\n",
      "         [-0.0000,  1.7233, -0.0000,  ..., -1.0889,  0.0843,  0.0000],\n",
      "         [-0.0000, -0.8697, -0.0000,  ..., -0.0000, -1.7527,  2.3835],\n",
      "         ...,\n",
      "         [ 3.9752, -2.2129, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "         [-0.0000, -0.4327, -0.0000,  ..., -0.5270, -0.5566, -0.9715],\n",
      "         [-0.0000, -0.1884, -2.0455,  ..., -0.0000,  0.0926,  0.1005]],\n",
      "\n",
      "        [[ 0.5819,  0.7969, -0.0000,  ...,  0.2996,  0.0000,  0.0000],\n",
      "         [-0.0000, -0.0000, -0.0000,  ..., -0.0269,  0.3061,  0.0000],\n",
      "         [-1.2621,  0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000, -0.7020, -1.4711,  ..., -0.0000, -1.1817, -0.0000],\n",
      "         [-0.0000, -0.0000, -0.0000,  ...,  0.0000, -0.0000, -0.9555],\n",
      "         [-1.5100, -3.1098, -0.0000,  ...,  0.0000,  0.0000,  0.2445]],\n",
      "\n",
      "        [[-0.0000,  0.3639, -0.0000,  ...,  0.0000,  1.7605,  0.1649],\n",
      "         [-0.0909,  0.0000, -1.1719,  ...,  0.6557, -0.0000,  4.6047],\n",
      "         [-5.6715,  3.4784, -1.4496,  ...,  0.1880, -0.0395, -0.0000],\n",
      "         ...,\n",
      "         [ 0.2317,  0.0000, -0.0000,  ...,  0.3247,  0.0383,  0.2361],\n",
      "         [-0.0000, -0.1019, -0.2824,  ..., -0.0000, -0.0967,  0.6108],\n",
      "         [ 2.7612,  6.0725, -0.0000,  ..., -0.0000,  0.0926, -0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-0.0000, -0.3243, -0.6721,  ..., -0.0000, -0.0000, -0.7566],\n",
      "        [-0.6825, -0.1692, -6.9895,  ...,  0.0000,  0.2799, -0.0000],\n",
      "        [-0.0000, -2.4672,  0.0000,  ..., -0.4546, -1.0051, -1.4223],\n",
      "        ...,\n",
      "        [-0.0000, -0.4521, -0.3311,  ..., -0.0000,  0.0926,  0.1005],\n",
      "        [ 0.5819,  0.7969, -0.0000,  ...,  0.0000,  0.0000,  0.2445],\n",
      "        [-0.0000,  0.3639, -0.0000,  ..., -0.0000,  0.0926, -0.0000]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.0000e+00, -9.8128e-02, -0.0000e+00,  ...,  1.4151e-01,\n",
      "           0.0000e+00,  2.5912e-01],\n",
      "         [ 4.0279e-03,  1.6132e-01,  1.7162e-01,  ..., -0.0000e+00,\n",
      "           3.6486e-03,  0.0000e+00],\n",
      "         [-0.0000e+00, -2.6704e+00,  1.9821e+00,  ...,  7.6864e-01,\n",
      "           0.0000e+00,  1.6725e+00],\n",
      "         ...,\n",
      "         [-1.3600e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           5.8280e-02, -0.0000e+00],\n",
      "         [-7.0134e-01,  6.7326e-01, -4.0527e-01,  ...,  0.0000e+00,\n",
      "          -4.3471e-01, -2.5147e-01],\n",
      "         [-0.0000e+00, -3.3416e+00, -4.9783e-01,  ...,  1.6151e-01,\n",
      "           0.0000e+00, -8.3648e-01]],\n",
      "\n",
      "        [[-2.6709e+00,  0.0000e+00,  0.0000e+00,  ...,  7.2617e-01,\n",
      "           0.0000e+00,  1.6327e-01],\n",
      "         [-6.0356e+00,  0.0000e+00, -9.4988e-01,  ..., -0.0000e+00,\n",
      "          -2.9211e-01,  1.5108e-01],\n",
      "         [-3.1531e-01,  2.3719e+00,  4.7264e-01,  ...,  0.0000e+00,\n",
      "           1.4777e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00,  3.9179e-01, -0.0000e+00,  ...,  2.8558e-01,\n",
      "           0.0000e+00,  8.1103e-01],\n",
      "         [-2.8540e+00, -1.5664e-01, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "        [[-0.0000e+00,  8.8255e-02, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  8.2403e-02],\n",
      "         [ 3.2301e-01, -4.0530e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          -0.0000e+00,  8.0912e-01],\n",
      "         [-0.0000e+00, -3.0925e-01, -7.4129e-01,  ...,  1.0573e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [-4.3997e-01, -3.7980e-01, -1.9419e+00,  ...,  0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [-2.2603e+00,  0.0000e+00, -0.0000e+00,  ...,  4.2014e-01,\n",
      "           0.0000e+00,  5.8965e-01],\n",
      "         [-6.1133e-01,  3.0607e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -2.2809e-01, -1.5098e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-3.0732e+00,  0.0000e+00, -1.1556e+00,  ...,  0.0000e+00,\n",
      "           3.9003e-02,  0.0000e+00],\n",
      "         [-4.2998e-02, -4.1447e-01,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           3.1189e-02,  1.9381e+00],\n",
      "         [-4.2036e-02, -0.0000e+00, -5.8222e-01,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  2.9615e-03],\n",
      "         ...,\n",
      "         [-2.8574e+00, -1.6290e+00, -7.4590e-01,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  6.0394e-01],\n",
      "         [-0.0000e+00,  3.1898e-01,  0.0000e+00,  ..., -0.0000e+00,\n",
      "           6.1615e+00, -0.0000e+00],\n",
      "         [ 0.0000e+00, -3.4755e+00,  4.2012e+00,  ..., -2.6780e-01,\n",
      "          -0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-3.7692e-01,  0.0000e+00, -1.9464e-02,  ...,  3.9411e+00,\n",
      "           5.0504e-01, -1.9753e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -6.3225e-01,  ..., -0.0000e+00,\n",
      "           3.8068e-01, -0.0000e+00],\n",
      "         [-7.0113e-01,  3.4506e-01, -0.0000e+00,  ...,  6.5474e-01,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [-5.0745e-01,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           1.4001e+00,  1.8859e-01],\n",
      "         [-3.6541e-02,  0.0000e+00, -0.0000e+00,  ...,  4.1270e-01,\n",
      "           6.1635e-01,  7.3904e-01],\n",
      "         [-1.6799e+00,  1.2274e-01,  1.3517e-01,  ..., -0.0000e+00,\n",
      "           1.5500e-01,  0.0000e+00]],\n",
      "\n",
      "        [[-0.0000e+00,  7.8536e-01, -7.4711e-02,  ...,  0.0000e+00,\n",
      "           6.7585e-01, -7.0202e-02],\n",
      "         [-4.3299e-01,  1.5772e-01, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -0.0000e+00, -6.7739e-01],\n",
      "         [-4.5125e-01, -0.0000e+00, -6.2008e-01,  ...,  3.9113e-01,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [-2.4688e-01, -2.8921e+00,  0.0000e+00,  ..., -8.2916e-01,\n",
      "           6.6457e-01, -1.1992e+00],\n",
      "         [-1.4844e+00,  0.0000e+00, -0.0000e+00,  ...,  2.3868e-01,\n",
      "          -0.0000e+00, -3.6888e-02],\n",
      "         [ 1.6385e-01,  3.5212e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  1.4650e+00]]], grad_fn=<MulBackward0>)\n",
      "tensor([[-0.0000, -0.0981, -0.0000,  ...,  0.1615,  0.0000, -0.8365],\n",
      "        [-2.6709,  0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [-0.0000,  0.0883, -0.0000,  ..., -0.0000, -0.2281, -1.5098],\n",
      "        ...,\n",
      "        [-3.0732,  0.0000, -1.1556,  ..., -0.2678, -0.0000,  0.0000],\n",
      "        [-0.3769,  0.0000, -0.0195,  ..., -0.0000,  0.1550,  0.0000],\n",
      "        [-0.0000,  0.7854, -0.0747,  ..., -0.0000,  0.0000,  1.4650]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-1.9750, -0.0000, -0.0000,  ...,  4.9738, -0.3033, -0.0000],\n",
      "         [-0.0000, -0.0000,  1.1064,  ...,  3.4133, -0.2117, -0.0000],\n",
      "         [-0.0000,  0.1804, -0.0000,  ...,  0.0000,  0.2693, -0.6355],\n",
      "         ...,\n",
      "         [-0.0000,  0.0000,  0.0000,  ..., -0.0120, -0.0000,  0.4812],\n",
      "         [-0.0000,  0.0000,  0.0000,  ...,  0.4598,  0.3043, -0.2145],\n",
      "         [-0.0000,  0.0000, -0.0000,  ..., -1.1165, -0.0000,  0.3878]],\n",
      "\n",
      "        [[ 0.0000, -0.0000, -0.0000,  ..., -0.1001,  0.5810, -0.0000],\n",
      "         [-0.5254, -1.4116, -0.8557,  ...,  0.0000,  0.0803,  0.1120],\n",
      "         [-1.4832,  2.9657, -1.7959,  ..., -0.4585, -0.7251, -0.0000],\n",
      "         ...,\n",
      "         [-0.0000,  0.1813, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "         [ 0.0000, -0.0000, -0.9074,  ...,  0.0000,  1.0414,  0.3147],\n",
      "         [-0.7752,  0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.5305]],\n",
      "\n",
      "        [[-0.0000, -0.0000, -0.0000,  ...,  0.0000, -5.7384,  2.7653],\n",
      "         [-0.6710, -3.4613,  0.7492,  ..., -2.3529,  0.0000,  4.6117],\n",
      "         [ 2.2126, -1.2319, -1.3167,  ...,  0.0000, -0.8214, -2.0730],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0431,  0.4647,  ...,  0.3099, -0.4408,  0.0000],\n",
      "         [-7.0074,  0.4414,  0.0000,  ..., -1.2746,  0.0000,  0.0000],\n",
      "         [-0.1099, -0.0000, -0.5327,  ..., -0.3941,  0.0000, -2.2213]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000,  0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "         [-0.7511, -0.2734, -0.0000,  ...,  0.0000,  0.0000, -3.5693],\n",
      "         [ 0.0000, -0.0000, -0.0000,  ..., -0.9203,  0.7592,  4.3887],\n",
      "         ...,\n",
      "         [-0.6972,  2.1824, -0.0000,  ..., -0.9042, -0.1009, -0.0000],\n",
      "         [-0.8460,  3.3669, -0.0000,  ..., -0.0000, -1.9428,  0.7838],\n",
      "         [ 0.0000, -0.7065,  3.2953,  ..., -0.0000, -0.4908, -0.2067]],\n",
      "\n",
      "        [[-0.0000, -3.7841, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "         [-0.0000, -0.0000,  0.0000,  ..., -5.1389, -0.0000, -0.0000],\n",
      "         [-0.0000,  0.1372,  1.4510,  ...,  0.0000,  0.0000,  0.0415],\n",
      "         ...,\n",
      "         [ 0.0842,  0.2330, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "         [-0.0000,  0.0000, -0.7227,  ...,  0.0000,  0.1210, -1.1040],\n",
      "         [ 0.0000, -2.5809, -3.9740,  ...,  0.0597,  0.8221,  0.1253]],\n",
      "\n",
      "        [[ 0.0000,  0.1455, -0.4339,  ...,  0.4413, -0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000, -0.0000,  ...,  0.1656,  0.0000,  0.3703],\n",
      "         [-0.9846,  0.0000,  0.0000,  ..., -0.0000, -1.2280, -1.1375],\n",
      "         ...,\n",
      "         [-0.2079,  0.0000, -0.1572,  ...,  0.0000, -1.7561, -0.7787],\n",
      "         [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.6763],\n",
      "         [-0.4433, -0.6416, -0.7504,  ..., -0.2693, -0.0000, -0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-1.9750, -0.0000, -0.0000,  ..., -1.1165, -0.0000,  0.3878],\n",
      "        [ 0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.5305],\n",
      "        [-0.0000, -0.0000, -0.0000,  ..., -0.3941,  0.0000, -2.2213],\n",
      "        ...,\n",
      "        [-0.0000,  0.0000, -0.0000,  ..., -0.0000, -0.4908, -0.2067],\n",
      "        [-0.0000, -3.7841, -0.0000,  ...,  0.0597,  0.8221,  0.1253],\n",
      "        [ 0.0000,  0.1455, -0.4339,  ..., -0.2693, -0.0000, -0.0000]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.0000, -0.0000, -0.0000,  ...,  0.0000,  0.5289, -0.0000],\n",
      "         [-0.0000, -0.2990,  0.0796,  ..., -0.0000,  0.0000,  0.0000],\n",
      "         [ 0.6374,  0.2893, -0.0000,  ...,  0.7043,  1.1700,  0.3211],\n",
      "         ...,\n",
      "         [ 3.8797, -0.0000, -0.0000,  ..., -0.4011, -0.0000, -0.2864],\n",
      "         [-4.8687,  2.8573, -0.3237,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.0000, -0.9345,  0.0000,  ..., -0.0000, -0.0000, -0.1026]],\n",
      "\n",
      "        [[ 1.1552,  0.3134,  0.0000,  ...,  0.3479, -1.1412, -0.3789],\n",
      "         [ 5.1631,  0.0000, -0.7057,  ..., -0.0000,  0.0000, -0.0000],\n",
      "         [ 0.0921, -0.0000, -0.0000,  ..., -0.0000,  0.3165, -1.0701],\n",
      "         ...,\n",
      "         [-0.5876, -0.0000, -0.0000,  ...,  6.6696,  0.0000, -3.7726],\n",
      "         [-0.0000,  0.9472, -0.0000,  ...,  0.0000,  4.3320,  0.0000],\n",
      "         [-0.2536, -0.0000, -0.0000,  ...,  1.3396, -1.0657, -4.2970]],\n",
      "\n",
      "        [[-1.0963, -0.0000, -0.0000,  ..., -0.3160, -0.1768, -0.9853],\n",
      "         [-0.0000, -0.0000,  4.0935,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [-1.6180,  0.0000,  0.0000,  ..., -7.7849,  0.2365,  0.0000],\n",
      "         ...,\n",
      "         [-0.7132, -0.0000, -0.7705,  ..., -0.6341, -0.5439, -0.0000],\n",
      "         [-0.0000,  3.2670, -0.1924,  ...,  0.0000, -0.0000,  0.4127],\n",
      "         [-0.0000, -4.1747,  4.0270,  ...,  0.0841, -0.0000, -0.3306]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.0615, -0.1178, -0.0000,  ..., -0.0000,  4.2953,  2.4682],\n",
      "         [-0.0000,  0.0000, -1.3349,  ...,  0.0000, -0.9593,  4.3255],\n",
      "         [-0.0000, -0.0000,  0.0000,  ..., -0.4418,  5.7686,  0.0000],\n",
      "         ...,\n",
      "         [-2.2027,  4.9347,  0.0000,  ..., -0.4137, -0.0000, -0.0000],\n",
      "         [-0.1503,  0.2973, -1.6176,  ..., -0.0000,  0.0000, -0.5856],\n",
      "         [-2.1967, -0.3413, -0.6996,  ..., -0.0000, -0.5099, -0.4201]],\n",
      "\n",
      "        [[-1.8545, -0.0000, -0.6747,  ...,  1.1770, -4.0902, -0.3557],\n",
      "         [-0.0000, -0.0000,  4.2925,  ...,  0.0000, -0.5285,  2.5357],\n",
      "         [-0.8082, -0.0000,  3.3557,  ..., -0.5677, -0.2632, -5.9386],\n",
      "         ...,\n",
      "         [ 5.7128, -0.0000, -1.2782,  ..., -0.0000,  0.6409, -2.3621],\n",
      "         [-3.9972,  1.8852, -0.0000,  ...,  0.3906, -0.2729,  0.0000],\n",
      "         [ 5.5540,  0.0000,  0.0000,  ...,  0.1356, -0.1385, -0.0000]],\n",
      "\n",
      "        [[-0.0000,  0.0000,  0.0000,  ..., -0.0000, -0.5794, -0.0000],\n",
      "         [-0.0000, -0.0000,  0.0898,  ..., -0.0000,  5.2705, -3.1320],\n",
      "         [-0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.5055, -0.8451],\n",
      "         ...,\n",
      "         [ 2.8526, -0.0000, -0.0000,  ...,  3.2244, -0.0000, -3.2771],\n",
      "         [-0.0000,  0.0000, -0.0000,  ...,  0.0000, -5.0476, -0.0000],\n",
      "         [ 0.0000, -0.0000, -0.0000,  ...,  2.5315, -0.4119, -0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.1026],\n",
      "        [ 1.1552,  0.3134,  0.0000,  ...,  1.3396, -1.0657, -4.2970],\n",
      "        [-1.0963, -0.0000, -0.0000,  ...,  0.0841, -0.0000, -0.3306],\n",
      "        ...,\n",
      "        [-1.0615, -0.1178, -0.0000,  ..., -0.0000, -0.5099, -0.4201],\n",
      "        [-1.8545, -0.0000, -0.6747,  ...,  0.1356, -0.1385, -0.0000],\n",
      "        [-0.0000,  0.0000,  0.0000,  ...,  2.5315, -0.4119, -0.0000]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.9625,  0.3285,  3.8132,  ..., -0.0000, -0.0000,  0.1728],\n",
      "         [-0.4733, -0.0000, -0.6330,  ..., -0.1235, -0.0000, -0.0000],\n",
      "         [ 4.7046,  0.6323, -0.0000,  ..., -0.1693,  0.0000,  0.1452],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000, -0.5028,  ..., -0.0000, -0.3655, -0.0000],\n",
      "         [-0.0000, -0.2324,  0.0000,  ..., -0.8856,  0.0000, -0.4505],\n",
      "         [-1.0027,  0.8653, -0.0000,  ...,  0.0000,  0.0000, -0.0000]],\n",
      "\n",
      "        [[-0.1038,  1.8709,  0.7555,  ...,  0.0000,  1.1808, -3.4388],\n",
      "         [ 2.1306, -2.8381,  2.6025,  ..., -0.0000, -0.3851, -0.4423],\n",
      "         [-0.8319, -0.0000, -0.4341,  ..., -0.0000,  0.9515, -0.0000],\n",
      "         ...,\n",
      "         [ 2.4340, -0.0000, -0.0000,  ..., -0.7272, -0.3863, -0.6059],\n",
      "         [-0.9234,  0.6284, -0.0000,  ...,  0.0000,  0.0000, -0.9545],\n",
      "         [-0.2739, -4.0145, -1.0245,  ..., -0.2150,  0.1330,  0.6695]],\n",
      "\n",
      "        [[-0.0000, -1.0258, -0.0000,  ...,  0.0000, -0.3673,  4.7251],\n",
      "         [-1.3046,  0.0000, -0.8702,  ..., -0.0000, -0.0249,  0.0000],\n",
      "         [-2.3433,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -3.5627],\n",
      "         ...,\n",
      "         [ 6.0499, -0.0000, -0.0000,  ...,  0.0000, -1.0551, -0.0000],\n",
      "         [-1.1293,  0.6813, -0.0000,  ..., -0.0455,  1.8925, -0.0000],\n",
      "         [-0.2987, -0.0194, -0.4010,  ..., -0.0000,  0.0000, -2.4893]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000,  0.0000, -0.0000,  ..., -0.1605,  5.2903, -1.9599],\n",
      "         [-0.0000, -0.6089, -4.6494,  ...,  0.0000, -4.0501,  3.6871],\n",
      "         [ 4.0150, -0.0000, -0.0000,  ..., -0.1526,  0.0000, -0.0000],\n",
      "         ...,\n",
      "         [-0.0000, -1.1293,  0.4372,  ...,  6.8402, -0.7668, -0.0000],\n",
      "         [ 0.0000,  0.0966,  0.0000,  ..., -0.0000,  0.2811, -0.0864],\n",
      "         [ 0.0000,  1.3227,  0.3657,  ...,  0.0000,  1.2640, -0.0000]],\n",
      "\n",
      "        [[-0.0000, -0.0000, -1.0124,  ...,  5.9596, -0.0000,  0.0000],\n",
      "         [-0.0092, -0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
      "         [-2.2505,  0.0000, -1.4438,  ..., -0.0000,  0.0182,  0.0000],\n",
      "         ...,\n",
      "         [ 5.0151, -0.0000, -0.0000,  ..., -0.6941, -0.0000, -1.4679],\n",
      "         [-0.6599,  0.1924, -0.0000,  ...,  0.3074,  0.0000, -0.0000],\n",
      "         [-0.0000,  0.8339,  0.2538,  ...,  0.2162,  1.1846, -4.0031]],\n",
      "\n",
      "        [[-0.3303, -0.1572, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "         [-1.1370, -0.0297, -1.1927,  ..., -0.0000,  1.6064, -0.0000],\n",
      "         [ 0.0000,  0.1854,  0.4033,  ...,  0.5709,  0.0000, -1.3389],\n",
      "         ...,\n",
      "         [-0.0000, -0.3889,  0.0000,  ..., -1.3631, -0.0000, -0.4122],\n",
      "         [-1.7728,  0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [-0.0000, -0.0000,  0.0000,  ..., -0.5939, -0.1158, -0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-0.9625,  0.3285,  3.8132,  ...,  0.0000,  0.0000, -0.0000],\n",
      "        [-0.1038,  1.8709,  0.7555,  ..., -0.2150,  0.1330,  0.6695],\n",
      "        [-0.0000, -1.0258, -0.0000,  ..., -0.0000,  0.0000, -2.4893],\n",
      "        ...,\n",
      "        [-0.0000,  0.0000, -0.0000,  ...,  0.0000,  1.2640, -0.0000],\n",
      "        [-0.0000, -0.0000, -1.0124,  ...,  0.2162,  1.1846, -4.0031],\n",
      "        [-0.3303, -0.1572, -0.0000,  ..., -0.5939, -0.1158, -0.0000]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.0000,  0.0706, -0.8705,  ...,  0.0000, -1.1329, -0.0000],\n",
      "         [-0.5855, -0.2315, -0.0000,  ...,  0.4123,  0.0000,  0.0000],\n",
      "         [-0.7931, -0.0000, -0.2043,  ...,  0.0000,  0.0000, -0.3963],\n",
      "         ...,\n",
      "         [-0.0000, -0.1945, -0.7297,  ..., -0.7562,  0.0000, -0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.0000, -0.3629],\n",
      "         [ 0.0288,  0.5453, -1.0561,  ..., -1.8311, -0.8334,  0.0000]],\n",
      "\n",
      "        [[-4.2094, -0.0000, -0.0000,  ...,  0.7127,  0.0000,  0.0073],\n",
      "         [-0.0000, -0.1136, -1.3764,  ..., -0.0000, -0.2134, -0.0000],\n",
      "         [-1.3539,  0.1917, -0.3679,  ..., -1.7980,  0.1542, -0.0000],\n",
      "         ...,\n",
      "         [-0.1712,  0.0000, -0.0000,  ..., -0.0000, -0.2224, -0.0000],\n",
      "         [-0.0000,  3.4003, -0.0000,  ...,  0.0000, -0.4287, -0.6342],\n",
      "         [ 2.3043, -0.0373,  0.0000,  ..., -0.0000, -2.8115, -0.9063]],\n",
      "\n",
      "        [[-0.9167,  0.7959, -0.0000,  ...,  0.0000,  0.0000, -0.0000],\n",
      "         [-0.0000,  0.7052, -0.0485,  ...,  0.0000,  0.0000, -0.0000],\n",
      "         [-0.3330,  0.7596,  0.5124,  ..., -5.3926, -0.1151, -0.4088],\n",
      "         ...,\n",
      "         [ 4.7901, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [-1.5690, -0.0000, -3.1948,  ..., -0.0000, -0.6830,  2.8021],\n",
      "         [ 4.1090, -0.0000, -0.0270,  ..., -0.0000,  0.6535, -0.0879]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000,  0.4790,  0.0000,  ...,  0.3866, -2.3638, -0.0000],\n",
      "         [-1.7413,  0.0000, -0.0000,  ..., -0.0000, -0.5791, -1.2764],\n",
      "         [-0.0000, -3.9560, -0.2263,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-0.8327, -0.0301,  0.0000,  ..., -0.7300, -0.0000, -2.7671],\n",
      "         [-0.0000, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [-0.0000, -0.5972,  3.7824,  ..., -0.0585, -0.6165, -0.1770]],\n",
      "\n",
      "        [[-0.2458,  0.0657, -0.2647,  ..., -5.4157, -0.0000, -0.0000],\n",
      "         [-2.7313, -0.0000, -0.0000,  ..., -0.7197,  0.0000, -0.6288],\n",
      "         [ 0.1843, -0.0000, -1.0128,  ..., -0.0000,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 0.0000,  0.0000, -0.0000,  ..., -0.8751, -0.0000, -0.0000],\n",
      "         [-0.0814,  0.0000, -0.0000,  ..., -0.0402, -0.0095,  0.0000],\n",
      "         [ 2.5213, -0.0000, -0.0000,  ..., -0.0000, -0.0000, -0.0000]],\n",
      "\n",
      "        [[-0.9011, -0.8120, -6.5733,  ...,  1.7163, -0.0434, -0.1610],\n",
      "         [-0.0000, -0.0000,  0.5522,  ...,  0.0000,  0.0000, -0.0598],\n",
      "         [-0.0000,  0.2576, -0.0000,  ...,  0.0000,  0.3509, -0.0000],\n",
      "         ...,\n",
      "         [-1.0181,  0.0000, -0.2101,  ...,  0.0000, -1.9641,  0.0000],\n",
      "         [-0.0000,  0.0000, -0.6715,  ..., -0.0000,  0.0000,  1.1101],\n",
      "         [-0.0000, -0.0000, -0.0000,  ..., -0.4327,  0.2037, -0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-0.0000,  0.0706, -0.8705,  ..., -1.8311, -0.8334,  0.0000],\n",
      "        [-4.2094, -0.0000, -0.0000,  ..., -0.0000, -2.8115, -0.9063],\n",
      "        [-0.9167,  0.7959, -0.0000,  ..., -0.0000,  0.6535, -0.0879],\n",
      "        ...,\n",
      "        [-0.0000,  0.4790,  0.0000,  ..., -0.0585, -0.6165, -0.1770],\n",
      "        [-0.2458,  0.0657, -0.2647,  ..., -0.0000, -0.0000, -0.0000],\n",
      "        [-0.9011, -0.8120, -6.5733,  ..., -0.4327,  0.2037, -0.0000]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[ 3.3619e-01,  0.0000e+00,  5.6630e-01,  ...,  0.0000e+00,\n",
      "           1.1628e+00, -5.4129e+00],\n",
      "         [-5.1402e-01,  1.2865e+00,  5.5367e-01,  ...,  0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [-1.3079e+00,  0.0000e+00,  0.0000e+00,  ..., -4.4632e-01,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00, -5.0293e-01,  3.3517e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-9.4451e-01,  0.0000e+00, -4.1193e-01,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  7.3025e-01],\n",
      "         [ 3.4539e+00,  2.9053e-01, -3.9637e-01,  ..., -0.0000e+00,\n",
      "          -6.7449e-01, -0.0000e+00]],\n",
      "\n",
      "        [[-0.0000e+00,  3.7282e-01,  0.0000e+00,  ..., -0.0000e+00,\n",
      "          -2.9432e+00,  8.0689e-01],\n",
      "         [-4.0124e+00,  0.0000e+00,  0.0000e+00,  ...,  4.9818e-01,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-0.0000e+00, -0.0000e+00, -1.1899e+00,  ..., -0.0000e+00,\n",
      "          -2.0455e+00,  2.9044e+00],\n",
      "         ...,\n",
      "         [-1.2439e+00,  0.0000e+00,  3.8174e-01,  ...,  2.5455e-01,\n",
      "           5.9143e-01, -7.4359e-01],\n",
      "         [-3.8375e-01, -0.0000e+00, -6.4774e-01,  ..., -1.1558e-01,\n",
      "          -7.6617e-01,  0.0000e+00],\n",
      "         [-6.6345e-02, -0.0000e+00, -2.5778e-01,  ..., -1.3462e-03,\n",
      "           0.0000e+00, -2.8336e+00]],\n",
      "\n",
      "        [[ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           5.9339e-01,  0.0000e+00],\n",
      "         [-0.0000e+00, -2.9557e-02, -7.1573e-01,  ..., -4.0297e-01,\n",
      "           6.8405e-01, -5.5218e+00],\n",
      "         [ 8.0538e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -3.0188e-01, -3.1337e-01],\n",
      "         ...,\n",
      "         [-3.3667e+00,  0.0000e+00, -4.6159e-01,  ..., -0.0000e+00,\n",
      "          -8.5155e-01,  5.0580e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -2.4788e-01],\n",
      "         [-0.0000e+00,  1.1206e+00, -8.6150e-01,  ...,  2.2224e+00,\n",
      "          -0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000e+00,  0.0000e+00, -2.3658e+00,  ...,  8.8947e-01,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-8.7239e-01,  9.1173e-01, -0.0000e+00,  ...,  2.0532e-01,\n",
      "          -1.9830e-02, -1.5535e+00],\n",
      "         [ 1.3775e+00, -6.6050e-02, -4.9267e+00,  ..., -4.2320e-01,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00,  7.1587e-01,  4.9536e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00,  1.4239e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         [-0.0000e+00, -2.4728e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -3.8451e+00,  1.8505e+00]],\n",
      "\n",
      "        [[-1.0370e-01, -3.4620e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -0.0000e+00, -1.7265e+00],\n",
      "         [ 7.1998e-02,  1.0891e+00,  9.3103e-01,  ...,  7.4771e-01,\n",
      "           1.9329e+00, -3.4673e-01],\n",
      "         [ 2.7340e-01,  2.0638e-01, -2.1807e-01,  ..., -1.8861e-02,\n",
      "          -2.2419e-02,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -0.0000e+00,  7.0651e-01,  ...,  0.0000e+00,\n",
      "          -0.0000e+00,  6.9963e-01],\n",
      "         [-0.0000e+00,  9.6693e-02, -0.0000e+00,  ...,  2.5085e-02,\n",
      "          -0.0000e+00, -6.5129e-02],\n",
      "         [-0.0000e+00,  1.4488e+00, -5.1358e-01,  ..., -0.0000e+00,\n",
      "          -9.6058e-01, -0.0000e+00]],\n",
      "\n",
      "        [[-6.2142e-01,  2.8555e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -5.6072e-01,  3.3333e+00],\n",
      "         [-2.3255e-02,  0.0000e+00, -0.0000e+00,  ...,  1.0201e+00,\n",
      "           3.3044e-01, -1.9779e+00],\n",
      "         [-1.5205e+00,  0.0000e+00,  1.6210e+00,  ...,  0.0000e+00,\n",
      "           2.5659e-01,  4.3784e-01],\n",
      "         ...,\n",
      "         [-0.0000e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -1.1575e+00, -3.1584e-01],\n",
      "         [-2.1002e+00,  2.2294e+00, -0.0000e+00,  ...,  8.8360e-01,\n",
      "          -4.0527e-01, -0.0000e+00],\n",
      "         [-0.0000e+00,  1.4432e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  9.1280e-01]]], grad_fn=<MulBackward0>)\n",
      "tensor([[ 3.3619e-01,  0.0000e+00,  5.6630e-01,  ..., -0.0000e+00,\n",
      "         -6.7449e-01, -0.0000e+00],\n",
      "        [-0.0000e+00,  3.7282e-01,  0.0000e+00,  ..., -1.3462e-03,\n",
      "          0.0000e+00, -2.8336e+00],\n",
      "        [ 0.0000e+00, -0.0000e+00, -0.0000e+00,  ...,  2.2224e+00,\n",
      "         -0.0000e+00, -0.0000e+00],\n",
      "        ...,\n",
      "        [-0.0000e+00,  0.0000e+00, -2.3658e+00,  ..., -0.0000e+00,\n",
      "         -3.8451e+00,  1.8505e+00],\n",
      "        [-1.0370e-01, -3.4620e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "         -9.6058e-01, -0.0000e+00],\n",
      "        [-6.2142e-01,  2.8555e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  9.1280e-01]], grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-1.8676,  0.0000,  0.0000,  ..., -0.0714,  0.0000, -2.0060],\n",
      "         [ 0.0000,  0.0000, -0.2874,  ..., -2.7192, -0.0000,  4.7044],\n",
      "         [ 0.0000, -1.1704, -0.4190,  ..., -0.1674, -0.0000, -1.5940],\n",
      "         ...,\n",
      "         [-0.0000, -0.0000, -1.0769,  ..., -1.0223, -0.0000, -0.7000],\n",
      "         [-0.0000,  1.5373, -0.0000,  ...,  0.6968,  0.0000, -0.0000],\n",
      "         [-0.0000, -0.0000, -0.0000,  ...,  0.0000, -0.0256, -0.7154]],\n",
      "\n",
      "        [[-0.1817, -0.0000, -0.0000,  ..., -0.1199, -0.0000, -0.0000],\n",
      "         [-1.4830,  0.0000,  0.0000,  ..., -0.4756, -0.4488, -0.0000],\n",
      "         [-0.0000,  2.2429, -1.3083,  ..., -4.0964,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 3.5934, -0.0000,  0.0000,  ...,  0.0000,  0.0714, -0.0000],\n",
      "         [-0.6130, -0.5482,  6.0195,  ..., -0.0000, -2.1705, -0.4695],\n",
      "         [-1.4714,  2.5317, -0.0000,  ...,  0.1117,  0.0000, -0.2917]],\n",
      "\n",
      "        [[-1.4424, -0.7153, -0.8549,  ..., -0.0000, -0.0000, -0.6293],\n",
      "         [-0.0469, -0.0000, -0.0000,  ...,  4.2385,  0.0000, -0.0000],\n",
      "         [-2.9459,  0.0000,  0.1037,  ..., -0.0000, -0.3513, -0.0000],\n",
      "         ...,\n",
      "         [-0.0000, -1.7324, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "         [-0.2705,  0.0000, -0.0000,  ...,  0.0000, -0.3930,  0.0000],\n",
      "         [ 0.0000, -0.2302, -0.9998,  ..., -0.0000, -0.2541, -0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.1689, -4.1218,  5.6628,  ...,  0.2182,  0.1706,  0.3622],\n",
      "         [-0.3181,  0.0000, -2.2684,  ...,  0.1360, -0.5792, -1.0577],\n",
      "         [-4.2311,  0.1944, -4.7716,  ...,  3.6943,  0.4942,  0.2012],\n",
      "         ...,\n",
      "         [ 0.4849, -2.3148,  0.0000,  ...,  0.4222, -0.0000, -0.0000],\n",
      "         [-1.0428,  0.9015,  0.0000,  ...,  0.4202,  0.4039, -0.0000],\n",
      "         [-0.0000,  0.0000,  0.5865,  ..., -0.5734,  0.0835,  0.8218]],\n",
      "\n",
      "        [[-0.8636, -0.2229, -0.6513,  ...,  6.4719, -0.8314,  0.5330],\n",
      "         [-0.0000,  0.0000, -0.0000,  ..., -2.1271, -2.3394, -0.0000],\n",
      "         [-1.0578, -0.0000, -0.8552,  ..., -0.0000, -0.7403,  2.2496],\n",
      "         ...,\n",
      "         [ 0.1502,  0.0000, -0.0000,  ...,  0.3077, -0.6981,  0.0000],\n",
      "         [-0.0000,  3.5941, -3.1166,  ..., -0.4518, -0.0000, -0.8494],\n",
      "         [ 0.0000,  0.0000, -0.0000,  ..., -0.0000,  0.4218, -1.2645]],\n",
      "\n",
      "        [[-0.0000, -0.5075, -0.0000,  ...,  0.0301, -0.0000, -0.0000],\n",
      "         [-0.0000,  0.0100, -0.6191,  ..., -0.1379, -0.0000,  1.3227],\n",
      "         [ 0.0000, -0.0569, -0.2256,  ...,  0.0937,  0.6094, -0.0803],\n",
      "         ...,\n",
      "         [-0.0000, -0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.1596],\n",
      "         [-0.3596, -0.0220, -0.5954,  ..., -0.4080,  3.6474, -5.3350],\n",
      "         [ 0.0000, -3.3829, -0.0000,  ..., -0.2361, -0.2955, -0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-1.8676,  0.0000,  0.0000,  ...,  0.0000, -0.0256, -0.7154],\n",
      "        [-0.1817, -0.0000, -0.0000,  ...,  0.1117,  0.0000, -0.2917],\n",
      "        [-1.4424, -0.7153, -0.8549,  ..., -0.0000, -0.2541, -0.0000],\n",
      "        ...,\n",
      "        [ 0.1689, -4.1218,  5.6628,  ..., -0.5734,  0.0835,  0.8218],\n",
      "        [-0.8636, -0.2229, -0.6513,  ..., -0.0000,  0.4218, -1.2645],\n",
      "        [-0.0000, -0.5075, -0.0000,  ..., -0.2361, -0.2955, -0.0000]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.5612,  4.8477, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "         [-0.0000,  0.7869,  0.6305,  ..., -0.7329,  3.7327,  0.0000],\n",
      "         [ 0.0000,  3.7115, -0.3357,  ...,  1.4381, -0.0000,  0.0000],\n",
      "         ...,\n",
      "         [ 2.9955,  0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
      "         [-0.4562, -0.0000, -0.0000,  ..., -0.3272, -0.0000, -0.7859],\n",
      "         [-0.2482,  1.1786, -0.4326,  ..., -0.0000, -0.5717, -0.0000]],\n",
      "\n",
      "        [[ 0.1298, -3.9242,  0.2616,  ...,  0.0000,  0.0000, -0.2547],\n",
      "         [-3.6484, -0.8238,  0.0000,  ...,  0.0000, -3.5848, -0.0000],\n",
      "         [-0.0000, -0.8236,  3.2247,  ...,  0.1966,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-1.4744,  0.0861, -0.0000,  ..., -0.3462,  0.0000, -0.8865],\n",
      "         [-5.0322, -0.0000, -0.0000,  ...,  0.0000, -0.5032,  0.0000],\n",
      "         [-0.7012, -0.0000,  0.0000,  ..., -0.0000, -0.1648, -0.0000]],\n",
      "\n",
      "        [[-0.0000, -0.0000, -0.0000,  ...,  0.0000, -0.0000,  0.0000],\n",
      "         [-0.0000, -0.7443, -0.0000,  ...,  3.5438, -0.6620, -0.0000],\n",
      "         [-1.5315, -0.0000,  0.0000,  ...,  1.2990, -0.4568, -0.4640],\n",
      "         ...,\n",
      "         [-0.2629,  0.0000,  0.0000,  ...,  0.6381,  0.1035,  0.0000],\n",
      "         [-0.7446, -0.0000,  0.0000,  ..., -4.5376,  0.9690, -4.1397],\n",
      "         [ 0.4978,  0.0652,  0.0000,  ..., -0.5747,  6.0735, -2.6013]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.0000, -0.1689, -0.0000,  ...,  0.0000,  0.3908,  0.0000],\n",
      "         [-0.0000,  0.0000,  0.0000,  ..., -0.5535,  0.3624,  2.3496],\n",
      "         [ 0.6206, -4.4448, -0.0000,  ..., -0.0000,  0.3142, -0.0000],\n",
      "         ...,\n",
      "         [ 4.9590,  0.0000,  0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
      "         [-1.0362,  0.4170, -1.1770,  ..., -0.0000, -2.1741,  2.5669],\n",
      "         [ 4.7037, -2.3149, -0.0000,  ...,  0.0000, -0.4537, -0.0000]],\n",
      "\n",
      "        [[ 0.0000,  0.8689, -0.3618,  ...,  0.0000,  0.0000,  0.8391],\n",
      "         [-0.3778, -0.3416, -0.9866,  ...,  0.1305, -0.0172,  2.7380],\n",
      "         [-1.1852,  0.0000, -0.2718,  ..., -3.3145,  0.0000,  1.5678],\n",
      "         ...,\n",
      "         [-0.0000, -0.0000, -0.8164,  ..., -0.0000, -1.6374, -0.0000],\n",
      "         [-0.0000, -0.8531,  3.2464,  ..., -0.0000, -0.5376,  0.2606],\n",
      "         [ 0.0000,  0.4379, -0.2908,  ...,  0.0000, -0.0000,  0.0000]],\n",
      "\n",
      "        [[-1.0096,  0.0000, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "         [-0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.5155, -0.8171],\n",
      "         [-0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.3831,  1.1418],\n",
      "         ...,\n",
      "         [ 3.6864,  3.5659, -0.2928,  ..., -0.0000, -0.3426, -0.1314],\n",
      "         [-0.1766,  2.4112, -1.6325,  ..., -0.0322, -0.0000, -0.2120],\n",
      "         [-0.1688,  1.4327,  0.2057,  ..., -0.0000,  1.7615, -2.7469]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-0.5612,  4.8477, -0.0000,  ..., -0.0000, -0.5717, -0.0000],\n",
      "        [ 0.1298, -3.9242,  0.2616,  ..., -0.0000, -0.1648, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000,  ..., -0.5747,  6.0735, -2.6013],\n",
      "        ...,\n",
      "        [-0.0000, -0.1689, -0.0000,  ...,  0.0000, -0.4537, -0.0000],\n",
      "        [ 0.0000,  0.8689, -0.3618,  ...,  0.0000, -0.0000,  0.0000],\n",
      "        [-1.0096,  0.0000, -0.0000,  ..., -0.0000,  1.7615, -2.7469]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.0000, -0.0000, -3.4254,  ..., -0.3929, -0.0106, -0.0000],\n",
      "         [-0.0000,  3.2667, -2.6142,  ...,  0.0000, -0.0000,  0.0000],\n",
      "         [-0.0000,  0.0000, -0.3045,  ..., -0.7459, -0.6837, -0.0000],\n",
      "         ...,\n",
      "         [-0.0000, -0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.0256],\n",
      "         [-0.8350, -0.0000, -0.0000,  ..., -0.0000, -2.4406, -0.2827],\n",
      "         [ 3.3799, -4.2298,  0.0000,  ..., -0.7848, -0.0000, -0.3903]],\n",
      "\n",
      "        [[-0.0000,  0.0000, -2.4046,  ..., -0.1576,  0.0000,  0.4613],\n",
      "         [ 0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [-0.4092, -0.0567, -0.8255,  ...,  0.2003, -6.8819, -0.1922],\n",
      "         ...,\n",
      "         [-0.0000,  0.4856,  5.6221,  ..., -0.0000,  0.0000,  0.0000],\n",
      "         [-0.0000, -0.0000, -0.2236,  ...,  0.0920, -0.2067, -0.0000],\n",
      "         [-0.4282, -0.0625, -0.0000,  ..., -0.0000, -0.8113, -0.0000]],\n",
      "\n",
      "        [[-0.0892, -0.1025, -0.0000,  ..., -0.0000,  5.4577, -0.3653],\n",
      "         [-4.8494,  0.0560, -0.0000,  ..., -0.0000,  1.1011,  0.0000],\n",
      "         [-0.0000, -0.0000, -0.4191,  ...,  0.0000,  0.6521, -5.6323],\n",
      "         ...,\n",
      "         [-0.6599, -0.2117, -0.0000,  ..., -0.0000, -0.0000, -0.2602],\n",
      "         [-1.0130,  0.6875, -0.2440,  ..., -0.0625,  0.0000, -0.0000],\n",
      "         [ 0.0000,  2.5943,  4.2736,  ..., -0.8786, -0.1606, -0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.1045, -0.0000,  0.0000,  ..., -0.0000, -0.0000, -0.0000],\n",
      "         [-0.2598, -0.0000, -0.2180,  ..., -0.7849,  0.0000,  0.9110],\n",
      "         [-0.0000,  0.0000,  0.4129,  ..., -0.3173,  0.0000,  0.0000],\n",
      "         ...,\n",
      "         [-3.5291,  0.0000, -0.0000,  ...,  0.4039, -2.8684,  0.4893],\n",
      "         [-0.4172,  0.0000, -1.9200,  ...,  0.6312, -5.3019, -0.0000],\n",
      "         [-1.6168, -0.0000,  0.0000,  ..., -1.0365, -0.2814, -0.0000]],\n",
      "\n",
      "        [[-0.0000, -0.0000, -0.0000,  ...,  5.4876,  1.0924,  0.0000],\n",
      "         [-0.0000,  0.0000,  0.0525,  ..., -0.0000, -0.3827,  0.0000],\n",
      "         [-0.0000,  0.3347,  3.4005,  ..., -4.6018,  0.0000, -0.0000],\n",
      "         ...,\n",
      "         [-0.0000, -0.9710,  0.0000,  ...,  0.0000,  0.8040,  0.5495],\n",
      "         [-0.0000, -0.2558, -0.1976,  ..., -0.0000, -0.0000,  0.0000],\n",
      "         [-0.1497,  0.0000,  0.0000,  ...,  0.3333,  0.0000,  1.1017]],\n",
      "\n",
      "        [[-0.0000, -0.0000,  0.0000,  ...,  0.0000,  0.9801,  0.2183],\n",
      "         [-0.0000,  0.0000, -0.0000,  ..., -0.0360, -0.0000, -0.8252],\n",
      "         [-0.4798, -0.0000, -0.0000,  ...,  0.0269, -1.1281,  5.4286],\n",
      "         ...,\n",
      "         [-5.4947,  0.0000, -3.8625,  ...,  0.0571,  0.5914, -0.2099],\n",
      "         [-0.0000,  0.1433, -0.0560,  ...,  0.1201,  0.0000, -3.0335],\n",
      "         [-0.0000, -0.0000, -0.5283,  ..., -0.0000, -0.0000,  0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-0.0000, -0.0000, -3.4254,  ..., -0.7848, -0.0000, -0.3903],\n",
      "        [-0.0000,  0.0000, -2.4046,  ..., -0.0000, -0.8113, -0.0000],\n",
      "        [-0.0892, -0.1025, -0.0000,  ..., -0.8786, -0.1606, -0.0000],\n",
      "        ...,\n",
      "        [-1.1045, -0.0000,  0.0000,  ..., -1.0365, -0.2814, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000,  ...,  0.3333,  0.0000,  1.1017],\n",
      "        [-0.0000, -0.0000,  0.0000,  ..., -0.0000, -0.0000,  0.0000]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-0.0000e+00, -1.6369e-01, -1.2864e+00,  ..., -1.4681e-01,\n",
      "          -1.3997e-01,  0.0000e+00],\n",
      "         [-0.0000e+00, -1.4353e-01, -3.5403e-01,  ...,  2.6319e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [ 1.3119e+00,  0.0000e+00,  0.0000e+00,  ...,  3.4049e-01,\n",
      "           3.4367e-01, -0.0000e+00],\n",
      "         ...,\n",
      "         [ 2.9829e-04,  0.0000e+00,  3.8135e-01,  ...,  2.7007e-01,\n",
      "           1.6210e+00, -0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -0.0000e+00, -6.7673e-01],\n",
      "         [-4.2857e-01, -0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "           2.3965e+00,  0.0000e+00]],\n",
      "\n",
      "        [[-0.0000e+00,  0.0000e+00, -0.0000e+00,  ...,  1.5287e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-3.0434e-01, -3.7088e+00,  0.0000e+00,  ...,  4.8016e-02,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-9.0853e-01, -6.4932e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [-1.6195e+00,  8.9662e-01, -8.4155e-01,  ..., -1.0787e+00,\n",
      "           0.0000e+00, -3.0182e+00],\n",
      "         [ 2.4905e+00,  0.0000e+00, -8.6421e-01,  ...,  1.4757e+00,\n",
      "           0.0000e+00,  4.2180e-01],\n",
      "         [ 4.4634e+00, -0.0000e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -1.3949e-01]],\n",
      "\n",
      "        [[-0.0000e+00, -1.8788e+00,  5.6236e+00,  ...,  2.6667e-01,\n",
      "           4.7310e-01,  0.0000e+00],\n",
      "         [-0.0000e+00,  4.3096e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -5.4551e-01,  0.0000e+00],\n",
      "         [-8.0471e-01,  5.2009e-01,  0.0000e+00,  ..., -1.2959e-01,\n",
      "           2.0317e+00, -5.9788e-01],\n",
      "         ...,\n",
      "         [-0.0000e+00, -4.0055e-01,  6.9328e-02,  ..., -7.8352e-02,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-0.0000e+00, -0.0000e+00, -2.2276e-01,  ..., -0.0000e+00,\n",
      "           5.6888e-01, -2.7209e-01],\n",
      "         [-2.7350e+00,  0.0000e+00,  0.0000e+00,  ..., -9.5230e-01,\n",
      "          -5.3234e-02, -2.0951e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-6.5166e-01, -2.7817e+00, -0.0000e+00,  ...,  1.2999e-01,\n",
      "           0.0000e+00,  2.2794e+00],\n",
      "         [ 1.5916e+00,  0.0000e+00, -0.0000e+00,  ..., -6.4843e+00,\n",
      "           3.7929e-01,  1.2254e+00],\n",
      "         [-0.0000e+00,  3.4464e+00, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [-1.8413e+00, -0.0000e+00, -0.0000e+00,  ..., -1.9031e+00,\n",
      "          -1.5018e+00, -0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00,  2.2584e+00,  ..., -0.0000e+00,\n",
      "           4.2547e-01, -3.1297e-01],\n",
      "         [-0.0000e+00, -0.0000e+00, -1.2636e+00,  ..., -2.0578e-01,\n",
      "           4.1538e+00, -0.0000e+00]],\n",
      "\n",
      "        [[-1.3595e-01,  1.4206e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  8.6094e-01],\n",
      "         [-1.4212e+00,  3.9776e+00,  2.3401e+00,  ...,  2.4014e-01,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00, -0.0000e+00,  3.9045e+00,  ...,  3.4877e-01,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -3.8811e+00,  3.6409e-01,  ...,  0.0000e+00,\n",
      "          -5.6808e-01, -1.1809e+00],\n",
      "         [-0.0000e+00,  0.0000e+00, -1.9968e+00,  ..., -2.2518e-01,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -3.0042e-02,\n",
      "          -6.3180e-01, -0.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00, -1.8345e+00,  6.9490e-01,  ...,  6.7259e-01,\n",
      "           4.6958e-01, -0.0000e+00],\n",
      "         [-6.7720e-01, -0.0000e+00,  0.0000e+00,  ...,  4.0835e+00,\n",
      "          -4.4736e+00, -0.0000e+00],\n",
      "         [ 6.6982e+00, -1.1307e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -7.0301e-01, -0.0000e+00],\n",
      "         ...,\n",
      "         [-9.0545e-01, -6.8409e-02, -0.0000e+00,  ..., -2.3550e-01,\n",
      "          -0.0000e+00, -2.2926e+00],\n",
      "         [-7.8488e-01,  4.2961e+00, -3.1306e-01,  ...,  0.0000e+00,\n",
      "          -0.0000e+00,  1.5529e-02],\n",
      "         [-0.0000e+00,  0.0000e+00,  6.6035e-01,  ..., -2.3635e+00,\n",
      "          -0.0000e+00, -2.7406e+00]]], grad_fn=<MulBackward0>)\n",
      "tensor([[-0.0000, -0.1637, -1.2864,  ..., -0.0000,  2.3965,  0.0000],\n",
      "        [-0.0000,  0.0000, -0.0000,  ..., -0.0000,  0.0000, -0.1395],\n",
      "        [-0.0000, -1.8788,  5.6236,  ..., -0.9523, -0.0532, -0.2095],\n",
      "        ...,\n",
      "        [-0.6517, -2.7817, -0.0000,  ..., -0.2058,  4.1538, -0.0000],\n",
      "        [-0.1359,  1.4206,  0.0000,  ..., -0.0300, -0.6318, -0.0000],\n",
      "        [ 0.0000, -1.8345,  0.6949,  ..., -2.3635, -0.0000, -2.7406]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([256, 23, 1])\n",
      "encoder output shape torch.Size([256, 23, 20])\n",
      "tensor([[[-1.9532,  0.0000, -2.3872,  ..., -0.0000,  0.0000,  0.0000],\n",
      "         [-0.5082,  0.5108, -0.7087,  ...,  0.0000,  0.0000, -0.0000],\n",
      "         [-0.0000,  1.2742,  0.0000,  ...,  0.0000, -3.2984,  0.4599],\n",
      "         ...,\n",
      "         [-0.0000, -3.3013, -0.0000,  ..., -1.7195,  0.0000, -4.1135],\n",
      "         [-5.5426,  0.0000, -0.0306,  ..., -0.3614, -0.0000, -0.0272],\n",
      "         [ 0.0381, -0.0000, -0.7506,  ...,  0.0000, -0.1730, -0.4306]],\n",
      "\n",
      "        [[ 0.4532, -0.8189,  0.0000,  ..., -2.0571,  0.0000, -0.0000],\n",
      "         [-0.0000,  0.0000, -0.0000,  ..., -0.0000, -0.3102, -5.1934],\n",
      "         [-0.0000,  2.0872, -0.0000,  ..., -3.5081,  1.0244,  0.0000],\n",
      "         ...,\n",
      "         [-2.5766, -0.1656,  3.5917,  ..., -0.6289,  0.2153, -0.7534],\n",
      "         [-2.0167,  0.0000, -0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ..., -0.5492, -1.4874, -0.2358]],\n",
      "\n",
      "        [[-0.0000,  0.0000, -0.1133,  ..., -0.0000,  0.9509,  0.0000],\n",
      "         [-0.0000,  0.5816, -0.6162,  ..., -0.1208,  6.2094,  0.0000],\n",
      "         [-5.5990, -0.1837,  0.0000,  ..., -0.0000,  0.0000,  0.3081],\n",
      "         ...,\n",
      "         [ 4.1463,  0.2169, -0.1076,  ..., -0.4327,  0.0000, -2.1613],\n",
      "         [-0.4833,  0.0000, -1.4636,  ...,  0.0000,  0.1176,  0.0000],\n",
      "         [-0.0000,  0.0000, -0.0479,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.2772, -0.3315,  0.0000,  ...,  1.2305, -0.9602,  0.0000],\n",
      "         [-0.1819, -0.0000, -0.0000,  ...,  0.0000,  3.4287, -0.2711],\n",
      "         [-0.4060,  3.0755,  0.0000,  ...,  0.0000,  0.0000,  0.2124],\n",
      "         ...,\n",
      "         [-0.0000,  0.0000,  0.0000,  ..., -0.0000,  0.1185, -0.0000],\n",
      "         [-1.5250,  2.5632, -0.0000,  ...,  0.0000,  0.0253,  3.1715],\n",
      "         [ 0.0000, -1.2641, -0.0000,  ..., -0.3845, -0.0702, -0.0000]],\n",
      "\n",
      "        [[-0.0000, -0.0000, -0.0000,  ...,  0.0000,  0.0000,  0.4239],\n",
      "         [-4.6194, -0.0000,  0.0000,  ...,  0.0000,  0.0304,  0.0000],\n",
      "         [-0.0000,  0.0000, -0.0000,  ..., -0.0000, -1.2758, -0.0000],\n",
      "         ...,\n",
      "         [-3.1762,  0.3224, -0.0000,  ..., -1.9673, -2.3724,  0.0000],\n",
      "         [ 0.0000,  2.8383, -0.0000,  ...,  0.0000,  0.4607,  0.7343],\n",
      "         [-0.6190, -0.3717, -0.8890,  ..., -0.3155, -0.0000, -0.4587]],\n",
      "\n",
      "        [[-0.9435, -0.1080,  0.0972,  ..., -0.0000,  0.0000,  0.1903],\n",
      "         [-1.1387, -2.8622, -0.3576,  ...,  0.0667,  0.0000,  0.0000],\n",
      "         [-0.5580, -1.6583,  0.2603,  ...,  0.0000, -3.4542,  0.3176],\n",
      "         ...,\n",
      "         [-0.0000, -1.3065,  3.1469,  ..., -0.0000,  0.0083,  0.0000],\n",
      "         [-0.1774,  0.1774,  0.2225,  ...,  0.0191,  0.0000, -0.1837],\n",
      "         [ 0.0298, -1.3699, -0.0000,  ...,  0.0000, -0.4753, -0.0000]]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[-1.9532,  0.0000, -2.3872,  ...,  0.0000, -0.1730, -0.4306],\n",
      "        [ 0.4532, -0.8189,  0.0000,  ..., -0.5492, -1.4874, -0.2358],\n",
      "        [-0.0000,  0.0000, -0.1133,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-1.2772, -0.3315,  0.0000,  ..., -0.3845, -0.0702, -0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000,  ..., -0.3155, -0.0000, -0.4587],\n",
      "        [-0.9435, -0.1080,  0.0972,  ...,  0.0000, -0.4753, -0.0000]],\n",
      "       grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([256, 460])\n",
      "shape of x going in  torch.Size([74, 23, 1])\n",
      "encoder output shape torch.Size([74, 23, 20])\n",
      "tensor([[[-2.2376e-01,  1.2012e+00,  7.3669e-01,  ..., -2.8241e+00,\n",
      "           0.0000e+00,  1.0229e+00],\n",
      "         [-1.8708e+00, -7.6390e-01, -8.5691e-01,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [-1.8419e-01,  1.9933e+00,  1.0508e-01,  ...,  3.9597e-01,\n",
      "          -1.6265e-01, -0.0000e+00],\n",
      "         ...,\n",
      "         [-1.2027e+00,  1.2792e-01,  3.7458e-01,  ..., -1.2434e-01,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [-3.9214e+00, -5.7416e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00,  2.3030e+00, -0.0000e+00,  ...,  0.0000e+00,\n",
      "          -6.5316e+00,  6.4338e-01]],\n",
      "\n",
      "        [[ 0.0000e+00, -1.8156e+00, -4.0449e-01,  ...,  0.0000e+00,\n",
      "          -8.0484e-01, -0.0000e+00],\n",
      "         [-1.0972e+00, -0.0000e+00, -4.0208e+00,  ..., -0.0000e+00,\n",
      "           7.0967e-01, -3.7724e-01],\n",
      "         [-4.0293e+00,  3.4438e-01, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [-3.3725e-01,  5.5521e-02,  0.0000e+00,  ..., -1.2317e+00,\n",
      "           3.3893e-01,  2.3268e-01],\n",
      "         [-0.0000e+00, -0.0000e+00,  0.0000e+00,  ..., -6.1592e-01,\n",
      "          -0.0000e+00,  3.6197e-01],\n",
      "         [-0.0000e+00,  0.0000e+00, -1.9622e-01,  ..., -9.4260e-01,\n",
      "          -0.0000e+00,  6.1035e-01]],\n",
      "\n",
      "        [[-0.0000e+00,  0.0000e+00,  1.9141e+00,  ...,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00],\n",
      "         [-1.4563e+00,  2.5357e-01, -3.1210e+00,  ..., -3.0599e-01,\n",
      "           0.0000e+00, -0.0000e+00],\n",
      "         [-0.0000e+00,  0.0000e+00,  3.0068e-01,  ..., -0.0000e+00,\n",
      "           1.1526e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00,  4.5492e-01, -7.2132e+00,  ...,  2.0782e-01,\n",
      "           8.1674e-01,  0.0000e+00],\n",
      "         [ 3.5739e+00, -0.0000e+00, -0.0000e+00,  ...,  1.1244e+00,\n",
      "          -4.6539e-01,  2.8093e+00],\n",
      "         [-0.0000e+00,  4.9998e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           1.1058e-01,  0.0000e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0000e+00,  5.0775e-01,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           1.6460e+00,  0.0000e+00],\n",
      "         [-0.0000e+00, -1.9131e-01, -0.0000e+00,  ...,  0.0000e+00,\n",
      "           1.0250e-01, -4.7573e-01],\n",
      "         [ 3.2908e-01, -1.0884e+00, -5.3371e-01,  ..., -1.0925e-01,\n",
      "          -7.0139e-01, -0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00, -3.6685e+00,  2.4769e-01,  ..., -4.3854e-01,\n",
      "           0.0000e+00, -5.5106e-01],\n",
      "         [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           1.0333e+00,  0.0000e+00],\n",
      "         [-4.5498e-01,  0.0000e+00, -0.0000e+00,  ..., -4.2256e-01,\n",
      "           0.0000e+00, -0.0000e+00]],\n",
      "\n",
      "        [[-7.8533e-01, -0.0000e+00, -1.9668e-01,  ..., -3.0865e-01,\n",
      "           0.0000e+00,  1.5089e+00],\n",
      "         [-1.0070e+00,  6.5740e-01, -3.1538e-01,  ..., -0.0000e+00,\n",
      "          -4.4278e-03, -2.2842e-01],\n",
      "         [-3.9252e+00,  2.7281e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "           2.2898e+00, -0.0000e+00],\n",
      "         ...,\n",
      "         [-0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -0.0000e+00,\n",
      "           0.0000e+00, -1.8440e+00],\n",
      "         [-0.0000e+00,  7.8443e-02, -0.0000e+00,  ..., -2.9566e-01,\n",
      "          -6.2854e-01,  0.0000e+00],\n",
      "         [-8.8517e-01, -0.0000e+00, -0.0000e+00,  ..., -7.2064e-01,\n",
      "          -0.0000e+00, -1.3470e+00]],\n",
      "\n",
      "        [[-4.5425e-03, -0.0000e+00, -1.5897e-01,  ..., -0.0000e+00,\n",
      "          -7.1692e-01, -0.0000e+00],\n",
      "         [-7.2704e-01, -0.0000e+00, -3.1665e-01,  ..., -0.0000e+00,\n",
      "          -7.9562e-01, -0.0000e+00],\n",
      "         [-0.0000e+00, -1.0973e-01,  1.8021e+00,  ..., -0.0000e+00,\n",
      "          -0.0000e+00,  0.0000e+00],\n",
      "         ...,\n",
      "         [ 0.0000e+00,  6.9256e-01,  7.2363e-01,  ..., -0.0000e+00,\n",
      "           0.0000e+00,  6.4419e-02],\n",
      "         [-0.0000e+00,  6.4026e-01,  1.0379e-01,  ..., -0.0000e+00,\n",
      "           5.1800e+00,  7.4882e-01],\n",
      "         [-3.8163e+00,  9.0626e-02, -0.0000e+00,  ..., -0.0000e+00,\n",
      "           3.2376e-01,  0.0000e+00]]], grad_fn=<MulBackward0>)\n",
      "tensor([[-2.2376e-01,  1.2012e+00,  7.3669e-01,  ...,  0.0000e+00,\n",
      "         -6.5316e+00,  6.4338e-01],\n",
      "        [ 0.0000e+00, -1.8156e+00, -4.0449e-01,  ..., -9.4260e-01,\n",
      "         -0.0000e+00,  6.1035e-01],\n",
      "        [-0.0000e+00,  0.0000e+00,  1.9141e+00,  ...,  0.0000e+00,\n",
      "          1.1058e-01,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  5.0775e-01,  0.0000e+00,  ..., -4.2256e-01,\n",
      "          0.0000e+00, -0.0000e+00],\n",
      "        [-7.8533e-01, -0.0000e+00, -1.9668e-01,  ..., -7.2064e-01,\n",
      "         -0.0000e+00, -1.3470e+00],\n",
      "        [-4.5425e-03, -0.0000e+00, -1.5897e-01,  ..., -0.0000e+00,\n",
      "          3.2376e-01,  0.0000e+00]], grad_fn=<ReshapeAliasBackward0>)\n",
      "flattened for mlp torch.Size([74, 460])\n"
     ]
    }
   ],
   "source": [
    "for input, label in train_dataloader:\n",
    "    model(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classificationHead(nn.Module):\n",
    "    def __init__(self, n_features, embed_size, dropout):\n",
    "        super(classificationHead, self).__init__()\n",
    "\n",
    "        self.n_features = n_features*embed_size\n",
    "        self.lin1 = nn.Linear(self.n_features, self.n_features//2)\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.lin2 = nn.Linear(self.n_features//2, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.initialize_weights()\n",
    "\n",
    "    def initialize_weights(self):\n",
    "        torch.nn.init.kaiming_normal_(self.lin1.weight, nonlinearity='relu')\n",
    "        torch.nn.init.zeros_(self.lin1.bias)\n",
    "\n",
    "        torch.nn.init.kaiming_normal_(self.lin2.weight, nonlinearity='relu')\n",
    "        torch.nn.init.zeros_(self.lin2.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(x.shape)\n",
    "        x= torch.reshape(x, (-1, self.n_features))\n",
    "        # print(x.shape)\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.lin2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        # print(x)\n",
    "        # print(x.shape)\n",
    "        # print(x.squeeze())\n",
    "        # print(x.shape)\n",
    "        # print(x.squeeze(1).shape)\n",
    "        return x.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vpnClassifier(nn.Module):\n",
    "    def __init__(self, \n",
    "                 sigma=4,\n",
    "                 embed_size=20,\n",
    "                 input_size=1,\n",
    "                 n_features=23,\n",
    "                 num_layers=2,\n",
    "                 heads=4,\n",
    "                 forward_expansion=4,\n",
    "                 dropout=.5,\n",
    "                 ):\n",
    "        super(vpnClassifier, self).__init__()\n",
    "        self.encoder = Encoder(sigma=sigma, embed_size=embed_size, input_size=input_size, n_features=n_features, num_layers=num_layers, heads=heads, forward_expansion=forward_expansion, dropout=dropout)\n",
    "        self.classifying_head = classificationHead(n_features=n_features, embed_size=embed_size, dropout=dropout)\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.classifying_head(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vpnClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "        # print(batch_idx, inputs, targets)\n",
    "        pred = model(inputs)\n",
    "        # print(pred)\n",
    "        # print(pred.squeeze(0))\n",
    "        loss = loss_fn(pred, targets)\n",
    "        total_loss+= loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        predicted_labels = (pred>0.5).float()\n",
    "        # print(predicted_labels)\n",
    "        total_correct += (predicted_labels == targets).sum().item()\n",
    "        # print(total_correct)\n",
    "        total_samples += targets.size(0)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    avg_loss = total_loss/len(dataloader)\n",
    "    accuracy = total_correct / total_samples\n",
    "    return avg_loss, accuracy\n",
    "    \n",
    "\n",
    "def test(dataloader, model, loss_fn):\n",
    "  model.eval()\n",
    "  tot = 0\n",
    "  total_correct = 0\n",
    "  total_samples = 0\n",
    "  with torch.no_grad():\n",
    "    for batch_idx, (inputs, targets) in enumerate(dataloader):\n",
    "      #compute prediction error\n",
    "      pred = model(inputs)\n",
    "      test_loss = loss_fn(pred, targets)\n",
    "      tot += test_loss\n",
    "\n",
    "      # Calculate accuracy\n",
    "      predicted_labels = (pred>0.5).float()\n",
    "      # print(predicted_labels)\n",
    "      total_correct += (predicted_labels == targets).sum().item()\n",
    "      # print(total_correct)\n",
    "      total_samples += targets.size(0)\n",
    "\n",
    "  avg = tot/len(dataloader)\n",
    "  accuracy = total_correct / total_samples\n",
    "\n",
    "  return avg, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Train Loss: 0.6940, Test Loss: 0.6916, Train Accuracy: 0.5146, Test Accuracy: 0.5540\n",
      "Epoch 2/50, Train Loss: 0.6934, Test Loss: 0.6914, Train Accuracy: 0.5187, Test Accuracy: 0.5288\n",
      "Epoch 3/50, Train Loss: 0.6928, Test Loss: 0.6902, Train Accuracy: 0.5174, Test Accuracy: 0.5284\n",
      "Epoch 4/50, Train Loss: 0.6926, Test Loss: 0.6902, Train Accuracy: 0.5232, Test Accuracy: 0.5284\n",
      "Epoch 5/50, Train Loss: 0.6926, Test Loss: 0.6896, Train Accuracy: 0.5135, Test Accuracy: 0.5284\n",
      "Epoch 6/50, Train Loss: 0.6921, Test Loss: 0.6909, Train Accuracy: 0.5149, Test Accuracy: 0.5286\n",
      "Epoch 7/50, Train Loss: 0.6923, Test Loss: 0.6900, Train Accuracy: 0.5198, Test Accuracy: 0.5405\n",
      "Epoch 8/50, Train Loss: 0.6914, Test Loss: 0.6857, Train Accuracy: 0.5226, Test Accuracy: 0.5284\n",
      "Epoch 9/50, Train Loss: 0.6917, Test Loss: 0.6895, Train Accuracy: 0.5193, Test Accuracy: 0.5423\n",
      "Epoch 10/50, Train Loss: 0.6922, Test Loss: 0.6880, Train Accuracy: 0.5204, Test Accuracy: 0.5517\n",
      "Epoch 11/50, Train Loss: 0.6914, Test Loss: 0.6850, Train Accuracy: 0.5181, Test Accuracy: 0.5563\n",
      "Epoch 12/50, Train Loss: 0.6904, Test Loss: 0.6827, Train Accuracy: 0.5271, Test Accuracy: 0.5641\n",
      "Epoch 13/50, Train Loss: 0.6914, Test Loss: 0.6831, Train Accuracy: 0.5264, Test Accuracy: 0.5602\n",
      "Epoch 14/50, Train Loss: 0.6903, Test Loss: 0.6818, Train Accuracy: 0.5257, Test Accuracy: 0.5457\n",
      "Epoch 15/50, Train Loss: 0.6885, Test Loss: 0.6776, Train Accuracy: 0.5328, Test Accuracy: 0.5432\n",
      "Epoch 16/50, Train Loss: 0.6884, Test Loss: 0.6749, Train Accuracy: 0.5305, Test Accuracy: 0.5462\n",
      "Epoch 17/50, Train Loss: 0.6890, Test Loss: 0.6721, Train Accuracy: 0.5296, Test Accuracy: 0.5466\n",
      "Epoch 18/50, Train Loss: 0.6875, Test Loss: 0.6723, Train Accuracy: 0.5354, Test Accuracy: 0.5478\n",
      "Epoch 19/50, Train Loss: 0.6851, Test Loss: 0.6703, Train Accuracy: 0.5334, Test Accuracy: 0.5629\n",
      "Epoch 20/50, Train Loss: 0.6856, Test Loss: 0.6699, Train Accuracy: 0.5373, Test Accuracy: 0.5430\n",
      "Epoch 21/50, Train Loss: 0.6835, Test Loss: 0.6680, Train Accuracy: 0.5360, Test Accuracy: 0.5753\n",
      "Epoch 22/50, Train Loss: 0.6820, Test Loss: 0.6686, Train Accuracy: 0.5315, Test Accuracy: 0.5482\n",
      "Epoch 23/50, Train Loss: 0.6805, Test Loss: 0.6681, Train Accuracy: 0.5379, Test Accuracy: 0.5823\n",
      "Epoch 24/50, Train Loss: 0.6782, Test Loss: 0.6672, Train Accuracy: 0.5396, Test Accuracy: 0.5865\n",
      "Epoch 25/50, Train Loss: 0.6772, Test Loss: 0.6684, Train Accuracy: 0.5417, Test Accuracy: 0.5862\n",
      "Epoch 26/50, Train Loss: 0.6758, Test Loss: 0.6648, Train Accuracy: 0.5482, Test Accuracy: 0.5849\n",
      "Epoch 27/50, Train Loss: 0.6746, Test Loss: 0.6685, Train Accuracy: 0.5305, Test Accuracy: 0.5615\n",
      "Epoch 28/50, Train Loss: 0.6735, Test Loss: 0.6645, Train Accuracy: 0.5439, Test Accuracy: 0.5846\n",
      "Epoch 29/50, Train Loss: 0.6728, Test Loss: 0.6642, Train Accuracy: 0.5420, Test Accuracy: 0.5835\n",
      "Epoch 30/50, Train Loss: 0.6704, Test Loss: 0.6618, Train Accuracy: 0.5566, Test Accuracy: 0.5959\n",
      "Epoch 31/50, Train Loss: 0.6706, Test Loss: 0.6599, Train Accuracy: 0.5589, Test Accuracy: 0.6009\n",
      "Epoch 32/50, Train Loss: 0.6701, Test Loss: 0.6596, Train Accuracy: 0.5479, Test Accuracy: 0.5803\n",
      "Epoch 33/50, Train Loss: 0.6693, Test Loss: 0.6569, Train Accuracy: 0.5520, Test Accuracy: 0.6057\n",
      "Epoch 34/50, Train Loss: 0.6656, Test Loss: 0.6533, Train Accuracy: 0.5614, Test Accuracy: 0.5984\n",
      "Epoch 35/50, Train Loss: 0.6691, Test Loss: 0.6510, Train Accuracy: 0.5487, Test Accuracy: 0.6086\n",
      "Epoch 36/50, Train Loss: 0.6666, Test Loss: 0.6498, Train Accuracy: 0.5618, Test Accuracy: 0.6114\n",
      "Epoch 37/50, Train Loss: 0.6647, Test Loss: 0.6464, Train Accuracy: 0.5649, Test Accuracy: 0.6116\n",
      "Epoch 38/50, Train Loss: 0.6653, Test Loss: 0.6465, Train Accuracy: 0.5668, Test Accuracy: 0.6111\n",
      "Epoch 39/50, Train Loss: 0.6642, Test Loss: 0.6417, Train Accuracy: 0.5670, Test Accuracy: 0.6125\n",
      "Epoch 40/50, Train Loss: 0.6614, Test Loss: 0.6389, Train Accuracy: 0.5698, Test Accuracy: 0.6146\n",
      "Epoch 41/50, Train Loss: 0.6599, Test Loss: 0.6420, Train Accuracy: 0.5729, Test Accuracy: 0.6127\n",
      "Epoch 42/50, Train Loss: 0.6593, Test Loss: 0.6412, Train Accuracy: 0.5736, Test Accuracy: 0.6116\n",
      "Epoch 43/50, Train Loss: 0.6617, Test Loss: 0.6374, Train Accuracy: 0.5709, Test Accuracy: 0.6155\n",
      "Epoch 44/50, Train Loss: 0.6576, Test Loss: 0.6338, Train Accuracy: 0.5809, Test Accuracy: 0.6153\n",
      "Epoch 45/50, Train Loss: 0.6581, Test Loss: 0.6383, Train Accuracy: 0.5773, Test Accuracy: 0.6174\n",
      "Epoch 46/50, Train Loss: 0.6586, Test Loss: 0.6327, Train Accuracy: 0.5737, Test Accuracy: 0.6160\n",
      "Epoch 47/50, Train Loss: 0.6579, Test Loss: 0.6346, Train Accuracy: 0.5726, Test Accuracy: 0.6150\n",
      "Epoch 48/50, Train Loss: 0.6579, Test Loss: 0.6285, Train Accuracy: 0.5803, Test Accuracy: 0.6190\n",
      "Epoch 49/50, Train Loss: 0.6562, Test Loss: 0.6280, Train Accuracy: 0.5794, Test Accuracy: 0.6187\n",
      "Epoch 50/50, Train Loss: 0.6547, Test Loss: 0.6319, Train Accuracy: 0.5813, Test Accuracy: 0.6160\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.6190476190476191\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "for t in range(epochs):\n",
    "  train_loss, train_accuracy = train(train_dataloader, model, loss_fn, optimizer)\n",
    "  test_loss, test_accuracy = test(test_dataloader, model, loss_fn)\n",
    "  train_losses.append(train_loss)\n",
    "  train_accuracies.append(train_accuracy)\n",
    "  test_losses.append(test_loss)\n",
    "  test_accuracies.append(test_accuracy)\n",
    "  print(f\"Epoch {t+1}/{epochs}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Plotting the loss curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, epochs+1), train_losses, label='Train Loss')\n",
    "plt.plot(range(1, epochs+1), test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss Curve')\n",
    "plt.legend()\n",
    "\n",
    "# Plotting the accuracy curves\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, epochs+1), train_accuracies, label='Train Accuracy')\n",
    "plt.plot(range(1, epochs+1), test_accuracies, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training and Test Accuracy Curve')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best accuracy: {max(test_accuracies)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
